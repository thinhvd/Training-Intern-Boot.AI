{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b84244b",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec8d004",
   "metadata": {},
   "source": [
    "## Filter method\n",
    "\n",
    "### Reducing feature with low variance\n",
    "\n",
    "**Variance threshold** được sử dụng để lựa chọn đặc trưng. Phương pháp này loại bỏ các đặc trưng mà phương sai không đáp ứng một ngưỡng nào đó. Theo mặc định, nó loại bỏ các đặc trưng có phương sai bằng 0, tức là những đặc trưng có cùng giá trị trong tất cả các mẫu.\n",
    "\n",
    "*Source:* https://scikit-learn.org/stable/modules/feature_selection.html#removing-features-with-low-variance\n",
    "\n",
    "### Univariate feature selection methods\n",
    "\n",
    "*Source:* https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection\n",
    "\n",
    "Phương pháp này lựa chọn các đặc trưng tốt nhất dựa trên các phép kiểm tra thống kê (stastical tests). Sklearn cung cấp 4 phương pháp đưới đây:\n",
    "- **SelectKBest**: Lựa chọn K đặc trưng tốt nhất dựa trên các kết quả của kiểm tra thống kê.\n",
    "\n",
    "- **SelectPercentile**: Lựa chọn phần trăm đặc trưng tốt nhất dựa trên các kết quả của kiểm tra thống kê.\n",
    "\n",
    "- Các phương pháp này dựa trên kiểm tra F-test nhưng với các mục tiêu khác nhau: **SelectFpr** chọn các đặc trưng với tỷ lệ false positive, **SelectFdr** chọn các đặc trưng để kiểm soát tỷ lệ false discovery rate, và **SelectFwe** chọn các đặc trưng để kiểm soát tỷ lệ family wise error.\n",
    "\n",
    "- **GenericUnivariateSelection**: Config để lựa chọn cách univariate feature selection. Nó cho phép lựa chọn chiến lựơc univariate selection tốt nhất. \n",
    "\n",
    "**Note:**\n",
    "\n",
    "Các hàm trên sẽ nhận tham số là 1 hàm kiểm tra và trả về univariate score:\n",
    "\n",
    "- For regression tasks: [f_regression](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression), [mutual_info_regression](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html#sklearn.feature_selection.mutual_info_regression)\n",
    "​\n",
    "- For classification tasks: [chi2](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html#sklearn.feature_selection.chi2), \n",
    "[f_classif](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html#sklearn.feature_selection.f_classif), [mutual_info_classif](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html#sklearn.feature_selection.mutual_info_classif)\n",
    "​\n",
    "\n",
    "Các phương pháp dựa trên F-test ước tính mức độ phụ thuộc tuyến tính giữa hai biến ngẫu nhiên. Mặt khác, các phương pháp mutual information có thể ước tính với bất kỳ loại phụ thuộc thống kê nào, nhưng không theo tham số, chúng yêu cầu nhiều mẫu hơn để ước tính chính xác."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf26cccb",
   "metadata": {},
   "source": [
    "# Tri comment: tìm hiểu kỹ hơn về các hàm như chi-square, cách tính, lưu ý về input cho các hàm này, ... (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516d2583",
   "metadata": {},
   "source": [
    "#### Information Gain\n",
    "\n",
    "**Mutual Information(MI)**\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Jaakko-Vaeyrynen/publication/220017760/figure/fig1/AS:669375174565899@1536602886399/Mutual-information-IX-Y-measures-the-common-information-between-two-random.png\" alt=\"MI\" style=\"width: 400px;\"/>\n",
    "\n",
    "- **Discrete distribution**:\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/1030462a874c1160206cf9347302067e20dbfb9a)\n",
    "\n",
    "- **Continous distribution**:\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/3f2b5ef93bc8c87f2ca4fe15e7a914f9fd163976)\n",
    "\n",
    "Ta thấy:\n",
    "\n",
    "- Thông tin chứa bởi cả cặp $(X, Y)$ là $H(X,Y)$.\n",
    "- Thông tin chứa trong $X$ nhưng lại không chứa trong $Y$ là $H(X|Y)$.\n",
    "- Thông tin chứa trong $Y$ nhưng lại không nằm trong $X$ là $H(Y|X)$.\n",
    "\n",
    "Chúng ta có thể trả lời câu hỏi sau đây: \"Lượng thông tin giống nhau, tức là cùng được biết bởi cả hai biến $X$ và $Y$, là bao nhiêu?\". Một cách rất trực quan, chúng ta xây dựng khái niệm mutual information như sau\n",
    "\n",
    "$$\n",
    "I(X,Y) = H(X,Y) - H(X|Y) - H(Y|X)\n",
    "$$\n",
    "\n",
    "Như vậy, mutual information là lượng thông tin thu được từ một biến ngẫu nhiên thông qua việc quan sát giá trị của một biến ngẫu nhiên khác. \n",
    "\n",
    "$$\n",
    "I(X;Y) = \\mathbf{E}_{X,Y} [I(x \\in \\mathcal{X},y \\in \\mathcal{Y})] = \\sum_{x \\in \\mathcal{X}}\\sum_{y \\in \\mathcal{Y}} p(x,y) \\log \\frac{p(x,y)}{p(x) p(y)}\n",
    "$$\n",
    "\n",
    "Hai công thức trên cho chúng ta một tính chất quan trọng của mutual information, tính đối xứng\n",
    "\n",
    "$$\n",
    "I(X;Y) = I(Y;X).\n",
    "$$\n",
    "\n",
    "Ngoài ra, dựa vào mối quan hệ của entropy hợp và entropy có điều kiện, các biểu thức sau đây đều tương đương với MI\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "I(X;Y) & = & I(Y;X) \\\\\n",
    "& = & H(X,Y) - H(X|Y) - H(Y|X) \\\\ \n",
    "& = & H(X) - H(X|Y) \\\\\n",
    "& = & H(Y) - H(Y|X) \\\\\n",
    "& = & H(X) + H(Y) - H(X,Y)\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "Từ đây, chúng ta thấy rằng MI luôn nhận giá trị không âm (tức là $H(X,Y) \\geq 0$), và dấu $\"=\"$ xảy ra khi và chỉ khi $X$ và $Y$ là hai biến ngẫu nhiên hoàn toàn độc lập. Khi đó, việc biết thông tin của một biến không cho chúng ta bất cứ thông tin gì về biến còn lại, và ngược lại.\n",
    "\n",
    "- **Mutual Information and kNN estimators**\n",
    "\n",
    "![](miKnn.png)\n",
    "\n",
    "- Đây là một phương pháp trong thư viện sklearn dùng để ước tính thông tin chung (mutual information) cho một biến mục tiêu rời rạc.\n",
    "\n",
    "- Thông tin chung (Mutual information, MI) giữa hai biến ngẫu nhiên là một giá trị không âm, đo lường mức độ phụ thuộc giữa các biến này. Nó bằng 0 nếu và chỉ nếu hai biến ngẫu nhiên độc lập, và giá trị cao hơn cho thấy mức độ phụ thuộc cao hơn.\n",
    "\n",
    "- Phương pháp này sử dụng các phương pháp nonparametric dựa trên ước tính entropy từ k-nearest neighbors distances.\n",
    "\n",
    "- Phương pháp này có thể được sử dụng để lựa chọn các đặc trưng dựa trên một biến (univariate feature selection).\n",
    "\n",
    "*Source*: https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html#sklearn.feature_selection.mutual_info_classif\n",
    "\n",
    "\n",
    "**mutual_info_classif**\n",
    "\n",
    "- **mutual_info_classif** áp dụng cho biến rời rạc\n",
    "\n",
    "**mutual_info_regression**\n",
    "\n",
    "- **mutual_info_regression** áp dụng cho biến liên tục.\n",
    "\n",
    "*Source*: https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html#sklearn.feature_selection.mutual_info_regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41108dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T13:05:25.345174Z",
     "start_time": "2023-08-17T13:05:25.328177Z"
    }
   },
   "source": [
    "# Tri comment: tìm hiểu kỹ hơn về mutual information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9da3385",
   "metadata": {},
   "source": [
    "#### Chi-square\n",
    "\n",
    "**Chi-squared** test sẽ tính toán thống kê chi-squared giữa mối feature và biến target. Thống kê **chi-squared** tính toán sự khác biệt giữa tần số kì vọng(expected frequency) và tần số quan sát được(observed frequency) của mỗi feature\n",
    "\n",
    "Ví dụ về **tần số kì vọng** và **tần số quan sát**:\n",
    "\n",
    "<img src=\"Image\\chi2.png\" alt=\"chi2\" style=\"width: 650px;\"/>\n",
    "\n",
    "Thống kê chi-squared **càng cao** thì cho thấy feature đó **càng liên quan** đến biến **target** (có ý nghĩa trong classification)\n",
    "\n",
    "**Chi-squared** statistic được tính bằng công thức dưới đây:\n",
    "$$\n",
    "\\chi^2 = \\sum \\left( \\frac{(O - E)^2}{E} \\right)\n",
    "$$\n",
    "\n",
    "Trong đó:\n",
    "\n",
    "- **O** là tần số quan sát được (observed frequency) \n",
    "\n",
    "- **E** là tần số kì vọng (expected frequency)\n",
    "\n",
    "**Chi-squared** được sử dụng với feature dạng **categorical**, được lấy mẫu **độc lập** và hàm **chi2** trong sklearn chỉ nhận các giá trị feature **không âm**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3786ae86",
   "metadata": {},
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe1c9f2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T06:37:17.426352Z",
     "start_time": "2023-08-18T06:37:17.393314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sepal length (cm)</td>\n",
       "      <td>10.287129</td>\n",
       "      <td>5.836848e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sepal width (cm)</td>\n",
       "      <td>5.022670</td>\n",
       "      <td>8.115982e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>petal length (cm)</td>\n",
       "      <td>133.068548</td>\n",
       "      <td>1.272131e-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>petal width (cm)</td>\n",
       "      <td>74.279070</td>\n",
       "      <td>7.421726e-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature       score       p-value\n",
       "0  sepal length (cm)   10.287129  5.836848e-03\n",
       "1   sepal width (cm)    5.022670  8.115982e-02\n",
       "2  petal length (cm)  133.068548  1.272131e-29\n",
       "3   petal width (cm)   74.279070  7.421726e-17"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_cat = X.astype(int)\n",
    "\n",
    "chi2_selector = SelectKBest(chi2, k=2)\n",
    "chi2_selector.fit(X_cat, y)\n",
    "\n",
    "chi2_scores = pd.DataFrame(list(zip(iris.feature_names, chi2_selector.scores_, chi2_selector.pvalues_)), \n",
    "                           columns=['feature', 'score', 'p-value'])\n",
    "chi2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5436db81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T06:37:19.765924Z",
     "start_time": "2023-08-18T06:37:19.744932Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['petal length (cm)', 'petal width (cm)'], dtype='<U17')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbest = np.asarray(iris.feature_names)[chi2_selector.get_support()]\n",
    "kbest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f26dfee",
   "metadata": {},
   "source": [
    "#### F_classif\n",
    "\n",
    "**ANOVA F-value**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9222054",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T06:37:22.217515Z",
     "start_time": "2023-08-18T06:37:22.183480Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sepal length (cm)</td>\n",
       "      <td>119.264502</td>\n",
       "      <td>1.669669e-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sepal width (cm)</td>\n",
       "      <td>49.160040</td>\n",
       "      <td>4.492017e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>petal length (cm)</td>\n",
       "      <td>1180.161182</td>\n",
       "      <td>2.856777e-91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>petal width (cm)</td>\n",
       "      <td>960.007147</td>\n",
       "      <td>4.169446e-85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature        score       p-value\n",
       "0  sepal length (cm)   119.264502  1.669669e-31\n",
       "1   sepal width (cm)    49.160040  4.492017e-17\n",
       "2  petal length (cm)  1180.161182  2.856777e-91\n",
       "3   petal width (cm)   960.007147  4.169446e-85"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fclassif_selector = SelectKBest(f_classif, k=2)\n",
    "fclassif_selector.fit(X, y)\n",
    "\n",
    "f_scores = pd.DataFrame(list(zip(iris.feature_names, fclassif_selector.scores_, fclassif_selector.pvalues_)), \n",
    "                           columns=['feature', 'score', 'p-value'])\n",
    "f_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d015851",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T06:37:23.421442Z",
     "start_time": "2023-08-18T06:37:23.399797Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['petal length (cm)', 'petal width (cm)'], dtype='<U17')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbest = np.asarray(iris.feature_names)[fclassif_selector.get_support()]\n",
    "kbest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aa21e8",
   "metadata": {},
   "source": [
    "#### Correlation-Matrix with Heatmap\n",
    "\n",
    "- **Tương quan (Correlation)** là một đo lường về mối quan hệ tuyến tính giữa 2 hoặc nhiều biến. Thông qua tương quan, chúng ta có thể dự đoán một biến từ biến khác.\n",
    "\n",
    "- **Các biến tốt là những biến có mối tương quan cao với biến mục tiêu.**\n",
    "\n",
    "- Các biến dự đoán có tương quan cung cấp thông tin trùng lặp.\n",
    "\n",
    "- **Các biến nên có mối tương quan với biến mục tiêu nhưng không tương quan với nhau.**\n",
    "\n",
    "- Lựa chọn đặc trưng dựa trên tương quan đánh giá các tập hợp đặc trưng dựa trên giả thuyết sau:\n",
    "\n",
    "- \"Các tập hợp đặc trưng tốt bao gồm các đặc trưng có mối tương quan cao với biến mục tiêu, nhưng không tương quan với nhau\".\n",
    "\n",
    "- Trong phần này, tôi sẽ minh họa cách chọn đặc trưng dựa trên tương quan giữa hai đặc trưng. Chúng ta có thể tìm các đặc trưng có tương quan với nhau. Bằng cách xác định những đặc trưng này, chúng ta sau đó có thể quyết định các đặc trưng chúng ta muốn giữ lại và những đặc trưng chúng ta muốn loại bỏ.\n",
    "\n",
    "- Sử dụng tương quan Pearson, giá trị hệ số trả về sẽ biến đổi trong khoảng từ -1 đến 1.\n",
    "\n",
    "- Nếu tương quan giữa hai đặc trưng bằng 0, điều này có nghĩa là thay đổi bất kỳ trong hai đặc trưng này sẽ không ảnh hưởng đến đặc trưng còn lại.\n",
    "\n",
    "- Nếu tương quan giữa hai đặc trưng lớn hơn 0, điều này có nghĩa là tăng giá trị trong một đặc trưng sẽ làm tăng giá trị trong đặc trưng khác (càng gần hệ số tương quan với 1, mối quan hệ giữa hai đặc trưng càng mạnh).\n",
    "\n",
    "- Nếu tương quan giữa hai đặc trưng nhỏ hơn 0, điều này có nghĩa là tăng giá trị trong một đặc trưng sẽ làm giảm giá trị trong đặc trưng khác (càng gần hệ số tương quan với -1, mối quan hệ giữa hai đặc trưng càng mạnh).\n",
    "\n",
    "- Trong phân tích này, chúng ta sẽ kiểm tra xem các biến được lựa chọn có tương quan cao với nhau hay không. Nếu có, chúng ta cần giữ lại chỉ một trong những biến tương quan và loại bỏ các biến khác."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53aef5d",
   "metadata": {},
   "source": [
    "# Tri comment: Test - sử dụng correlation để chọn những feature cho 1 bài toán. Đánh giá kết quả trước và sau khi remove những feature có correlation cao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c308884",
   "metadata": {},
   "source": [
    "## Wrapper method\n",
    "\n",
    "### Recursive feature elimination\n",
    "\n",
    "**Recursive Feature Elimination (RFE)** thực hiện một phương pháp tìm kiếm tham lam để tìm tập con đặc trưng có hiệu suất tốt nhất. Nó lặp đi lặp lại việc xây dựng các mô hình và xác định đặc trưng tốt nhất hoặc tệ nhất ở mỗi vòng lặp. Đầu tiên, model estimator được huấn luyện trên tập đặc trưng ban đầu và sự quan trọng của mỗi đặc trưng được xác định thông qua các thuộc tính cụ thể (như coef_, feature_importances_). Sau đó, những đặc trưng ít quan trọng nhất được loại bỏ khỏi tập đặc trưng hiện tại. Việc này được lặp lại đệ quy trên tập cho đến khi đạt được số lượng đặc trưng cần chọn. Sau đó, nó xếp hạng các đặc trưng dựa trên thứ tự loại bỏ chúng. Trong trường hợp tồi nhất, nếu một tập dữ liệu chứa N đặc trưng, RFE sẽ thực hiện một tìm kiếm tham lam cho 2N sự kết hợp của các đặc trưng.\n",
    "\n",
    "### Recursive feature elimination with cross-validation\n",
    "\n",
    "A **recursive feature elimination** example with **automatic tuning of the number of features** selected with **cross-validation**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246745f1",
   "metadata": {},
   "source": [
    "## Embedded method\n",
    "\n",
    "### Lasso Regression\n",
    "\n",
    "### Ridge Regression\n",
    "\n",
    "### Random forest importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179343f7",
   "metadata": {},
   "source": [
    "## How to choose a feature selection method\n",
    "\n",
    "![how to choose a feature selection method](https://machinelearningmastery.com/wp-content/uploads/2019/11/How-to-Choose-Feature-Selection-Methods-For-Machine-Learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb93da81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T08:23:58.134793Z",
     "start_time": "2023-08-15T08:23:58.127769Z"
    }
   },
   "source": [
    "# Evaluating Regerssion Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05887bab",
   "metadata": {},
   "source": [
    "## Mean Absolute Error(MAE) (L1 Loss)\n",
    "\n",
    "<img src=\"https://www.freecodecamp.org/news/content/images/2022/07/1_tu6FSDz_FhQbR3UHQIaZNg.png\" alt=\"MAE\" style=\"width: 400px;\"/>\n",
    "\n",
    "**Ưu điểm**\n",
    "\n",
    "- Dễ hiểu và diễn giải: MAE là trung bình của giá trị tuyệt đối sai số giữa giá trị dự đoán và giá trị thực tế.\n",
    "- Ít nhạy cảm hơn đối với outliers\n",
    "\n",
    "**Nhược điểm**\n",
    "- Cần so sánh với chỉ số MAE khác để biết đánh giá tốt hay không\n",
    "- Ít nhạy cảm đối với outliers cũng được coi là nhược điểm của MAE khi mà có những outliers có sai số lớn, MAE sẽ bị tác động dẫn đến không phản ảnh được đúng hiệu suất mô hình\n",
    "- Không khả vi tại 0 (khó khăn đối với các thuật toán tối ưu sử dụng đạo hàm)\n",
    "\n",
    "**Áp dụng**\n",
    "\n",
    "Sử dụng **MAE** khi muốn đánh giá mô hình dự đoán biến liên tục, nhạy cảm với mức lệch lệch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224c2c98",
   "metadata": {},
   "source": [
    "## MAPE (Mean absolute percentage error)\n",
    "\n",
    "<img src=\"Image\\mape.png\" alt=\"MAPE\" style=\"width: 350px;\"/>\n",
    "\n",
    "**Ưu điểm**\n",
    "- Dễ hiểu. Cho biết kết quả theo tỉ lệ phần trăm, giúp dễ dàng so sánh với các mô hình khác \n",
    "\n",
    "**Nhược điểm**\n",
    "\n",
    "- Bị ảnh hưởng bởi outliers như các giá trị quá lớn\n",
    "- Không thể hiện chính xác khi giá trị thực tế gần 0\n",
    "- Phạt negative error nặng hơn positive error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e624db0",
   "metadata": {},
   "source": [
    "## MSE (L2 Loss)\n",
    "\n",
    "<img src=\"https://editor.analyticsvidhya.com/uploads/53490MSE.png\" alt=\"mse\" style=\"width: 400px;\"/>\n",
    "\n",
    "**Ưu điểm**\n",
    "- Sử dụng bình phương nên với những lỗi lớn sẽ bị phạt rất nặng\n",
    "- Vì là một hàm bậc 2 nên những thuật toán tối ưu sử dụng đạo hàm sẽ tối ưu rất nhanh, không có cực tiểu địa phương\n",
    "\n",
    "**Nhược điểm**\n",
    "- Không cùng đơn vị với target\n",
    "- Cần so sánh thêm với các MSE khác để biết đánh giá có tốt hay không\n",
    "- Nhạy cảm với outlier cũng sẽ là nhược điểm của MSE, khi có lỗi ngoại lai rất lớn sẽ dẫn đến lỗi cực lớn\n",
    "\n",
    "**Áp dụng**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffadd4f",
   "metadata": {},
   "source": [
    "## Root Mean Squared Error (RMSE)\n",
    "\n",
    "![RMSE](https://www.freecodecamp.org/news/content/images/2022/07/0_2IuTz3Tr_dYNc6Df.png)\n",
    "\n",
    "**Ưu điểm**\n",
    "- Dễ hiểu\n",
    "- Dễ dàng thực hiện đạo hàm cho các thuật toán tối ưu\n",
    "- Không xử phạt các lỗi nhiều như MSE do đã được căn bậc 2, vì sử dụng căn bậc 2 nên có cùng đơn vị với target\n",
    "\n",
    "**Nhược điểm**\n",
    "- Muốn đánh giá được mô hình với RMSE cần so sánh với các chỉ số RMSE khác (như sử dụng mô hình khác, mô hình khi sử dụng các feature khác,...)\n",
    "- Nhạy cảm với outliers\n",
    "\n",
    "**Áp dụng**\n",
    "- Khi muốn sử dụng để so sánh các mô hình mà thay vì dùng MSE ta muốn có đơn vị sai số tương đương với target\n",
    "\n",
    "**Biến thể:**\n",
    "\n",
    "**RMSE** có một số các biến thể khác như:\n",
    "- **NRMSE** là **RMSE** được chuẩn hóa bằng cách chia cho một giá trị nào đó. Điều này giúp giảm phụ thuộc vào tỷ lệ, thuận lợi cho việc so sánh giữa các mô hình với các tỷ lệ khác nhau:\n",
    "    - RMSE / maximum value in the series\n",
    "    - RMSE / mean\n",
    "    - RMSE / difference between the maximum and the minimum values (if mean is zero)\n",
    "    - RMSE / standard deviation\n",
    "    - RMSE / interquartile range\n",
    "    \n",
    "- **RRMSE**\n",
    "<img src=\"Image\\rrmse.webp\" alt=\"rrmse\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec91439",
   "metadata": {},
   "source": [
    "## RMSLE\n",
    "\n",
    "<img src=\"https://editor.analyticsvidhya.com/uploads/32137RMSLE.png\" alt=\"rmsle\" style=\"width: 400px;\"/>\n",
    "\n",
    "**Ưu điểm**\n",
    "- Không bị ảnh hưởng bởi các ngoại lệ lớn\n",
    "- Không phụ thuộc vào quy mô, có thể đánh giá với dữ liệu có giá trị lớn\n",
    "\n",
    "**Nhược điểm**:\n",
    "- **MSLE** bị cho là có hình phạt thiên lệch (biased penalty) vì nó phạt việc ước tính thấp hơn (underestimation) nhiều hơn so với ước tính cao hơn (overestimation) (có thể thử so sánh giữa $|log(10) - log(19)|$ và $|log(10) - log(1)|$)\n",
    "\n",
    "**Áp dụng**\n",
    "\n",
    "Thường được sử dụng cho dữ liệu có phân phối lệch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd9470d",
   "metadata": {},
   "source": [
    "## R2 Score\n",
    "\n",
    "<img src=\"https://www.freecodecamp.org/news/content/images/2022/08/image.png\" alt=\"R2\" style=\"width: 800px;\"/>\n",
    "\n",
    "**Ưu điểm**\n",
    "- Thể hiện rõ ràng, R2 tính toán tỉ lệ phần trăm biến thiên của biến phụ thuộc được giải thích bởi các biến độc lập\n",
    "- Không phụ thuộc vào quy mô của sai số và dữ liệu, R2 có thể đánh giá được mô hình mà không cần so sánh với mô hình khác\n",
    "\n",
    "**Nhược điểm**\n",
    "\n",
    "- Càng đưa thêm nhiều biến vào mô hình, mặc dù chưa xác định biến đưa vào có ý nghĩa hay không thì giá trị R2 sẽ giữ nguyên hoặc tăng lên. Lý do là khi càng đưa thêm biến giải thích vào mô hình thì sẽ càng khiến phần dư giảm xuống (vì bản chất những gì không giải thích được đều nằm ở phần dư), do vậy tăng thêm biến sẽ khiến tổng bình phương phần dư(Residual Sum of Squares) giảm, trong khi Total Sum of Squares không đổi, dẫn tới R2 tăng.\n",
    "\n",
    "**Áp dung**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59ac5d8",
   "metadata": {},
   "source": [
    "## Adjusted R-squared\n",
    "**Adjusted R-squared** tính đến số lượng biến độc lập được sử dụng để dự đoán biến mục tiêu. Khi làm như vậy, chúng ta có thể xác định xem việc thêm các biến mới vào mô hình có thực sự làm tăng mức độ phù hợp của mô hình hay không.\n",
    "\n",
    "<img src=\"Image\\adj_r2.png\" alt=\"adj_R2\" style=\"width: 400px;\"/>\n",
    "\n",
    "Trong đó,\n",
    "\n",
    "- **n** là số điểm dữ liệu trong dataset\n",
    "- **k** là số lượng biến độc lập\n",
    "- **R** là giá trị R-squared\n",
    "\n",
    "**Ưu điểm**\n",
    "- Khắc phục được nhược điểm của **R-squared**\n",
    "- Cho phép chúng ta so sánh các mô hình với số lượng biến lộc lập khác nhau\n",
    "\n",
    "**Nhược điểm**\n",
    "\n",
    "**Áp dụng**\n",
    "- Khi muốn so sánh các mô hình với số lượng biến độc lập khác nhau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15e24da",
   "metadata": {},
   "source": [
    "## Nhìn chung, MAE, MSE và RMSE thường được sử dụng để so sánh các mô hình với nhau; R-squared và Adjusted R-squared thường được sử dụng để đánh giá mức độ phù hợp của mô hình."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b3a2f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T13:09:42.210383Z",
     "start_time": "2023-08-17T13:09:42.188354Z"
    }
   },
   "source": [
    "# Tri comment: Bổ sung - các metric đánh giá ở trên có ưu, nhược điểm gì. Được áp dụng trong những trường hợp nào, có metric / biến thể nào khác không"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c093c0d9",
   "metadata": {},
   "source": [
    "# SLIDE REGRESSION MODEL:\n",
    "\n",
    "https://www.canva.com/design/DAFrIZJ5TPw/wCD2L8RVIn1qBatUHsFNWg/edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106a4771",
   "metadata": {},
   "source": [
    "# Simple Linear Regression\n",
    "![](Image\\C1_W1_L3_S1_Lecture_b.png)\n",
    "\n",
    "The model's prediction:\n",
    "\n",
    "$$f_{w,b}(x^{(i)}) = wx^{(i)} + b$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f126b3",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "The model's prediction with multiple variables is given by the linear model:\n",
    "\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) =  w_0x_0 + w_1x_1 +... + w_{n-1}x_{n-1} + b $$\n",
    "or in vector notation:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) = \\mathbf{w} \\cdot \\mathbf{x} + b  $$ \n",
    "where $\\cdot$ is a vector `dot product`\n",
    "\n",
    "**Cost funtion**\n",
    "$$J(\\mathbf{w},b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})^2 $$\n",
    "\n",
    "**Gradient descent**\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\\;\n",
    "& w_j = w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  \\; & \\text{for j = 0..n-1}\\newline\n",
    "&b\\ \\ = b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "\n",
    "where, n is the number of features, parameters $w_j$,  $b$, are updated simultaneously and where  \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)}  \\\\\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})\n",
    "\\end{align}\n",
    "$$\n",
    "* m is the number of training examples in the data set\n",
    "\n",
    "    \n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ is the model's prediction, while $y^{(i)}$ is the target value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f1eb23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T10:16:47.069685Z",
     "start_time": "2023-08-21T10:16:47.056695Z"
    }
   },
   "source": [
    "# Support Vector Regression\n",
    "\n",
    "<img src=\"Image\\svr.png\" alt=\"svr\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ae2f20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T01:48:49.742962Z",
     "start_time": "2023-08-10T01:48:49.659966Z"
    }
   },
   "source": [
    "# Decision Tree Regression\n",
    "\n",
    "<img src=\"https://machinelearningcoban.com/assets/34_id3/dt_ex2.png\" alt=\"decision tree\" style=\"width: 800px;\"/>\n",
    "\n",
    "**References**:\n",
    "\n",
    "- https://phamdinhkhanh.github.io/deepai-book/ch_ml/DecisionTree.html\n",
    "\n",
    "- https://machinelearningcoban.com/2018/01/14/id3/\n",
    "\n",
    "**Decision tree** là một mô hình supervised learning, có thể được áp dụng vào cả hai bài toán **classification** và **regression**. Việc xây dựng một decision tree trên dữ liệu huấn luyện cho trước là việc đi xác định các câu hỏi và thứ tự của chúng.\n",
    "\n",
    "## Cách hoạt động của Decision tree\n",
    "Decision Trees sử dụng nhiều thuật toán để quyết định chia một nút thành hai hoặc nhiều nút con. Việc tạo ra các nút con này làm tăng tính đồng nhất của các nút con kết quả. Nói cách khác, ta có thể nói rằng độ tinh khiết của nút tăng lên đối với biến mục tiêu. Cây quyết định chia nút dựa trên tất cả các biến có sẵn và sau đó chọn phân chia dẫn đến các nút con đồng nhất nhất.\n",
    "\n",
    "Lựa chọn thuật toán cũng dựa trên loại biến mục tiêu. Dưới đây là một số thuật toán được sử dụng trong Decision Trees:\n",
    "\n",
    "- **ID3**\n",
    "- C4.5\n",
    "- **CART (Classification And Regression Tree)**\n",
    "- CHAID (Chi-square automatic interaction detection)\n",
    "- MARS (multivariate adaptive regression splines)\n",
    "\n",
    "## ID3 và CART\n",
    "\n",
    "Trong ID3, tổng có trọng số của entropy tại các leaf-node sau khi xây dựng decision tree được coi là hàm mất mát của decision tree đó. Rẽ nhánh tập $S$ tạo thành $k$ tập $\\mathcal{S}_1, \\mathcal{S}_2,\\dots,\\mathcal{S}_{k}$ . Khi đó hàm entropy sau phân chia:\n",
    "\n",
    "$$\n",
    "\\mathbf{H}(x^{(j)}, \\mathbf{t}; \\mathcal{S}) = \\sum_{i=1}^{k}\\frac{N_i}{N}\\mathbf{H}(\\mathcal{S}_i)\n",
    "$$\n",
    "\n",
    "**Information gain**:\n",
    "$$\n",
    "\\begin{split}\\begin{eqnarray}\\mathbf{G}(x^{(j)}, \\mathbf{t}; \\mathcal{S}) & = & \\mathbf{H}(\\mathcal{S}) - \\mathbf{H}(x^{(j)}, \\mathbf{t}; \\mathcal{S}) \\\\\n",
    "& = & \\mathbf{H}(\\mathcal{S}) - \\sum_{i=1}^{k}\\frac{N_i}{N}\\mathbf{H}(\\mathcal{S}_i)\\end{eqnarray}\\end{split}\n",
    "$$\n",
    "\n",
    "Ở mỗi lượt, giải thuật tìm kiếm tham lam sẽ tìm kiếm theo thứ tự từ trên xuống dưới biến $x^{(j)}$ và ngưỡng $t$ tương ứng, sao cho giá trị hàm tin thu đạt cực đại. Tức là $j, t$ là nghiệm của bài toán tối ưu:\n",
    "$$\n",
    "\\hat{j}, \\hat{t}  = \\arg \\max_{j, t} \\mathbf{G}(x^{(j)}, t; \\mathcal{S})\n",
    "$$\n",
    " \n",
    "## Chỉ số Gini\n",
    "\n",
    "Chỉ số Gini là một lựa chọn khác bên cạnh hàm entropy được sử dụng để đo lường mức độ bất bình đẳng trong phân phối của các lớp. Chỉ số này được tính bằng cách lấy 1 trừ đi tổng bình phương tỷ lệ phần trăm ở mỗi lớp:\n",
    "\\begin{aligned}\n",
    "\\displaystyle Gini = 1 - \\sum_{i=1}^C(p_i)^2\n",
    "\\end{aligned}\n",
    "$$\n",
    "0 \\leq \\text{Gini} \\leq 1-\\frac{1}{C}\n",
    "$$\n",
    "\n",
    "![](https://machinelearningcoban.com/tabml_book/_images/gini_score.PNG)\n",
    "\n",
    "\n",
    "## Decision tree cho bài toán regression\n",
    "Thay vì sử dụng hàm information gain, bài toán sử dụng *độ suy giảm của phương sai (reduction in variance)*.\n",
    "\n",
    "Đầu tiên chúng ta tính phương sai trước khi phân chia của biến mục tiêu $y$ tại node $S$:\n",
    "$$\n",
    "\\text{S}(y; \\mathcal{S}) = \\frac{\\sum_{i=1}^{N}(y_i-\\bar{y})^2}{N}\n",
    "$$\n",
    "Phương sai của biến mục tiêu sau khi phân chia sẽ bằng tổng có trọng số của phương sai trên từng nhóm:\n",
    "$$\n",
    "\\text{S}(y, x^{(j)}, \\mathbf{t}; \\mathcal{S}) = \\sum_{i=1}^{k} \\frac{N_i}{N}\\text{S}(y;\\mathcal{S_i})\n",
    "$$\n",
    "Giá trị của reduction variance sau phân chia:\n",
    "$$\n",
    "\\text{RV}(y, x^{(j)}, \\mathbf{t}; \\mathcal{S}) = \\text{S}(y; \\mathcal{S}) - \\text{S}(y, x^{(j)}, \\mathbf{t}; \\mathcal{S})\n",
    "$$\n",
    "Thuật toán tìm kiếm tham lam sẽ tìm cách lựa chọn $x_i$\n",
    " và ngưỡng phân chia sao cho *độ suy giảm phương sai* $\\text{RV}(y, x_j, \\mathbf{t}; \\mathcal{S})$\n",
    " là lớn nhất. Điều này cũng có nghĩa rằng các quan sát được phân về cùng một node lá thì có giá trị dự báo sát nhau. Như vậy ta có thể đưa ra một ước lượng chung cho node lá bằng trung bình cộng của biến mục tiêu mà không lo lắng giá trị dự báo bị chệch. Như vậy giá trị ước lượng của một quan sát $(\\mathbf{x}_i, y_i)$\n",
    " thuộc về node $(\\mathbf{x}_i, y_i)$\n",
    " sẽ bằng trung bình cộng biến mục tiêu của node:\n",
    " $$\n",
    " \\hat{y}_i = \\frac{1}{|S_j|}\\sum_{k=1}^{|S_j|} y_k\n",
    " $$\n",
    " \n",
    " ## Hyper parameters in sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a527b98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T01:53:59.614593Z",
     "start_time": "2023-08-10T01:53:59.597175Z"
    }
   },
   "source": [
    "# Random Forest Regression\n",
    "\n",
    "\n",
    "## Bagging\n",
    "Bagging là phương pháp kết hợp nhiều mô hình học máy có độ chính xác cao nhưng có phương sai lớn để tăng tính ổn định (nhưng giữ độ chính xác). Trước khi có Bagging, mô hình cây quyết định phải sử dụng các kỹ thuật cắt tỉa cây để tăng tính ổn định (giảm hiện tượng học quá - overfitting) nhưng phải đánh đổi bằng việc giảm độ chính xác.\n",
    "\n",
    "Lược đồ của phương pháp Bagging như sau, cho thuật toán học $\\mathcal A$ và bộ dữ liệu $D$\n",
    "\n",
    "$\\mathrm{Bagging}(\\mathcal A, D, B)$\n",
    "\n",
    "1. Lấy mẫu có hoàn lại từ $D$ để tạo ra $B$ bộ dữ liệu mới $D_1, D_2, \\ldots, D_B$\n",
    "2. Chạy thuật toán $\\mathcal A$ trên các bộ dữ liệu này để huấn luyện $m$ mô hình\n",
    "    \n",
    "    $$\n",
    "    h_i = \\mathcal A(D_i), i=1,2,\\ldots,B\n",
    "    $$\n",
    "    \n",
    "3. Xây dựng mô hình tổng hợp\n",
    "    - Với mô hình phân lớp, sử dụng $h_i$ để **bỏ phiếu** chọn ra phân lớp có nhiều mô hình chọn nhất\n",
    "    \n",
    "    $$\n",
    "    h(\\mathbf x) = \\underset{c}{\\operatorname{argmax}}\n",
    " \\sum_{i=1}^B \\mathbb I(h_i(\\mathbf x)=c)\n",
    "    $$\n",
    "    \n",
    "    - Với mô hình hồi quy, lấy **trung bình cộng** kết quả của $h_i$\n",
    "        \n",
    "        $$\n",
    "        h(\\mathbf x) = \\frac 1 B\\sum_{i=1}^B h_i(\\mathbf x)\n",
    "        $$\n",
    "        \n",
    "\n",
    "## Random forest\n",
    "Mô hình rừng ngẫu nhiên sử dụng **Bagging** đối với thuật toán cây quyết định với một thay đổi nhỏ. Trong đó, khi xây dựng cây quyết định từ tập mẫu $D_i$, tại mỗi bước phân chia nút trong cây, ta chỉ chọn ngẫu nhiên $m$ thuộc tính trong $p$ thuộc tính $A_1, A_2,\\ldots, A_p$ để chọn ra thuộc tính phân chia tốt nhất.\n",
    "\n",
    "$\\mathrm{RandomForest}(D, B, m)$\n",
    "\n",
    "1. Lấy mẫu có hoàn lại từ $D$ để tạo ra $B$ bộ dữ liệu mới $D_1, D_2, \\ldots, D_B$\n",
    "\n",
    "2. Với mỗi tập dữ liệu $D_i$, xây dựng cây quyết định $h_i =T_i$ sao cho:\n",
    "    - Tại mỗi lần phân chia, chọn ngẫu nhiên $m$ thuộc tính trong $p$ thuộc tính dữ liệu\n",
    "    - Tìm thuộc tính phân chia tốt nhất (theo ID3, C4.5, CART)\n",
    "    - Phân chia đến khi mỗi nút có không quá $n_{min}$ mẫu dữ \n",
    "    \n",
    "3. Xây dựng mô hình tổng hợp (giống như đã nêu ở Bagging)\n",
    "- Phân lớp: $h(\\mathbf x) = \\underset{c}{\\operatorname{argmax}}\\sum_{i=1}^B \\mathbb I(h_i(\\mathbf x)=c)$\n",
    "\n",
    "- Hồi quy: $h(\\mathbf x) = \\frac 1 B\\sum_{i=1}^B h_i(\\mathbf x)$\n",
    "\n",
    "**Cách chọn tham số**: thường chọn $m\\approx\\sqrt{p}$\n",
    "\n",
    "## Hyper parameters in sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5923e4a7",
   "metadata": {},
   "source": [
    "# Tri comment: Bổ sung \n",
    "\n",
    "- Với Linear Regression và các thuật toán Tree-based có phải scale dữ liệu trước khi fit với dữ liệu không\n",
    "- Với những thuật toán Tree-based:\n",
    "    - Feature importance là gì, có những loại feature importance nào\n",
    "    - Tối ưu tham số mô hình: Mô hình cây có những tham số nào ảnh hưởng đến:\n",
    "        - Tốc độ training\n",
    "        - Kết quả mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2b40d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T06:52:57.315150Z",
     "start_time": "2023-08-21T06:52:57.300139Z"
    }
   },
   "source": [
    "## Feature scaling với mô hình Linear regression và các thuật toán Tree-based\n",
    "\n",
    "- Với **Linear regression**, việc scale dữ liệu là không bắt buộc nhưng nên thực hiện vì nó sẽ đem lại những lợi ích nhất định. Việc scale dữ liệu sẽ giúp đưa dữ liệu từ 1 phạm vi lớn thu về 1 phạm vi nhỏ hơn, điều này sẽ giúp cho thuật toán tối ưu Linear regression là gradient descent có thể tính toán nhanh, hội tụ nhanh hơn. Ngoài ra, Linear regression là 1 mô hình đơn giản, khá nhạy cảm với outliers, việc scale dữ liệu cũng sẽ giúp giảm ảnh hưởng của outlier đối với mô hình\n",
    "\n",
    "- Với các thuật toán **Tree-based**, như **Decision tree**, việc phân chia các node thực hiện trên việc tính toán các ngưỡng thông tin của đặc trưng, chứ không bị ảnh hưởng bởi phạm vi giá trị, nên mô hình sử dụng các thuật toán Tree-based có thể hoạt động tốt mà không cần scale dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefb00b9",
   "metadata": {},
   "source": [
    "## Feature importance\n",
    "\n",
    "### Feature importance based on mean decrease in impurity\n",
    "\n",
    "Tại mỗi node, tính toán sự giảm mức độ vẩn đục (impurity) khi split dữ liệu dựa trên một feature. Feature quan trọng sẽ là feature làm giảm mức độ impurity nhiều nhất. Feature importances cung cấp attribute *feature_importances_*, được tính bằng trung bình (mean) và độ lệch chuẩn (standard deviation) của độ giảm impuirty của tất cả các split dựa trên feature đó. \n",
    "\n",
    "### Feature importance based on feature permutation\n",
    "\n",
    "Permutation feature importance được định nghĩa là model score giảm khi một feature được xáo trộn ngẫu nhiên. Quy trình này phá vỡ mối quan hệ giữa feature và target, do đó, việc model score giảm cho thấy mức độ quan trọng của feature đối với mô hình.\\\n",
    "\n",
    "Hàm **permutation_importance** tính toán feature importance của 1 mô hình estimator với bộ dataset cho trước. Tham số *n_repeats* set số lần feature được xáo trộn ngẫu nhiên và trả về bộ sample các feature importances\n",
    "\n",
    "Permutation feature importance là việc model score bị giảm khi ta hoán vị 1 feature 1 cách ngẫu nhiên. Hàm tính điểm được sử dụng cho việc tính toán độ quan trọng có thể được chỉ định với tham số *scoring*. Chúng ta có thể sử dụng 1 lúc nhiều cách scoring khác nhau để tăng hiệu quả tính toán so với việc gọi lại liên tục hàm **permuatation_importance** cho mỗi cách tính điểm khác nhau(vì như vậy nó sẽ sử dụng lại các dự đoán của mô hình)\n",
    "\n",
    "**Outline of the permutation importance algorithm**\n",
    "- Inputs: fitted predictive model $m$ , tabular dataset (training or validation) $D$ .\n",
    "- Compute the reference score $s$ of the model $m$ on data $D$ (for instance the accuracy for a classifier or the $R^2$ for a regressor).\n",
    "- For each feature $j$(column of $D$):\n",
    "    - For each repetition $k$ in ${1, ..., K}$:\n",
    "        - Randomly shuffle column $j$ of dataset $D$ to generate a corrupted version of the data named $\\tilde{D}_{k,j}$\n",
    "        - Compute the score $s_{k,j}$ of model $m$ on corrupted data $\\tilde{D}_{k,j}$\n",
    "    - Compute importance $i_j$ for feature $f_j$ defined as:\n",
    "$$\n",
    "i_j = s - \\frac{1}{K} \\sum_{k=1}^{K} s_{k,j}\n",
    "$$\n",
    "\n",
    "**Mối quan hệ với impurity-based importance in trees**\n",
    "\n",
    "Các Tree-based model cung cấp một cách đo độ quan trọng của các đặc trưng khác dựa trên mean decrease in impurity (MDI). Impurity được định lượng bằng tiêu chí chia nhánh của cây quyết định (như Gini, Log Loss hoặc Mean Squared Error). Tuy nhiên, phương pháp này có thể gán độ quan trọng cao cho các đặc trưng có thể không dự đoán được trên dữ liệu chưa nhìn thấy khi mô hình đang bị quá khớp. Trong khi đó, đo lường quan trọng dựa trên hoán vị của các đặc trưng tránh vấn đề này, vì nó có thể tính toán trên dữ liệu chưa nhìn thấy.\n",
    "\n",
    "Hơn nữa, độ quan trọng dựa trên impurity cho các cây có sự thiên vị mạnh mẽ (**strongly biased**) và ưu ái đối với các đặc trưng có độ phân loại cao (**favor high cardinality features**) (thường là đặc trưng numerical) hơn là các đặc trưng có độ phân loại thấp như đặc trưng nhị phân hoặc biến categorical với một số lượng danh mục nhỏ.\n",
    "\n",
    "Trong khi đó, permutation feature importance không thể hiện sự thiên vị(bias) như vậy. Hơn nữa, permutation feature importance có thể tính toán chỉ số hiệu suất trên dự đoán của mô hình và có thể được sử dụng để phân tích bất kỳ loại mô hình nào (không chỉ dựa trên cây).\n",
    "\n",
    "**Misleading values on strongly correlated features**\n",
    "\n",
    "Khi hai đặc trưng có sự tương quan và một trong các đặc trưng được hoán vị, mô hình vẫn sẽ có khả năng truy cập (*access*) đến đặc trưng thông qua đặc trưng tương quan với nó. Điều này sẽ dẫn đến mức độ quan trọng thấp hơn cho cả hai đặc trưng, trong khi thực tế chúng có thể quan trọng.\n",
    "\n",
    "Một cách để xử lý tình huống này là gom nhóm các đặc trưng có tương quan và chỉ giữ lại một đặc trưng từ mỗi nhóm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad16a64",
   "metadata": {},
   "source": [
    "# Phương pháp Boosting\n",
    "\n",
    "Trái với phương pháp **Bagging** tìm cách làm tăng sự ổn định của các mô hình chính xác (nhưng không ổn định), phương pháp **Boosting** tìm cách tăng sự chính xác của các mô hình có **độ chính xác thấp** (weak learners), tức là các mô hình chỉ cần cho xác suất lỗi lớn hơn dự đoán ngẫu nhiên một chút. Ý tưởng chính của **Boosting** là cập nhật mô hình bằng tổ hợp tuyến tính của các mô hình yếu sao cho hàm lỗi giảm dần.\n",
    "\n",
    "<img src=\"https://tricky-tax-444.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F5211dd2e-49c4-4030-8e8f-af719b89f3ca%2FIllustration-of-AdaBoost-algorithm-for-creating-a-strong-classifier-based-on-multiple.png?table=block&id=c0a92ac2-beef-47b8-8598-0b6c0fb5d57d&spaceId=489a998d-9308-40e6-bfe8-44f23a91cf17&width=1400&userId=&cache=v2\" alt=\"svr\" style=\"width: 700px;\"/>\n",
    "\n",
    "\n",
    "## Ada Boosting\n",
    "\n",
    "Thuật toán này thực hiện việc xây dựng một mô hình và đưa ra các trọng số bằng nhau cho tất cả các điểm dữ liệu. Sau đó, nó gán trọng số cao hơn cho các điểm bị phân loại sai. Bây giờ tất cả các điểm có trọng số cao hơn sẽ được coi trọng hơn trong mô hình tiếp theo. Nó sẽ tiếp tục train các mô hình đào tạo cho đến khi được lỗi thấp hơn.\n",
    "\n",
    "Đối với bài toán Regression, thuật toán thường được sử dụng là **AdaBoost.R2**. Đây cũng đang là thuật toán được thư viện sklearn sử dụng\n",
    "\n",
    "**AdaBoost.R2** vẫn dựa trên ý tưởng học từ các sai sót của các **weak leaners** trước đó giống như **AdaBoost**.\n",
    "\n",
    "- Khác **AdaBoost**, **AdaBoost.R2** không kết hợp trực tiếp trọng số vào hàm mất mát mà sử dụng trọng số để lấy mẫu có chỉ định (bootstrapping) từ tập dữ liệu huấn luyện. Các quan sát có trọng số lớn hơn sẽ có xác suất lớn hơn được lấy mẫu.\n",
    "\n",
    "- Mỗi vòng lặp, huấn luyện một **weak learner** trên tập dữ liệu **bootstrapped**.\n",
    "\n",
    "- Tính toán giá trị dự đoán của weak learner đó trên tập dữ liệu gốc (không phải tập bootstrapped).\n",
    "\n",
    "- Sử dụng phương sai của các giá trị dự đoán so với giá trị thực để đánh giá chất lượng của weak learner (gọi là $\\beta^t$).\n",
    "\n",
    "- Cập nhật trọng số dựa trên chất lượng bộ học và độ chính xác dự đoán cho từng quan sát (gọi là $L_n$).\n",
    "\n",
    "- Sau khi lặp qua nhiều weak learners, chúng ta sẽ có được các giá trị phù hợp. Cụ thể, với mỗi quan sát, ta sử dụng **weighted median** của weak learner's prediction, được tính trọng số bằng cách $\\log(1/\\beta^t)$ với $t = 1, \\dots, T$\n",
    "\n",
    "**AdaBoost.R2 Algorithm**\n",
    "\n",
    "1. Initialize the weights with $w^1_n = \\frac{1}{N}$ for $n = 1, 2, \\dots, N$.\n",
    "\n",
    "2. For $t = 1, 2, \\dots, T$ or while $\\bar{L}^t$, as defined below, is less than or equal to 0.5,\n",
    "\n",
    "    - Draw a sample of size $N$ from the training data with replacement and with probability $w^t_n$ for $n = 1, 2, \\dots, N$. \n",
    "    - Fit weak learner $t$ to the resampled data and calculate the fitted values on the original dataset. Denote these fitted values with $f^t(x_{n})$ for $n = 1, 2, \\dots, N$.\n",
    "    - Calculate the observation error $L^t_{n}$ for $n = 1, 2, \\dots, N$:\n",
    "      \n",
    "    $$\n",
    "    \\begin{aligned}\n",
    "    D^t &= \\underset{n}{\\text{max}} \\{ |y_{n} - f^t(x_{n})|  \\} \\\\\n",
    "    L^t_{n} &= \\frac{|y_{n} - f^t(x_{n})|}{D^t}\n",
    "    \\end{aligned}\n",
    "    $$\n",
    "\n",
    "    - Calculate the model error $\\bar{L}^t$:\n",
    "      \n",
    "      $$\n",
    "      \\bar{L}^t = \\sum_{n = 1}^N  L^t_n w^t_n\n",
    "      $$\n",
    "\n",
    "      If $\\bar{L}^t \\geq 0.5$, end iteration and set $T$ equal to $t - 1$.\n",
    "\n",
    "    - Let $\\beta^t = \\frac{\\bar{L}^t}{1- \\bar{L}^t}$. The lower $\\beta^t$, the greater our confidence in the model. \n",
    "\n",
    "    - Let $Z^t = \\sum_{n = 1}^N w^t_n (\\beta^t)^{1 - L^t_n}$ be a normalizing constant and update the model weights with \n",
    "      \n",
    "      $$\n",
    "      w^{t + 1}_n = \\frac{w^t_n (\\beta^t)^{1 - L^t_n}}{Z^t},\n",
    "      $$\n",
    "\n",
    "      which increases the weight for observations with a greater error $L^t_n$.\n",
    "\n",
    "3. Set the overall fitted value for observation $n$ equal to the weighted median of $f^t(x_n)$ for $t = 1, 2, \\dots, T$ using weights $\\log(1/\\beta^t)$ for model $t$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f28c16",
   "metadata": {},
   "source": [
    "## Gradient Boosting\n",
    "\n",
    "Phương pháp _Gradient Boosting_ cũng có ý tưởng tương tự như _AdaBoost_ đó là huấn luyện liên tiếp các mô hình yếu. Nhưng chúng ta không sử dụng sai số của mô hình để tính toán trọng số cho dữ liệu huấn luyện mà sử dụng phần dư. Xuất phát từ mô hình hiện tại, chúng ta cố gắng xây dựng một cây quyết định cố gắng khớp phần dư từ mô hình liền trước. Điểm đặc biệt của mô hình này đó là thay vì chúng ta cố gắng khớp giá trị biến mục tiêu là $\\mathbf{y}$ thì chúng ta sẽ tìm cách khớp giá trị sai số của mô hình trước đó. Sau đó chúng ta sẽ đưa thêm mô hình huấn luyện vào hàm dự báo để cập nhật dần dần phần dư. Mỗi một cây quyết định trong chuỗi mô hình có kích thước rất nhỏ với chỉ một vài _nodes quyết định_ được xác định bởi tham số độ sâu $d$ trong mô hình\n",
    "\n",
    "<img src=\"https://tricky-tax-444.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0d979dc4-ffd6-42ea-8942-c024480033f2%2FUntitled.png?table=block&id=10d9f630-1f9f-4466-bb34-13226d4fa2bd&spaceId=489a998d-9308-40e6-bfe8-44f23a91cf17&width=2000&userId=&cache=v2\" alt=\"gbm\" style=\"width: 700px;\"/>\n",
    "\n",
    "Giả định $\\hat{f}(x)$ là hàm dự báo từ _phương pháp tăng cường_ được áp dụng trên một tác vụ dự báo với ma trận đầu vào $\\mathbf{X}$ và biến mục tiêu là véc tơ $\\mathbf{y}$. Tại mô hình thứ $b$ trong chuỗi mô hình dự báo, kí hiệu là $\\hat{f}^{b}$, ta tìm cách khớp một giá trị phần dư $\\mathbf{r}_i$ từ cây quyết định tiền nhiệm $\\hat{f}^{b-1}$. Các bước trong quá trình huấn luyện mô hình theo _phương pháp tăng cường_ được tóm tắt như sau:\n",
    "\n",
    "**1.**- Ban đầu ta thiết lập hàm dự báo $\\hat{f}(\\mathbf{x}) = 0$ và số dư $\\mathbf{r}_0 = \\mathbf{y}$ cho toàn bộ quan sát trong tập huấn luyện.\n",
    "\n",
    "**2.**- Lặp lại quá trình huấn luyện cây quyết định theo chuỗi tương ứng với $b = 1,2, \\dots, B$. Với một lượt huấn luyện gồm các bước con sau đây:\n",
    "\n",
    "  a. Khớp một cây quyết định $\\hat{f}^{b}$ có độ sâu là $d$ trên tập huấn luyện $(\\mathbf{X}, \\mathbf{r}_b)$.\n",
    "\n",
    "  b. Cập nhật $\\hat{f}$  bằng cách cộng thêm vào giá trị dự báo của một cây quyết đinh, giá trị này được nhân với hệ số co $\\lambda$:\n",
    "\n",
    "  $$\\hat{f}(\\mathbf{x}) = \\hat{f}(\\mathbf{x})+\\lambda \\hat{f}^{b}(\\mathbf{x})$$\n",
    "\n",
    "  c. Cập nhật phần dư cho mô hình:\n",
    "\n",
    "  $$\\mathbf{r}_{b+1} := \\mathbf{r}_b - \\lambda \\hat{f}^{b}(\\mathbf{x})$$\n",
    "\n",
    "  Thuật toán sẽ dừng cập nhật khi số lượng cây quyết định đạt ngưỡng tối đa $B$ hoặc toàn bộ các quan sát trên tập huấn luyện được dự báo đúng.\n",
    "\n",
    "**3.**- Kết quả dự báo từ chuỗi mô hình sẽ là kết hợp của các mô hình con:\n",
    "\n",
    "$$\\hat{f}(\\mathbf{x}) = \\sum_{b=1}^{B} \\lambda \\hat{f}^{b}(\\mathbf{x})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2cc851",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T07:31:52.415880Z",
     "start_time": "2023-08-23T07:31:52.379895Z"
    }
   },
   "source": [
    "## XGBoost, LightGBM, Hist Gradient Boosting\n",
    "\n",
    "**XGBoost**\n",
    "- Tốc độ tính toán nhanh nhờ tính toán song song\n",
    "- Tránh overfit bằng Regularization\n",
    "- Linh hoạt trong sử dụng hàm tối ưu\n",
    "- Tự động xử lý missing value\n",
    "- Tự động cắt tỉa cây(pruning): Tự động bỏ qua những leaves, nodes không mang giá trị tích cực trong quá trình split tree\n",
    "\n",
    "**LightGBM**\n",
    "\n",
    "**Light GBM** sử dụng histogram-based algorithm, đưa các feature có giá trị liên tục thành các bins rời rạc. Điều này giúp tăng tốc độ training và giảm bộ nhớ sử dụng.\n",
    "\n",
    "Dưới đây là ưu điểm khi sử dụng histogram based algorithm trích dẫn từ document LightGBM:\n",
    "\n",
    "*Source*: https://lightgbm.readthedocs.io/en/stable/Features.html\n",
    "\n",
    "**Advantages of histogram-based algorithms include the following:**\n",
    "\n",
    "-  **Reduced cost of calculating the gain for each split**\n",
    "\n",
    "   -  Pre-sort-based algorithms have time complexity ``O(#data)``\n",
    "\n",
    "   -  Computing the histogram has time complexity ``O(#data)``, but this involves only a fast sum-up operation. Once the histogram is constructed, a histogram-based algorithm has time complexity ``O(#bins)``, and ``#bins`` is far smaller than ``#data``.\n",
    "\n",
    "-  **Use histogram subtraction for further speedup**\n",
    "\n",
    "   -  To get one leaf's histograms in a binary tree, use the histogram subtraction of its parent and its neighbor\n",
    "\n",
    "   -  So it needs to construct histograms for only one leaf (with smaller ``#data`` than its neighbor). It then can get histograms of its neighbor by histogram subtraction with small cost (``O(#bins)``)\n",
    "   \n",
    "-  **Reduce memory usage**\n",
    "\n",
    "   -  Replaces continuous values with discrete bins. If ``#bins`` is small, can use small data type, e.g. uint8\\_t, to store training data\n",
    "\n",
    "   -  No need to store additional information for pre-sorting feature values\n",
    "\n",
    "-  **Reduce communication cost for distributed learning**\n",
    "\n",
    "**Light GBM** đánh bại tất cả các thuật toán khác khi tập dataset có kích thước cực lớn. Thực tế chứng minh, nó cần ít thời gian đê xử lý hơn trên tập dữ liệu này. Nguyên nhân sâu xa của sự khác biệt này nằm ở cơ chế làm viêc của Light GBM. Trong khi các thuật toán khác sử dụng cơ chế *level-wise* thì nó lại sử dụng *leaf-wise*.\n",
    "\n",
    "<img src=\"https://tiensu.github.io/images/post/level-wise.webp\" alt=\"lv_wise\" style=\"width: 500px;\"/>\n",
    "<img src=\"https://tiensu.github.io/images/post/leaf-wise.webp\" alt=\"leaf_wise\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "Như chúng ta thấy, *leaf-wise* chỉ mở rộng tree theo 1 trong 2 hướng so với cả 2 hướng của *level-wise*, tức là số lượng tính toán của Light GBM chỉ bằng 1/2 so với XGBoost.\n",
    "\n",
    "**Hist Gradient Boosting**\n",
    "\n",
    "- HistGradientBoosting trên sklearn được lấy cảm hứng dựa trên LightGBM\n",
    "- Nhanh hơn Gradient boosting thông thường rất nhiều khi sử dụng với dữ liệu có lượng samples lớn\n",
    "- Tự động hỗ trợ xử lý missing value, không cần sử dụng imputer\n",
    "- Estimator này trước tiên sẽ bin các mẫu đầu vào X vào các bins có giá trị số nguyên (thường là 256 bins), giúp giảm đáng kể số lượng điểm phân tách cần xem xét và cho phép thuật toán tận dụng các cấu trúc dữ liệu dựa trên số nguyên (histogram) thay vì dựa vào các giá trị liên tục được sắp xếp khi xây dựng cây.\n",
    "\n",
    "*Tham khảo thêm*: https://robotenique.github.io/posts/gbm-histogram/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870c09b3",
   "metadata": {},
   "source": [
    "# Tham số trong các mô hình dạng cây\n",
    "\n",
    "- **n_estimators**: Tổng số mô hình con (cây) sử dụng trong thuật toán ensemble. Nếu *n_estimators* càng lớn, tức là mô hình càng phức tạp, độ chính xác có thể sẽ tốt hơn nhưng thời gian training mô hình sẽ lâu hơn.\n",
    "- **learning_rate**: Đối với các thuật toán boosting như Gradient Boosting, XGB (*learning rate* trong XGB gọi là *eta*), LightGBM,... *learning_rate* là 1 shrinkage parameter để tránh tình trạng overfitting, có thể coi là hệ số cập nhật các weights (phần dư) của các tree-estimators. *learning_rate* là 1 hệ số cần phải **trade-off** với *n_estimators*, khi *learning_rate* nhỏ chúng ta cần lặp nhiều hơn, tức là cần nhiều cây hơn để cải thiện hiệu suất. \n",
    "- **max_depth**: Độ sâu tối đa của cây. Nếu *max_depth* nhỏ có thể kết quả của cây sẽ không tốt. Nếu *max_depth* quá lớn có thể dẫn đến mô hình quá phức tạp, có khả năng kết quả bị overfit và thời gian training sẽ lâu hơn. Đối với các thuật toán boosting không cần cây phải có độ sâu quá lớn (vì boosting tăng cường trên các mô hình yếu).\n",
    "- **min_samples_split**: số lượng samples tối thiểu cần split từ node ban đầu. Nếu *min_samples_split* tăng, cây của ta có thể giảm số lần split, giúp tránh overfitting. Tuy nhiên nếu *min_samples_split* quá cao sẽ dần khiến mô hình underfit.\n",
    "- **min_samples_leaf**: số lượng samples tối thiểu tại mỗi leaf node.\n",
    "- **max_leaf_nodes**: số lượng node lá tối đa, tham số này đặt ra điều kiện splitting của cây để hạn chế sự tăng trưởng của cây. Nếu *max_leaf_node* quá nhỏ có thể khiến mô hình underfit, và quá lớn sẽ dẫn đến overfit\n",
    "\n",
    "Ngoài ra, với **XGBoost** và **LightGBM** là những mô hình không nằm trong sklearn sẽ có thêm các tham số khác để cải thiện tốc độ training hay độ chính xác (tham khảo ở các documents của mô hình):\n",
    "- **LightGBM**:\n",
    "    - Giảm thời gian training: https://lightgbm.readthedocs.io/en/stable/Parameters-Tuning.html#for-faster-speed\n",
    "    - Cải thiện độ chính xác: https://lightgbm.readthedocs.io/en/stable/Parameters-Tuning.html#for-better-accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854a5676",
   "metadata": {},
   "source": [
    "# Differences Between Bagging and Boosting\n",
    "\n",
    "| No. |                                                                     Bagging                                                                    |                                      Boosting                                      |\n",
    "|:----:|:----------------------------------------------------------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------:|\n",
    "|  1.  |                                    The simplest way of combining predictions that  belong to the same type.                                    |         A way of combining predictions that  belong to the different types.        |\n",
    "|  2.  |                                                       Aim to decrease variance, not bias.                                                      |                         Aim to decrease bias, not variance.                        |\n",
    "|  3.  |                                                        Each model receives equal weight.                                                       |                 Models are weighted according to their performance.                |\n",
    "|  4.  |                                                       Each model is built independently.                                                       |      New models are influenced  by the performance of previously built models.     |\n",
    "|  5.  | Different training data subsets are selected using row sampling with replacement and random sampling methods from the entire training dataset. | Every new subset contains the elements that were misclassified by previous models. |\n",
    "|  6.  |                                                Bagging tries to solve the over-fitting problem.                                                |                           Boosting tries to reduce bias.                           |\n",
    "|  7.  |                                       If the classifier is unstable (high variance), then apply bagging.                                       |       If the classifier is stable and simple (high bias) the apply boosting.       |\n",
    "|  8.  |                                                In this base classifiers are trained parallelly.                                                |                 In this base classifiers are trained sequentially.                 |\n",
    "|   9  |                                                 Example: The Random forest model uses Bagging.                                                 |                   Example: The AdaBoost uses Boosting techniques                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30a5e71",
   "metadata": {},
   "source": [
    "# Voting Regressor\n",
    "\n",
    "Ý tưởng của **VotingRegressor** là kết hợp các mô hình hồi quy khác nhau và trả về các giá trị dự đoán **trung bình**. Estimator có thể hoạt động tốt cho một tập hợp các mô hình hoạt động tốt như nhau nhằm cân bằng các điểm yếu riêng lẻ của chúng."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f9763c",
   "metadata": {},
   "source": [
    "# Stacking Regressor\n",
    "\n",
    "Stacked generalization là phương pháp kết hợp các estimator khác nhau để giảm bias của chúng. Chính xác hơn, dự đoán của mỗi estimator sẽ được stack với nhau sử dụng làm input cho final estimator tính toán. Final estimator này sẽ được train qua cross-validation\n",
    "\n",
    "Thực tế, một stacking predictor sẽ có kết quả tốt tương đương với kết quả tốt nhất của mô hình trong layer base và đôi lúc có thể tốt hơn vì được kết hợp với các điểm mạnh của mô hình khác. Tuy nhiên, training stacking predictor đòi hòi tài nguyên tính toán lớn\n",
    "\n",
    "<img src=\"https://editor.analyticsvidhya.com/uploads/39725Stacking.png\" alt=\"stack\" style=\"width: 700px;\"/>\n",
    "\n",
    "Một nhược điểm lớn của Stacking đó là **độ phức tạp lớn**. Với lượng dữ liệu lớn, mô hình stacking có thể phải **mất rất nhiều thời gian** để chạy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5bce17",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n",
    "*Nguồn: https://machinelearningcoban.com/2017/02/24/mlp/*\n",
    "\n",
    "## Layer\n",
    "\n",
    "Ngoài Input layers và Output layers, một Multi-layer Perceptron (MLP) có thể có nhiều Hidden layers ở giữa. Các Hidden layers theo thứ tự từ input layer đến output layer được đánh số thứ thự là Hidden layer 1, Hidden layer 2, … Hình dưới đây là một ví dụ với 2 Hidden layers.\n",
    "\n",
    "<img src=\"https://machinelearningcoban.com/assets/14_mlp/multi_layers.png\" alt=\"layer\" style=\"width: 400px;\"/>\n",
    "\n",
    "## Unit\n",
    "\n",
    "Một _node_ hình tròn trong một layer được gọi là một unit. Unit ở các input layer, hidden layers, và output layer được lần lượt gọi là input unit, hidden unit, và output unit. Đầu vào của các hidden layer được ký hiệu bởi \\\\(z\\\\), đầu ra của mỗi unit thường được ký hiệu là \\\\(a\\\\) (thể hiện _activation_, tức giá trị của mỗi unit sau khi ta áp dụng activation function lên \\\\(z\\\\)). Đầu ra của unit thứ \\\\(i\\\\) trong layer thứ \\\\(l\\\\) được ký hiệu là \\\\(a_i^{(l)}\\\\). Giả sử thêm rằng số unit trong layer thứ \\\\(l)\\\\) (không tính bias) là \\\\(d^{(l)}\\\\). Vector biểu diễn output của layer thứ \\\\(l\\\\) được ký hiệu là \\\\(\\mathbf{a}^{(l)} \\in \\mathbb{R}^{d^{(l)}}\\\\).\n",
    "\n",
    "<img src=\"https://machinelearningcoban.com/assets/14_mlp/mlp_notation.png\" alt=\"unit\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "\n",
    "## Weight, Bias\n",
    "\n",
    "Có \\\\(L\\\\) ma trận trọng số cho một MLP có \\\\(L\\\\) layers. Các ma trận này được ký hiệu là \\\\(\\mathbf{W}^{(l)} \\in \\mathbb{R}^{d^{(l-1)}\\times d^{(l)}}, l = 1, 2, \\dots, L\\\\) trong đó \\\\(\\mathbf{W}^{(l)}\\\\) thể hiện các _kết nối_ từ layer thứ \\\\(l-1\\\\) tới layer thứ \\\\(l\\\\) (nếu ta coi input layer là layer thứ \\\\(0\\\\)). Cụ thể hơn, phần tử \\\\(w^{(l)}_{ij}\\\\) thể hiện kết nối từ node thứ \\\\(i\\\\) của layer thứ \\\\((l-1)\\\\) tới node từ \\\\(j\\\\) của layer thứ \\\\((l)\\\\). Các biases của layer thứ \\\\((l)\\\\) được ký hiệu là \\\\(\\mathbf{b}^{(l)} \\in \\mathbb{R}^{d^{(l)}}\\\\). Các trọng số này được ký hiệu như trên Hình 4. Khi tối ưu một MLP cho một công việc nào đó, chúng ta cần đi tìm các weghts và biases này.\n",
    "\n",
    "Tập hợp các weights và biases lần lượt được ký hiệu là \\\\(\\mathbf{W}\\\\) và \\\\(\\mathbf{b}\\\\).\n",
    "\n",
    "\n",
    "## Activate function\n",
    "\n",
    "### Sigmoid\n",
    "\n",
    "(hay dùng ở các lớp trước lớp cuối cùng (lớp ẩn)\n",
    "\n",
    "$$\\phi_l(a) = \\sigma(a) = \\frac 1 {1+e^{-a}}$$\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/1200px-Logistic-curve.svg.png\" alt=\"sigmoid\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "### Tanh\n",
    "\n",
    "$$\\phi_l(a) = 2\\sigma(a)-1$$\n",
    "\n",
    "<img src=\"https://mathworld.wolfram.com/images/interactive/TanhReal.gif\" alt=\"tanh\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "### ReLU\n",
    "\n",
    "$$\n",
    "\\phi_l(a) = \\max(0, a)$$\n",
    "\n",
    "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2018/10/Line-Plot-of-Rectified-Linear-Activation-for-Negative-and-Positive-Inputs.png\" alt=\"relu\" style=\"width: 500px;\"/>\n",
    "\n",
    "**- Hàm sigmoid hay hàm tanh đều là những hàm có dạng đồ thị đẹp, dễ dàng tính toán đạo hàm. Tuy nhiên 2 hàm này gặp nhược điểm khi đầu vào có trị tuyết đối quá lớn thì gradient của hàm sẽ rất gần với 0, dẫn đến các hệ số gần như không được cập nhật (vanishing gradient)**\n",
    "\n",
    "**- Hàm ReLU có thể khắc phục được nhược điểm trên. Ngoài ra hàm ReLU còn được sử dụng rộng rãi vì tính đơn giản của nó cũng như sự tăng tốc hội tụ của các hàm tối ưu khi sử dụng ReLU được tăng lên đáng kể**\n",
    "\n",
    "## Train neural network model\n",
    "\n",
    "### Backpropagation\n",
    "\n",
    "Phương pháp phổ biến nhất để tối ưu MLP vẫn là Gradient Descent (GD). Để áp dụng GD, chúng ta cần tính được gradient của hàm mất mát theo từng ma trận trọng số \\\\(\\mathbf{W}^{(l)}\\\\) và vector bias \\\\(\\mathbf{b}^{(l)}\\\\). Trước hết, chúng ta cần tính _predicted output_ \\\\( \\mathbf{\\hat{y}}\\\\)  với một input \\\\(\\mathbf{x}\\\\):\n",
    "\\\\[\n",
    "\\begin{eqnarray}\n",
    "\\mathbf{a}^{(0)} &=& \\mathbf{x} \\newline\n",
    "z_{i}^{(l)} &=& \\mathbf{w}_i^{(l)T}\\mathbf{a}^{(l-1)} + b_i^{(l)} \\newline\n",
    "\\mathbf{z}^{(l)}  &=& \\mathbf{W}^{(l)T}\\mathbf{a}^{(l-1)} + \\mathbf{b}^{(l)},~~ l =  1, 2, \\dots, L \\newline\n",
    "\\mathbf{a}^{(l)} &=& f(\\mathbf{z}^{(l)}), ~~ l =  1, 2, \\dots, L \\newline\n",
    "\\mathbf{\\hat{y}} &=& \\mathbf{a}^{(L)}\n",
    "\\end{eqnarray}\n",
    "\\\\]\n",
    "\n",
    "Bước này được gói là **feedforward** vì cách tính toán được thực hiện từ đầu đến cuối của network\n",
    "\n",
    "Giả sử \\\\(J(\\mathbf{W, b, X, Y})\\\\) là một hàm mất mát của bài toán, trong đó \\\\(\\mathbf{W, b}\\\\) là tập hợp tất cả các ma trận trọng số giữa các layers và biases của mỗi layer. \\\\(\\mathbf{X, Y}\\\\) là cặp dữ liệu huấn luyện với mỗi cột tương ứng với một điểm dữ liệu. Để có thể áp dụng các gradient-based methods (mà Gradient Descent là một ví dụ), chúng ta cần tính được:\n",
    "\\\\[\n",
    "\\frac{\\partial J}{\\partial \\mathbf{W}^{(l)}} ; \\frac{\\partial J}{\\partial \\mathbf{b}^{(l)}},~~ l = 1, 2, \\dots, L\n",
    "\\\\]\n",
    "\n",
    "Theo những công thức ở trên, việc tính toán trực tiếp giá trị này là cực kỳ phức tạp vì hàm mất mát không phụ thuộc trực tiếp vào các hệ số. Phương pháp phổ biến nhất được dùng có tên là Backpropagation giúp tính gradient ngược từ layer cuối cùng đến layer đầu tiên. Layer cuối cùng được tính toán trước vì nó gần gũi hơn với predicted outputs và hàm mất mát. Việc tính toán gradient của các layer trước được thực hiện dựa trên một quy tắc quen thuộc có tên là **chain rule**.\n",
    "\n",
    "Đạo hàm của hàm mất mát theo _chỉ một thành phần_ của ma trận trọng số của lớp cuối cùng:\n",
    "\n",
    "\\\\[\n",
    "\\begin{eqnarray}\n",
    "\\frac{\\partial J}{\\partial w_{ij}^{(L)}} &=& \\frac{\\partial J}{\\partial z_j^{(L)}}. \\frac{\\partial z_j^{(L)}}{\\partial w_{ij}^{(L)}} \\newline\n",
    "&=& e_j^{(L)} a_i^{(L-1)}\n",
    "\\end{eqnarray}\n",
    "\\\\]\n",
    "\n",
    "Trong đó \\\\(e_j^{(L)} = \\frac{\\partial J}{\\partial z_j^{(L)}} \\\\) thường là một đại lượng _dễ tính toán_ và \\\\(\\frac{\\partial z_j^{(L)}}{\\partial w_{ij}^{(L)}}  = a_i^{(L-1)}\\\\) vì \\\\(z_j^{(L)} = \\mathbf{w}_j^{(L)T}\\mathbf{a}^{(L-1)} + b_j^{(L)}\\\\).\n",
    "\n",
    "Tương tự như thế, đạo hàm của hàm mất mát theo bias của layer cuối cùng là:\n",
    "\\\\[\n",
    "\\frac{\\partial J}{\\partial b_{j}^{(L)}} = \\frac{\\partial J}{\\partial z_j^{(L)}}. \\frac{\\partial z_j^{(L)}}{\\partial b_{j}^{(L)}} = e_j^{(L)}\n",
    "\\\\]\n",
    "\n",
    "Với đạo hàm theo hệ số ở các lớp \\\\(l\\\\) _thấp hơn_, xem hình dưới đây.\n",
    "<hr>\n",
    "<div class=\"imgcap\">\n",
    " <img src =\"https://machinelearningcoban.com/assets/14_mlp/backpropagation.png\" align = \"center\" width = \"800\">\n",
    "</div>\n",
    "<hr>\n",
    "\n",
    "Dựa vào hính trên, ta có thể tính được:\n",
    "\n",
    "\\\\[\n",
    "\\begin{eqnarray}\n",
    "\\frac{\\partial J}{\\partial w_{ij}^{(l)}} &=& \\frac{\\partial J}{\\partial z_j^{(l)}}. \\frac{\\partial z_j^{(l)}}{\\partial w_{ij}^{(l)}} \\newline\n",
    "&=& e_j^{(l)} a_i^{(l-1)}\n",
    "\\end{eqnarray}\n",
    "\\\\]\n",
    "với:\n",
    "\n",
    "\\\\[\n",
    "\\begin{eqnarray}\n",
    "e_j^{(l)} &=& \\frac{\\partial J}{\\partial z_j^{(l)}} = \\frac{\\partial J}{\\partial a_j^{(l)}} . \\frac{\\partial a_j^{(l)}}{\\partial z_j^{(l)}} \\newline\n",
    "&=& \\left( \\sum_{k = 1}^{d^{(l+1)}} \\frac{\\partial J}{\\partial z_k^{(l+1)}} .\\frac{\\partial z_k^{(l+1)}}{\\partial a_j^{(l)}} \\right) f'(z_j^{(l)}) \\newline\n",
    " &=&\\left( \\sum_{k = 1}^{d^{(l+1)}} e_k^{(l+1)} w_{jk}^{(l+1)} \\right) f'(z_j^{(l)}) \\newline\n",
    " &=&\\left( \\mathbf{w}_{j:}^{(l+1)} \\mathbf{e}^{(l+1)} \\right) f'(z_j^{(l)}) \\newline\n",
    "\\end{eqnarray}\n",
    "\\\\]\n",
    "\n",
    "trong đó \\\\(\\mathbf{e}^{(l+1)} = [e_1^{(l+1)}, e_2^{(l+1)}, ..., e_{d^{(l+1)}}^{(l+1)}]^T \\in \\mathbb{R}^{d^{(l+1)}\\times 1} \\\\) và \\\\(\\mathbf{w}_{j:}^{(l+1)}\\\\) được hiểu là **hàng** thứ \\\\(j\\\\) của ma trận \\\\(\\mathbf{W}^{(l+1)}\\\\) (Chú ý dấu hai chấm, khi không có dấu này, mặc định ký hiệu nó cho vector _cột_).\n",
    "\n",
    "Dấu sigma tính tổng ở hàng thứ hai trong phép tính trên xuất hiện vì \\\\(a_{j}^{(l)}\\\\) _đóng góp_ vào việc tính tất cả các \\\\(z_k^{(l+1)}, k = 1, 2, \\dots, d^{(l+1)}\\\\). Biểu thức đạo hàm ngoài dấu ngoặc lớn là vì \\\\(a_j^{(l)}  = f(z_j^{(l)})\\\\). Tới đây, ta có thể thấy rằng việc activation function có đạo hàm đơn giản sẽ có ích rất nhiều trong việc tính toán.\n",
    "\n",
    "Với cách làm tương tự, bạn đọc có thể suy ra:\n",
    "\\\\[\n",
    "\\frac{\\partial J}{\\partial b_j^{(l)}} = e_j^{(l)}\n",
    "\\\\]\n",
    "\n",
    "Nhận thấy rằng trong các công thức trên đây, việc tính các \\\\(e_j^{(l)}\\\\) đóng một vài trò quan trọng. Hơn nữa, để tính được giá trị này, ta cần tính được các \\\\(e_j^{(l+1)}\\\\). Nói cách khác, ta cần tính _ngược_ các giá trị này từ cuối.\n",
    "\n",
    "<a name=\"-backpropagation-cho-stochastic-gradient-descent\"></a>\n",
    "\n",
    "### Backpropagation cho Stochastic Gradient Descent\n",
    "\n",
    "<a name=\"-dao-ham-theo-tung-he-so-\\\\wij^l-bi^l\\\\\"></a>\n",
    "\n",
    "#### Đạo hàm theo ma trận \\\\(\\mathbf{W}^{(l)}, \\mathbf{b}^{(l)}\\\\)\n",
    "\n",
    "Đặt \\\\(\\mathbf{e}^{(l)} = [e_1^{(l)}, e_2^{(l)}, ..., e_{d^{(l)}}^{(l)}]^T \\in \\mathbb{R}^{d^{(l)}\\times 1} \\\\). Ta sẽ có quy tắc tính như sau:\n",
    "\n",
    "<hr>\n",
    "\n",
    "1. Bước feedforward: Với 1 giá trị đầu vào \\\\(\\mathbf{x}\\\\), tính giá trị đầu ra của network, trong quá trình tính toán, lưu lại các _activation_ \\\\(\\mathbf{a}^{(l)}\\\\) tại mỗi layer.\n",
    "\n",
    "2. Với output layer, tính: \\\\[\\mathbf{e}^{(L)} = \\frac{\\partial J}{\\partial \\mathbf{z}^{(L)}}\\\\]\n",
    "\n",
    "3. Từ đó suy ra:\n",
    "\\\\[\n",
    "\\begin{eqnarray}\n",
    "\\frac{\\partial J}{\\partial \\mathbf{W}^{(L)}} &=& \\mathbf{a}^{(L-1)}\\mathbf{e}^{(L)T}\\newline\n",
    "\\frac{\\partial J}{\\partial \\mathbf{b}^{(L)}} &=&  \\mathbf{e}^{(L)}\n",
    "\\end{eqnarray}\n",
    "\\\\]\n",
    "4. Với \\\\(l = L-1, L-2, ..., 1\\\\), tính:\n",
    "\\\\[\n",
    "\\mathbf{e}^{(l)} = \\left( \\mathbf{W}^{(l+1)} \\mathbf{e}^{(l+1)} \\right) \\odot f'(\\mathbf{z}^{(l)})\n",
    "\\\\]\n",
    "\n",
    "trong đó \\\\(\\odot\\\\) là *element-wise product* tức lấy từng thành phần của hai vector nhân với nhau để được vector kết quả.\n",
    "\n",
    "5. Cập nhật đạo hàm cho ma trận trọng số và vector biases:\n",
    "\\\\[\n",
    "\\begin{eqnarray}\n",
    "\\frac{\\partial J}{\\partial \\mathbf{W}^{(l)}} &=& \\mathbf{a}^{(l-1)}\\mathbf{e}^{(l)T}\\newline\n",
    "\\frac{\\partial J}{\\partial \\mathbf{b}^{(l)}} &=& \\mathbf{e}^{(l)}\n",
    "\\end{eqnarray}\n",
    "\\\\]\n",
    "\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_kernel",
   "language": "python",
   "name": "jupyter_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
