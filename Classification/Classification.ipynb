{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f3602bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T02:03:43.152519Z",
     "start_time": "2023-10-03T02:03:39.895902Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, f_classif, chi2, VarianceThreshold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SMOTE, SVMSMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c629df5f",
   "metadata": {},
   "source": [
    "# Dataset Description\n",
    "\n",
    "You are provided with an anonymized dataset containing a large number of numeric variables. The \"TARGET\" column is the variable to predict. It equals one for unsatisfied customers and 0 for satisfied customers.\n",
    "\n",
    "The task is to predict the probability that each customer in the test set is an unsatisfied customer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8b5978",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac949ee9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T02:03:47.193945Z",
     "start_time": "2023-10-03T02:03:43.155519Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f352713c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T02:03:47.286945Z",
     "start_time": "2023-10-03T02:03:47.197939Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76015</th>\n",
       "      <td>151829</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60926.490000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76016</th>\n",
       "      <td>151830</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118634.520000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76017</th>\n",
       "      <td>151835</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74028.150000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76018</th>\n",
       "      <td>151836</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84278.160000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76019</th>\n",
       "      <td>151838</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76020 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0           1     2     23                 0.0                      0.0   \n",
       "1           3     2     34                 0.0                      0.0   \n",
       "2           4     2     23                 0.0                      0.0   \n",
       "3           8     2     37                 0.0                    195.0   \n",
       "4          10     2     39                 0.0                      0.0   \n",
       "...       ...   ...    ...                 ...                      ...   \n",
       "76015  151829     2     48                 0.0                      0.0   \n",
       "76016  151830     2     39                 0.0                      0.0   \n",
       "76017  151835     2     23                 0.0                      0.0   \n",
       "76018  151836     2     25                 0.0                      0.0   \n",
       "76019  151838     2     46                 0.0                      0.0   \n",
       "\n",
       "       imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  \\\n",
       "0                          0.0                      0.0   \n",
       "1                          0.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                        195.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "76015                      0.0                      0.0   \n",
       "76016                      0.0                      0.0   \n",
       "76017                      0.0                      0.0   \n",
       "76018                      0.0                      0.0   \n",
       "76019                      0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_comer_ult3  imp_op_var40_efect_ult1  \\\n",
       "0                          0.0                      0.0   \n",
       "1                          0.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          0.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "76015                      0.0                      0.0   \n",
       "76016                      0.0                      0.0   \n",
       "76017                      0.0                      0.0   \n",
       "76018                      0.0                      0.0   \n",
       "76019                      0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_efect_ult3  ...  saldo_medio_var33_hace2  \\\n",
       "0                          0.0  ...                      0.0   \n",
       "1                          0.0  ...                      0.0   \n",
       "2                          0.0  ...                      0.0   \n",
       "3                          0.0  ...                      0.0   \n",
       "4                          0.0  ...                      0.0   \n",
       "...                        ...  ...                      ...   \n",
       "76015                      0.0  ...                      0.0   \n",
       "76016                      0.0  ...                      0.0   \n",
       "76017                      0.0  ...                      0.0   \n",
       "76018                      0.0  ...                      0.0   \n",
       "76019                      0.0  ...                      0.0   \n",
       "\n",
       "       saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                          0.0                     0.0   \n",
       "1                          0.0                     0.0   \n",
       "2                          0.0                     0.0   \n",
       "3                          0.0                     0.0   \n",
       "4                          0.0                     0.0   \n",
       "...                        ...                     ...   \n",
       "76015                      0.0                     0.0   \n",
       "76016                      0.0                     0.0   \n",
       "76017                      0.0                     0.0   \n",
       "76018                      0.0                     0.0   \n",
       "76019                      0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var33_ult3  saldo_medio_var44_hace2  \\\n",
       "0                         0.0                      0.0   \n",
       "1                         0.0                      0.0   \n",
       "2                         0.0                      0.0   \n",
       "3                         0.0                      0.0   \n",
       "4                         0.0                      0.0   \n",
       "...                       ...                      ...   \n",
       "76015                     0.0                      0.0   \n",
       "76016                     0.0                      0.0   \n",
       "76017                     0.0                      0.0   \n",
       "76018                     0.0                      0.0   \n",
       "76019                     0.0                      0.0   \n",
       "\n",
       "       saldo_medio_var44_hace3  saldo_medio_var44_ult1  \\\n",
       "0                          0.0                     0.0   \n",
       "1                          0.0                     0.0   \n",
       "2                          0.0                     0.0   \n",
       "3                          0.0                     0.0   \n",
       "4                          0.0                     0.0   \n",
       "...                        ...                     ...   \n",
       "76015                      0.0                     0.0   \n",
       "76016                      0.0                     0.0   \n",
       "76017                      0.0                     0.0   \n",
       "76018                      0.0                     0.0   \n",
       "76019                      0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var44_ult3          var38  TARGET  \n",
       "0                         0.0   39205.170000       0  \n",
       "1                         0.0   49278.030000       0  \n",
       "2                         0.0   67333.770000       0  \n",
       "3                         0.0   64007.970000       0  \n",
       "4                         0.0  117310.979016       0  \n",
       "...                       ...            ...     ...  \n",
       "76015                     0.0   60926.490000       0  \n",
       "76016                     0.0  118634.520000       0  \n",
       "76017                     0.0   74028.150000       0  \n",
       "76018                     0.0   84278.160000       0  \n",
       "76019                     0.0  117310.979016       0  \n",
       "\n",
       "[76020 rows x 371 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c53f947",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T02:03:48.380945Z",
     "start_time": "2023-10-03T02:03:47.290925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75964.050723</td>\n",
       "      <td>-1523.199277</td>\n",
       "      <td>33.212865</td>\n",
       "      <td>86.208265</td>\n",
       "      <td>72.363067</td>\n",
       "      <td>119.529632</td>\n",
       "      <td>3.559130</td>\n",
       "      <td>6.472698</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>...</td>\n",
       "      <td>7.935824</td>\n",
       "      <td>1.365146</td>\n",
       "      <td>12.215580</td>\n",
       "      <td>8.784074</td>\n",
       "      <td>31.505324</td>\n",
       "      <td>1.858575</td>\n",
       "      <td>76.026165</td>\n",
       "      <td>56.614351</td>\n",
       "      <td>1.172358e+05</td>\n",
       "      <td>0.039569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43781.947379</td>\n",
       "      <td>39033.462364</td>\n",
       "      <td>12.956486</td>\n",
       "      <td>1614.757313</td>\n",
       "      <td>339.315831</td>\n",
       "      <td>546.266294</td>\n",
       "      <td>93.155749</td>\n",
       "      <td>153.737066</td>\n",
       "      <td>30.604864</td>\n",
       "      <td>36.513513</td>\n",
       "      <td>...</td>\n",
       "      <td>455.887218</td>\n",
       "      <td>113.959637</td>\n",
       "      <td>783.207399</td>\n",
       "      <td>538.439211</td>\n",
       "      <td>2013.125393</td>\n",
       "      <td>147.786584</td>\n",
       "      <td>4040.337842</td>\n",
       "      <td>2852.579397</td>\n",
       "      <td>1.826646e+05</td>\n",
       "      <td>0.194945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163750e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38104.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.787061e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76043.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.064092e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113748.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187563e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151838.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>210000.000000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>21024.810000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>11073.570000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50003.880000</td>\n",
       "      <td>20385.720000</td>\n",
       "      <td>138831.630000</td>\n",
       "      <td>91778.730000</td>\n",
       "      <td>438329.220000</td>\n",
       "      <td>24650.010000</td>\n",
       "      <td>681462.900000</td>\n",
       "      <td>397884.300000</td>\n",
       "      <td>2.203474e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID           var3         var15  imp_ent_var16_ult1  \\\n",
       "count   76020.000000   76020.000000  76020.000000        76020.000000   \n",
       "mean    75964.050723   -1523.199277     33.212865           86.208265   \n",
       "std     43781.947379   39033.462364     12.956486         1614.757313   \n",
       "min         1.000000 -999999.000000      5.000000            0.000000   \n",
       "25%     38104.750000       2.000000     23.000000            0.000000   \n",
       "50%     76043.000000       2.000000     28.000000            0.000000   \n",
       "75%    113748.750000       2.000000     40.000000            0.000000   \n",
       "max    151838.000000     238.000000    105.000000       210000.000000   \n",
       "\n",
       "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 72.363067               119.529632   \n",
       "std                 339.315831               546.266294   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             21024.810000   \n",
       "\n",
       "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  3.559130                 6.472698   \n",
       "std                  93.155749               153.737066   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                8237.820000             11073.570000   \n",
       "\n",
       "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "count             76020.000000             76020.000000  ...   \n",
       "mean                  0.412946                 0.567352  ...   \n",
       "std                  30.604864                36.513513  ...   \n",
       "min                   0.000000                 0.000000  ...   \n",
       "25%                   0.000000                 0.000000  ...   \n",
       "50%                   0.000000                 0.000000  ...   \n",
       "75%                   0.000000                 0.000000  ...   \n",
       "max                6600.000000              6600.000000  ...   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  7.935824                 1.365146   \n",
       "std                 455.887218               113.959637   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               50003.880000             20385.720000   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "count            76020.000000            76020.000000   \n",
       "mean                12.215580                8.784074   \n",
       "std                783.207399              538.439211   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.000000                0.000000   \n",
       "50%                  0.000000                0.000000   \n",
       "75%                  0.000000                0.000000   \n",
       "max             138831.630000            91778.730000   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 31.505324                 1.858575   \n",
       "std                2013.125393               147.786584   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max              438329.220000             24650.010000   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3         var38  \\\n",
       "count            76020.000000            76020.000000  7.602000e+04   \n",
       "mean                76.026165               56.614351  1.172358e+05   \n",
       "std               4040.337842             2852.579397  1.826646e+05   \n",
       "min                  0.000000                0.000000  5.163750e+03   \n",
       "25%                  0.000000                0.000000  6.787061e+04   \n",
       "50%                  0.000000                0.000000  1.064092e+05   \n",
       "75%                  0.000000                0.000000  1.187563e+05   \n",
       "max             681462.900000           397884.300000  2.203474e+07   \n",
       "\n",
       "             TARGET  \n",
       "count  76020.000000  \n",
       "mean       0.039569  \n",
       "std        0.194945  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 371 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17a8cbad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T02:03:48.460944Z",
     "start_time": "2023-10-03T02:03:48.382939Z"
    }
   },
   "outputs": [],
   "source": [
    "data = train_data.drop(columns=['TARGET', 'ID'], axis=1)\n",
    "target = train_data['TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5babc84e",
   "metadata": {},
   "source": [
    "**Replace value -999999 in var 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6988c823",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T02:03:48.538947Z",
     "start_time": "2023-10-03T02:03:48.464940Z"
    }
   },
   "outputs": [],
   "source": [
    "data.var3 = data.var3.replace(-999999, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e90520",
   "metadata": {},
   "source": [
    "# Split train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c56df6bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T02:03:48.554940Z",
     "start_time": "2023-10-03T02:03:48.541945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    76020.000000\n",
       "mean         2.716483\n",
       "std          9.447971\n",
       "min          0.000000\n",
       "25%          2.000000\n",
       "50%          2.000000\n",
       "75%          2.000000\n",
       "max        238.000000\n",
       "Name: var3, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.var3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6389ea4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T02:03:48.932944Z",
     "start_time": "2023-10-03T02:03:48.558939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53214, 369) (22806, 369)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=16)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d4fe75c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T02:03:48.948939Z",
     "start_time": "2023-10-03T02:03:48.934943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target count y_train:\n",
      "0    51107\n",
      "1     2107\n",
      "Name: TARGET, dtype: int64\n",
      "\n",
      "Target count y_test:\n",
      "0    21905\n",
      "1      901\n",
      "Name: TARGET, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Target count y_train:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nTarget count y_test:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a5c0d2",
   "metadata": {},
   "source": [
    "**Drop constant column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df6884d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T02:03:49.203940Z",
     "start_time": "2023-10-03T02:03:48.954938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ind_var2_0', 'ind_var2', 'ind_var18_0', 'ind_var18', 'ind_var27_0',\n",
       "       'ind_var28_0', 'ind_var28', 'ind_var27', 'ind_var41', 'ind_var46_0',\n",
       "       'ind_var46', 'num_var18_0', 'num_var18', 'num_var27_0', 'num_var28_0',\n",
       "       'num_var28', 'num_var27', 'num_var41', 'num_var46_0', 'num_var46',\n",
       "       'saldo_var18', 'saldo_var28', 'saldo_var27', 'saldo_var41',\n",
       "       'saldo_var46', 'delta_imp_amort_var18_1y3', 'delta_imp_reemb_var33_1y3',\n",
       "       'delta_num_reemb_var33_1y3', 'imp_amort_var18_hace3',\n",
       "       'imp_amort_var18_ult1', 'imp_amort_var34_hace3',\n",
       "       'imp_reemb_var13_hace3', 'imp_reemb_var33_hace3',\n",
       "       'imp_reemb_var33_ult1', 'imp_trasp_var17_out_hace3',\n",
       "       'imp_trasp_var33_out_hace3', 'num_var2_0_ult1', 'num_var2_ult1',\n",
       "       'num_reemb_var13_hace3', 'num_reemb_var33_hace3',\n",
       "       'num_reemb_var33_ult1', 'num_trasp_var17_out_hace3',\n",
       "       'num_trasp_var33_out_hace3', 'saldo_var2_ult1',\n",
       "       'saldo_medio_var13_medio_hace3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_train = X_train.std()\n",
    "drop_col = std_train[std_train == 0].index\n",
    "drop_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69375d73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T02:03:49.330942Z",
     "start_time": "2023-10-03T02:03:49.209945Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53214, 324) (22806, 324)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.drop(columns=drop_col, axis=1)\n",
    "X_test = X_test.drop(columns=drop_col, axis=1)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6db461e",
   "metadata": {},
   "source": [
    "**Drop duplicate columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ddc2b4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T02:03:49.884946Z",
     "start_time": "2023-10-03T02:03:49.332940Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def duplicate_columns(frame):\n",
    "    groups = frame.columns.to_series().groupby(frame.dtypes).groups\n",
    "    dups = []\n",
    "    for t, v in groups.items():\n",
    "        dcols = frame[v].to_dict(orient=\"list\")\n",
    "\n",
    "        vs = list(dcols.values())\n",
    "        ks = list(dcols.keys())\n",
    "        lvs = len(vs)\n",
    "\n",
    "        for i in range(lvs):\n",
    "            for j in range(i+1,lvs):\n",
    "                if vs[i] == vs[j]: \n",
    "                    dups.append(ks[i])\n",
    "                    break\n",
    "\n",
    "    return dups\n",
    "\n",
    "dup_col = duplicate_columns(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c654baa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T02:03:49.980945Z",
     "start_time": "2023-10-03T02:03:49.887938Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=dup_col, axis=1)\n",
    "X_test = X_test.drop(columns=dup_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6b5326b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T02:03:50.044943Z",
     "start_time": "2023-10-03T02:03:49.983938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>imp_op_var40_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var29_ult3</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6363</th>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33746.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28436</th>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150825.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6944</th>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18699</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21200</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486302.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47519</th>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101840.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16765</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62133.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37316</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>266126.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50497</th>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62214.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260105.490000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53214 rows × 298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "6363      2     62                 0.0                      0.0   \n",
       "28436     2     33                 0.0                      0.0   \n",
       "6944      2     86                 0.0                      0.0   \n",
       "18699     2     24                 0.0                      0.0   \n",
       "21200     2     30                 0.0                      0.0   \n",
       "...     ...    ...                 ...                      ...   \n",
       "47519     2     36                 0.0                      0.0   \n",
       "16765     2     23                 0.0                      0.0   \n",
       "37316     2     22                 0.0                      0.0   \n",
       "50497     2     28                 0.0                      0.0   \n",
       "2169      2     24                 0.0                      0.0   \n",
       "\n",
       "       imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  \\\n",
       "6363                      0.00                      0.0   \n",
       "28436                    96.75                      0.0   \n",
       "6944                      0.00                      0.0   \n",
       "18699                     0.00                      0.0   \n",
       "21200                     0.00                      0.0   \n",
       "...                        ...                      ...   \n",
       "47519                     0.00                      0.0   \n",
       "16765                     0.00                      0.0   \n",
       "37316                     0.00                      0.0   \n",
       "50497                     0.00                      0.0   \n",
       "2169                      0.00                      0.0   \n",
       "\n",
       "       imp_op_var40_comer_ult3  imp_op_var40_efect_ult1  \\\n",
       "6363                       0.0                      0.0   \n",
       "28436                      0.0                      0.0   \n",
       "6944                       0.0                      0.0   \n",
       "18699                      0.0                      0.0   \n",
       "21200                      0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "47519                      0.0                      0.0   \n",
       "16765                      0.0                      0.0   \n",
       "37316                      0.0                      0.0   \n",
       "50497                      0.0                      0.0   \n",
       "2169                       0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_efect_ult3  imp_op_var40_ult1  ...  \\\n",
       "6363                       0.0                0.0  ...   \n",
       "28436                      0.0                0.0  ...   \n",
       "6944                       0.0                0.0  ...   \n",
       "18699                      0.0                0.0  ...   \n",
       "21200                      0.0                0.0  ...   \n",
       "...                        ...                ...  ...   \n",
       "47519                      0.0                0.0  ...   \n",
       "16765                      0.0                0.0  ...   \n",
       "37316                      0.0                0.0  ...   \n",
       "50497                      0.0                0.0  ...   \n",
       "2169                       0.0                0.0  ...   \n",
       "\n",
       "       saldo_medio_var29_ult3  saldo_medio_var33_hace2  \\\n",
       "6363                      0.0                      0.0   \n",
       "28436                     0.0                      0.0   \n",
       "6944                      0.0                      0.0   \n",
       "18699                     0.0                      0.0   \n",
       "21200                     0.0                      0.0   \n",
       "...                       ...                      ...   \n",
       "47519                     0.0                      0.0   \n",
       "16765                     0.0                      0.0   \n",
       "37316                     0.0                      0.0   \n",
       "50497                     0.0                      0.0   \n",
       "2169                      0.0                      0.0   \n",
       "\n",
       "       saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "6363                       0.0                     0.0   \n",
       "28436                      0.0                     0.0   \n",
       "6944                       0.0                     0.0   \n",
       "18699                      0.0                     0.0   \n",
       "21200                      0.0                     0.0   \n",
       "...                        ...                     ...   \n",
       "47519                      0.0                     0.0   \n",
       "16765                      0.0                     0.0   \n",
       "37316                      0.0                     0.0   \n",
       "50497                      0.0                     0.0   \n",
       "2169                       0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var33_ult3  saldo_medio_var44_hace2  \\\n",
       "6363                      0.0                      0.0   \n",
       "28436                     0.0                      0.0   \n",
       "6944                      0.0                      0.0   \n",
       "18699                     0.0                      0.0   \n",
       "21200                     0.0                      0.0   \n",
       "...                       ...                      ...   \n",
       "47519                     0.0                      0.0   \n",
       "16765                     0.0                      0.0   \n",
       "37316                     0.0                      0.0   \n",
       "50497                     0.0                      0.0   \n",
       "2169                      0.0                      0.0   \n",
       "\n",
       "       saldo_medio_var44_hace3  saldo_medio_var44_ult1  \\\n",
       "6363                       0.0                     0.0   \n",
       "28436                      0.0                     0.0   \n",
       "6944                       0.0                     0.0   \n",
       "18699                      0.0                     0.0   \n",
       "21200                      0.0                     0.0   \n",
       "...                        ...                     ...   \n",
       "47519                      0.0                     0.0   \n",
       "16765                      0.0                     0.0   \n",
       "37316                      0.0                     0.0   \n",
       "50497                      0.0                     0.0   \n",
       "2169                       0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var44_ult3          var38  \n",
       "6363                      0.0   33746.310000  \n",
       "28436                     0.0  150825.420000  \n",
       "6944                      0.0  117310.979016  \n",
       "18699                     0.0  117310.979016  \n",
       "21200                     0.0  486302.430000  \n",
       "...                       ...            ...  \n",
       "47519                     0.0  101840.760000  \n",
       "16765                     0.0   62133.270000  \n",
       "37316                     0.0  266126.340000  \n",
       "50497                     0.0   62214.990000  \n",
       "2169                      0.0  260105.490000  \n",
       "\n",
       "[53214 rows x 298 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faef79ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad121975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2504597",
   "metadata": {},
   "source": [
    "**Drop quasi-constant feature use Variance Threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b82b383",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T02:03:50.456943Z",
     "start_time": "2023-10-03T02:03:50.047923Z"
    }
   },
   "outputs": [],
   "source": [
    "thres = 0.002\n",
    "sel = VarianceThreshold(threshold=thres)\n",
    "sel.fit(X_train)\n",
    "\n",
    "X_train_sel = sel.transform(X_train)\n",
    "X_test_sel = sel.transform(X_test)\n",
    "\n",
    "selected_columns = X_train.columns[sel.get_support(indices=True)]\n",
    "\n",
    "X_train = pd.DataFrame(X_train_sel, columns=selected_columns)\n",
    "X_test = pd.DataFrame(X_test_sel, columns=selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5c19deb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T02:03:51.264948Z",
     "start_time": "2023-10-03T02:03:50.459941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>imp_op_var40_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var29_ult3</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53214.000000</td>\n",
       "      <td>53214.000000</td>\n",
       "      <td>53214.000000</td>\n",
       "      <td>53214.000000</td>\n",
       "      <td>53214.000000</td>\n",
       "      <td>53214.000000</td>\n",
       "      <td>53214.000000</td>\n",
       "      <td>53214.000000</td>\n",
       "      <td>53214.000000</td>\n",
       "      <td>53214.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>53214.000000</td>\n",
       "      <td>53214.000000</td>\n",
       "      <td>53214.000000</td>\n",
       "      <td>53214.000000</td>\n",
       "      <td>53214.000000</td>\n",
       "      <td>53214.000000</td>\n",
       "      <td>53214.000000</td>\n",
       "      <td>53214.000000</td>\n",
       "      <td>53214.000000</td>\n",
       "      <td>5.321400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.707088</td>\n",
       "      <td>33.183636</td>\n",
       "      <td>84.166756</td>\n",
       "      <td>71.916898</td>\n",
       "      <td>119.059727</td>\n",
       "      <td>3.895629</td>\n",
       "      <td>6.876538</td>\n",
       "      <td>0.503707</td>\n",
       "      <td>0.703992</td>\n",
       "      <td>3.683849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266614</td>\n",
       "      <td>5.931756</td>\n",
       "      <td>1.117222</td>\n",
       "      <td>9.226325</td>\n",
       "      <td>6.377532</td>\n",
       "      <td>35.295396</td>\n",
       "      <td>2.452425</td>\n",
       "      <td>85.785084</td>\n",
       "      <td>64.177261</td>\n",
       "      <td>1.173784e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.416571</td>\n",
       "      <td>12.947405</td>\n",
       "      <td>1463.713898</td>\n",
       "      <td>344.447465</td>\n",
       "      <td>556.044598</td>\n",
       "      <td>102.497931</td>\n",
       "      <td>161.535245</td>\n",
       "      <td>35.749521</td>\n",
       "      <td>42.801051</td>\n",
       "      <td>108.521963</td>\n",
       "      <td>...</td>\n",
       "      <td>38.103020</td>\n",
       "      <td>363.526971</td>\n",
       "      <td>87.387975</td>\n",
       "      <td>559.567481</td>\n",
       "      <td>372.086199</td>\n",
       "      <td>2282.510651</td>\n",
       "      <td>173.842642</td>\n",
       "      <td>4559.309473</td>\n",
       "      <td>3231.356683</td>\n",
       "      <td>1.907239e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163750e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.791206e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.065234e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.185470e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>235.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>135000.000000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>21024.810000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>10351.950000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>...</td>\n",
       "      <td>7331.340000</td>\n",
       "      <td>43406.220000</td>\n",
       "      <td>11047.770000</td>\n",
       "      <td>63317.190000</td>\n",
       "      <td>42767.160000</td>\n",
       "      <td>438329.220000</td>\n",
       "      <td>24650.010000</td>\n",
       "      <td>681462.900000</td>\n",
       "      <td>397884.300000</td>\n",
       "      <td>2.203474e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 267 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               var3         var15  imp_ent_var16_ult1  \\\n",
       "count  53214.000000  53214.000000        53214.000000   \n",
       "mean       2.707088     33.183636           84.166756   \n",
       "std        9.416571     12.947405         1463.713898   \n",
       "min        0.000000      5.000000            0.000000   \n",
       "25%        2.000000     23.000000            0.000000   \n",
       "50%        2.000000     27.000000            0.000000   \n",
       "75%        2.000000     39.000000            0.000000   \n",
       "max      235.000000    105.000000       135000.000000   \n",
       "\n",
       "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
       "count             53214.000000             53214.000000   \n",
       "mean                 71.916898               119.059727   \n",
       "std                 344.447465               556.044598   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             21024.810000   \n",
       "\n",
       "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "count             53214.000000             53214.000000   \n",
       "mean                  3.895629                 6.876538   \n",
       "std                 102.497931               161.535245   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                8237.820000             10351.950000   \n",
       "\n",
       "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  imp_op_var40_ult1  \\\n",
       "count             53214.000000             53214.000000       53214.000000   \n",
       "mean                  0.503707                 0.703992           3.683849   \n",
       "std                  35.749521                42.801051         108.521963   \n",
       "min                   0.000000                 0.000000           0.000000   \n",
       "25%                   0.000000                 0.000000           0.000000   \n",
       "50%                   0.000000                 0.000000           0.000000   \n",
       "75%                   0.000000                 0.000000           0.000000   \n",
       "max                6600.000000              6600.000000        8237.820000   \n",
       "\n",
       "       ...  saldo_medio_var29_ult3  saldo_medio_var33_hace2  \\\n",
       "count  ...            53214.000000             53214.000000   \n",
       "mean   ...                0.266614                 5.931756   \n",
       "std    ...               38.103020               363.526971   \n",
       "min    ...                0.000000                 0.000000   \n",
       "25%    ...                0.000000                 0.000000   \n",
       "50%    ...                0.000000                 0.000000   \n",
       "75%    ...                0.000000                 0.000000   \n",
       "max    ...             7331.340000             43406.220000   \n",
       "\n",
       "       saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "count             53214.000000            53214.000000   \n",
       "mean                  1.117222                9.226325   \n",
       "std                  87.387975              559.567481   \n",
       "min                   0.000000                0.000000   \n",
       "25%                   0.000000                0.000000   \n",
       "50%                   0.000000                0.000000   \n",
       "75%                   0.000000                0.000000   \n",
       "max               11047.770000            63317.190000   \n",
       "\n",
       "       saldo_medio_var33_ult3  saldo_medio_var44_hace2  \\\n",
       "count            53214.000000             53214.000000   \n",
       "mean                 6.377532                35.295396   \n",
       "std                372.086199              2282.510651   \n",
       "min                  0.000000                 0.000000   \n",
       "25%                  0.000000                 0.000000   \n",
       "50%                  0.000000                 0.000000   \n",
       "75%                  0.000000                 0.000000   \n",
       "max              42767.160000            438329.220000   \n",
       "\n",
       "       saldo_medio_var44_hace3  saldo_medio_var44_ult1  \\\n",
       "count             53214.000000            53214.000000   \n",
       "mean                  2.452425               85.785084   \n",
       "std                 173.842642             4559.309473   \n",
       "min                   0.000000                0.000000   \n",
       "25%                   0.000000                0.000000   \n",
       "50%                   0.000000                0.000000   \n",
       "75%                   0.000000                0.000000   \n",
       "max               24650.010000           681462.900000   \n",
       "\n",
       "       saldo_medio_var44_ult3         var38  \n",
       "count            53214.000000  5.321400e+04  \n",
       "mean                64.177261  1.173784e+05  \n",
       "std               3231.356683  1.907239e+05  \n",
       "min                  0.000000  5.163750e+03  \n",
       "25%                  0.000000  6.791206e+04  \n",
       "50%                  0.000000  1.065234e+05  \n",
       "75%                  0.000000  1.185470e+05  \n",
       "max             397884.300000  2.203474e+07  \n",
       "\n",
       "[8 rows x 267 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdb28f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T02:50:01.388100Z",
     "start_time": "2023-09-19T02:50:01.371091Z"
    }
   },
   "source": [
    "**Fit + Evaluate model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5cfe0f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T02:03:51.280949Z",
     "start_time": "2023-10-03T02:03:51.267941Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_score(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test,pred).round(3)\n",
    "    recall = recall_score(y_test,pred).round(3)\n",
    "    F1_score = f1_score(y_test,pred).round(3)\n",
    "    auc = roc_auc_score(y_test, pred).round(3)\n",
    "    \n",
    "    rp = classification_report(y_test, pred)\n",
    "    \n",
    "    return precision, recall, F1_score, auc, rp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b784648",
   "metadata": {},
   "source": [
    "**Save model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87f28c86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T02:03:51.295950Z",
     "start_time": "2023-10-03T02:03:51.283941Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use to save the best model to submits on Kaggle\n",
    "def save_model(model, sc, num_features):\n",
    "    model_name = model.__class__.__name__\n",
    "    \n",
    "    if sc == 0:\n",
    "        scaler = \"noScale\"\n",
    "    else:\n",
    "        scaler = sc.__class__.__name__\n",
    "    \n",
    "    model_path = f'model/{model_name}'\n",
    "    \n",
    "    filename = f\"{model_path}/{model_name}_{scaler}_{num_features}.pkl\" \n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c980fa5",
   "metadata": {},
   "source": [
    "**Scaler + Feature selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69e233e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T02:03:51.326920Z",
     "start_time": "2023-10-03T02:03:51.297941Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = [StandardScaler(), MinMaxScaler(), RobustScaler()]\n",
    "percentile = [90, 85, 80, 70, 60, 50]\n",
    "\n",
    "def eval_scale(model, detail, X_train, y_train, X_test, y_test, table):\n",
    "    for sc in scaler:\n",
    "        _X_train = sc.fit_transform(X_train)\n",
    "        _X_test = sc.transform(X_test)\n",
    "        \n",
    "        num_features = _X_train.shape[1]\n",
    "            \n",
    "        precision, recall, F1_score, auc, rp = model_score(model, _X_train, y_train, _X_test, y_test)\n",
    "        \n",
    "        print(f\"{sc.__class__.__name__}:\\n\")\n",
    "        print(rp)\n",
    "        print('\\n================================')\n",
    "        \n",
    "        save_model(model, sc, num_features)\n",
    "            \n",
    "        table.loc[table.shape[0]] = [model.__class__.__name__,\n",
    "                                         detail,\n",
    "                                         sc.__class__.__name__, '-',\n",
    "                                         num_features, \n",
    "                                         precision, \n",
    "                                         recall, \n",
    "                                         F1_score, \n",
    "                                         auc]\n",
    "\n",
    "#def eval_chi2(model, detail, X_train, X_test, y_train, y_test, table):\n",
    "    \n",
    "    \n",
    "def eval_fclassif(model, detail, X_train, y_train, X_test, y_test, table):\n",
    "    for p in percentile:\n",
    "        for sc in scaler:\n",
    "            _X_train = sc.fit_transform(X_train)\n",
    "            _X_test = sc.transform(X_test)\n",
    "                  \n",
    "            fc = SelectPercentile(f_classif, percentile=p)\n",
    "            fc.fit(_X_train, y_train)\n",
    "\n",
    "            _X_train = fc.transform(_X_train)\n",
    "            _X_test = fc.transform(_X_test)\n",
    "            \n",
    "            num_features = _X_train.shape[1]\n",
    "            \n",
    "            precision, recall, F1_score, auc, rp = model_score(model, _X_train, y_train, _X_test, y_test)\n",
    "            \n",
    "            print(f\"{sc.__class__.__name__}, select {num_features} features (percentile = {p}%):\\n\")\n",
    "            print(rp)\n",
    "            print('\\n================================')\n",
    "            \n",
    "            save_model(model, sc, num_features)\n",
    "            \n",
    "            table.loc[table.shape[0]] = [model.__class__.__name__,\n",
    "                                         detail,\n",
    "                                         sc.__class__.__name__, 'UFS(f_classif)',\n",
    "                                         f\"{num_features} ({p}%)\",\n",
    "                                         precision, \n",
    "                                         recall, \n",
    "                                         F1_score, \n",
    "                                         auc]\n",
    "\n",
    "#def eval_rfecv(model, detail, X_train, y_train, X_test, y_test, table):\n",
    "    \n",
    "            \n",
    "def eval_all(model, detail, X_train, y_train, X_test, y_test, table):\n",
    "    \n",
    "    # No scale + No use UFS\n",
    "    precision, recall, F1_score, auc, rp= model_score(model, X_train, y_train, X_test, y_test)\n",
    "    num_features = X_train.shape[1]\n",
    "    save_model(model, 0, num_features)\n",
    "    table.loc[table.shape[0]] = [model.__class__.__name__,\n",
    "                                         detail,\n",
    "                                         '-', '-',\n",
    "                                         num_features, \n",
    "                                         precision, \n",
    "                                         recall, \n",
    "                                         F1_score, \n",
    "                                         auc]\n",
    "    # Only scaler\n",
    "    eval_scale(model, detail, X_train, y_train, X_test, y_test, table)\n",
    "    \n",
    "    # Univariate feature selection + scalers\n",
    "    eval_fclassif(model, detail, X_train, y_train, X_test, y_test, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "467fd8e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T02:03:51.342903Z",
     "start_time": "2023-10-03T02:03:51.329930Z"
    }
   },
   "outputs": [],
   "source": [
    "base_evaluation_table = pd.DataFrame({'Model': [],\n",
    "                           'Details':[],\n",
    "                           'Scaler':[],\n",
    "                           'Feature selection':[],\n",
    "                           'No. features': [],\n",
    "                           'Precision':[],\n",
    "                           'Recall':[],\n",
    "                           'F1-score':[], \n",
    "                           'AUC':[]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a995bf6d",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "24004179",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T09:07:33.061154Z",
     "start_time": "2023-09-26T09:07:33.038959Z"
    }
   },
   "outputs": [],
   "source": [
    "logreg_evaluation = base_evaluation_table.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "022a53d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T03:31:16.972454Z",
     "start_time": "2023-09-26T03:04:43.008414Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.82     21905\n",
      "           1       0.09      0.76      0.17       901\n",
      "\n",
      "    accuracy                           0.70     22806\n",
      "   macro avg       0.54      0.73      0.49     22806\n",
      "weighted avg       0.95      0.70      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.76      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.73      0.49     22806\n",
      "weighted avg       0.95      0.69      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.50      0.66     21905\n",
      "           1       0.06      0.81      0.12       901\n",
      "\n",
      "    accuracy                           0.51     22806\n",
      "   macro avg       0.52      0.65      0.39     22806\n",
      "weighted avg       0.95      0.51      0.64     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 240 features (percentile = 90%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.82     21905\n",
      "           1       0.09      0.76      0.17       901\n",
      "\n",
      "    accuracy                           0.70     22806\n",
      "   macro avg       0.54      0.73      0.49     22806\n",
      "weighted avg       0.95      0.70      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 240 features (percentile = 90%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.76      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.73      0.49     22806\n",
      "weighted avg       0.95      0.69      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 240 features (percentile = 90%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.52      0.68     21905\n",
      "           1       0.06      0.79      0.12       901\n",
      "\n",
      "    accuracy                           0.53     22806\n",
      "   macro avg       0.52      0.66      0.40     22806\n",
      "weighted avg       0.95      0.53      0.66     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 227 features (percentile = 85%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.76      0.17       901\n",
      "\n",
      "    accuracy                           0.70     22806\n",
      "   macro avg       0.54      0.73      0.49     22806\n",
      "weighted avg       0.95      0.70      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 227 features (percentile = 85%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.76      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 227 features (percentile = 85%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.47      0.64     21905\n",
      "           1       0.06      0.82      0.11       901\n",
      "\n",
      "    accuracy                           0.49     22806\n",
      "   macro avg       0.52      0.65      0.38     22806\n",
      "weighted avg       0.95      0.49      0.62     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 213 features (percentile = 80%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.76      0.17       901\n",
      "\n",
      "    accuracy                           0.70     22806\n",
      "   macro avg       0.54      0.73      0.49     22806\n",
      "weighted avg       0.95      0.70      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 213 features (percentile = 80%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.76      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 213 features (percentile = 80%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.46      0.63     21905\n",
      "           1       0.06      0.82      0.11       901\n",
      "\n",
      "    accuracy                           0.48     22806\n",
      "   macro avg       0.52      0.64      0.37     22806\n",
      "weighted avg       0.95      0.48      0.61     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 187 features (percentile = 70%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.70      0.82     21905\n",
      "           1       0.09      0.76      0.17       901\n",
      "\n",
      "    accuracy                           0.70     22806\n",
      "   macro avg       0.54      0.73      0.49     22806\n",
      "weighted avg       0.95      0.70      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 187 features (percentile = 70%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.76      0.16       901\n",
      "\n",
      "    accuracy                           0.70     22806\n",
      "   macro avg       0.54      0.73      0.49     22806\n",
      "weighted avg       0.95      0.70      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 187 features (percentile = 70%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.43      0.60     21905\n",
      "           1       0.06      0.84      0.11       901\n",
      "\n",
      "    accuracy                           0.45     22806\n",
      "   macro avg       0.52      0.63      0.35     22806\n",
      "weighted avg       0.95      0.45      0.58     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 160 features (percentile = 60%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.76      0.16       901\n",
      "\n",
      "    accuracy                           0.70     22806\n",
      "   macro avg       0.54      0.73      0.49     22806\n",
      "weighted avg       0.95      0.70      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 160 features (percentile = 60%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.76      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 160 features (percentile = 60%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.47      0.63     21905\n",
      "           1       0.06      0.82      0.11       901\n",
      "\n",
      "    accuracy                           0.48     22806\n",
      "   macro avg       0.52      0.64      0.37     22806\n",
      "weighted avg       0.95      0.48      0.61     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 133 features (percentile = 50%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.76      0.16       901\n",
      "\n",
      "    accuracy                           0.70     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.70      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 133 features (percentile = 50%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.75      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.79     22806\n",
      "\n",
      "\n",
      "================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobustScaler, select 133 features (percentile = 50%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.62      0.76     21905\n",
      "           1       0.08      0.80      0.15       901\n",
      "\n",
      "    accuracy                           0.63     22806\n",
      "   macro avg       0.53      0.71      0.46     22806\n",
      "weighted avg       0.95      0.63      0.74     22806\n",
      "\n",
      "\n",
      "================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\miniconda3\\envs\\jupyter_kernel\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "logreg1 = LogisticRegression(max_iter=500, \n",
    "                             penalty='l2', \n",
    "                             solver = 'liblinear',\n",
    "                             class_weight='balanced',\n",
    "                             C = 100,\n",
    "                             random_state=12)\n",
    "detail = 'liblinear, l2, C = 100'\n",
    "eval_all(logreg1, detail, X_train, y_train, X_test, y_test, logreg_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6d1f5101",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T03:34:54.822453Z",
     "start_time": "2023-09-26T03:34:54.778454Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Feature selection</th>\n",
       "      <th>No. features</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear, l2, C = 100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>187 (70%)</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear, l2, C = 100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>240 (90%)</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear, l2, C = 100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>213 (80%)</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear, l2, C = 100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>-</td>\n",
       "      <td>267</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear, l2, C = 100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>227 (85%)</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear, l2, C = 100</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>187 (70%)</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear, l2, C = 100</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>-</td>\n",
       "      <td>267</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear, l2, C = 100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>160 (60%)</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear, l2, C = 100</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>213 (80%)</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear, l2, C = 100</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>240 (90%)</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear, l2, C = 100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>133 (50%)</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear, l2, C = 100</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>227 (85%)</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear, l2, C = 100</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>160 (60%)</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear, l2, C = 100</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>133 (50%)</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear, l2, C = 100</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>133 (50%)</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear, l2, C = 100</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>240 (90%)</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear, l2, C = 100</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>-</td>\n",
       "      <td>267</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear, l2, C = 100</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>227 (85%)</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear, l2, C = 100</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>213 (80%)</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear, l2, C = 100</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>160 (60%)</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear, l2, C = 100</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>187 (70%)</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear, l2, C = 100</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>267</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model                 Details          Scaler  \\\n",
       "0   LogisticRegression  liblinear, l2, C = 100  StandardScaler   \n",
       "1   LogisticRegression  liblinear, l2, C = 100  StandardScaler   \n",
       "2   LogisticRegression  liblinear, l2, C = 100  StandardScaler   \n",
       "3   LogisticRegression  liblinear, l2, C = 100  StandardScaler   \n",
       "4   LogisticRegression  liblinear, l2, C = 100  StandardScaler   \n",
       "5   LogisticRegression  liblinear, l2, C = 100    MinMaxScaler   \n",
       "6   LogisticRegression  liblinear, l2, C = 100    MinMaxScaler   \n",
       "7   LogisticRegression  liblinear, l2, C = 100  StandardScaler   \n",
       "8   LogisticRegression  liblinear, l2, C = 100    MinMaxScaler   \n",
       "9   LogisticRegression  liblinear, l2, C = 100    MinMaxScaler   \n",
       "10  LogisticRegression  liblinear, l2, C = 100  StandardScaler   \n",
       "11  LogisticRegression  liblinear, l2, C = 100    MinMaxScaler   \n",
       "12  LogisticRegression  liblinear, l2, C = 100    MinMaxScaler   \n",
       "13  LogisticRegression  liblinear, l2, C = 100    MinMaxScaler   \n",
       "14  LogisticRegression  liblinear, l2, C = 100    RobustScaler   \n",
       "15  LogisticRegression  liblinear, l2, C = 100    RobustScaler   \n",
       "16  LogisticRegression  liblinear, l2, C = 100    RobustScaler   \n",
       "17  LogisticRegression  liblinear, l2, C = 100    RobustScaler   \n",
       "18  LogisticRegression  liblinear, l2, C = 100    RobustScaler   \n",
       "19  LogisticRegression  liblinear, l2, C = 100    RobustScaler   \n",
       "20  LogisticRegression  liblinear, l2, C = 100    RobustScaler   \n",
       "21  LogisticRegression  liblinear, l2, C = 100               -   \n",
       "\n",
       "   Feature selection No. features  Precision  Recall  F1-score    AUC  \n",
       "0     UFS(f_classif)    187 (70%)      0.093   0.764     0.166  0.729  \n",
       "1     UFS(f_classif)    240 (90%)      0.093   0.761     0.166  0.728  \n",
       "2     UFS(f_classif)    213 (80%)      0.093   0.761     0.166  0.728  \n",
       "3                  -          267      0.093   0.762     0.166  0.728  \n",
       "4     UFS(f_classif)    227 (85%)      0.093   0.760     0.165  0.727  \n",
       "5     UFS(f_classif)    187 (70%)      0.092   0.760     0.165  0.726  \n",
       "6                  -          267      0.092   0.759     0.164  0.726  \n",
       "7     UFS(f_classif)    160 (60%)      0.093   0.758     0.165  0.726  \n",
       "8     UFS(f_classif)    213 (80%)      0.092   0.758     0.164  0.725  \n",
       "9     UFS(f_classif)    240 (90%)      0.092   0.759     0.164  0.725  \n",
       "10    UFS(f_classif)    133 (50%)      0.092   0.756     0.164  0.725  \n",
       "11    UFS(f_classif)    227 (85%)      0.092   0.758     0.164  0.725  \n",
       "12    UFS(f_classif)    160 (60%)      0.092   0.756     0.163  0.724  \n",
       "13    UFS(f_classif)    133 (50%)      0.091   0.755     0.163  0.723  \n",
       "14    UFS(f_classif)    133 (50%)      0.081   0.805     0.147  0.714  \n",
       "15    UFS(f_classif)    240 (90%)      0.063   0.795     0.117  0.656  \n",
       "16                 -          267      0.062   0.806     0.116  0.653  \n",
       "17    UFS(f_classif)    227 (85%)      0.060   0.821     0.113  0.648  \n",
       "18    UFS(f_classif)    213 (80%)      0.059   0.825     0.111  0.643  \n",
       "19    UFS(f_classif)    160 (60%)      0.059   0.820     0.111  0.643  \n",
       "20    UFS(f_classif)    187 (70%)      0.057   0.839     0.107  0.634  \n",
       "21                 -          267      0.059   0.098     0.073  0.517  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_evaluation = logreg_evaluation.sort_values(by='AUC', ascending=False, ignore_index=True)\n",
    "logreg_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d919df11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T03:35:03.438454Z",
     "start_time": "2023-09-26T03:35:03.424415Z"
    }
   },
   "outputs": [],
   "source": [
    "logreg_evaluation.to_csv('logreg_evaluation.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927fc87d",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "632785ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T07:56:10.700481Z",
     "start_time": "2023-09-26T07:56:10.688478Z"
    }
   },
   "outputs": [],
   "source": [
    "knn_evaluation = base_evaluation_table.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9f9e4d99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T08:25:41.593473Z",
     "start_time": "2023-09-26T07:56:12.705473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21905\n",
      "           1       0.15      0.07      0.10       901\n",
      "\n",
      "    accuracy                           0.95     22806\n",
      "   macro avg       0.56      0.53      0.54     22806\n",
      "weighted avg       0.93      0.95      0.94     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21905\n",
      "           1       0.14      0.08      0.10       901\n",
      "\n",
      "    accuracy                           0.95     22806\n",
      "   macro avg       0.55      0.53      0.54     22806\n",
      "weighted avg       0.93      0.95      0.94     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21905\n",
      "           1       0.14      0.07      0.09       901\n",
      "\n",
      "    accuracy                           0.95     22806\n",
      "   macro avg       0.55      0.53      0.53     22806\n",
      "weighted avg       0.93      0.95      0.94     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 240 features (percentile = 90%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21905\n",
      "           1       0.15      0.08      0.10       901\n",
      "\n",
      "    accuracy                           0.95     22806\n",
      "   macro avg       0.56      0.53      0.54     22806\n",
      "weighted avg       0.93      0.95      0.94     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 240 features (percentile = 90%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21905\n",
      "           1       0.14      0.08      0.10       901\n",
      "\n",
      "    accuracy                           0.95     22806\n",
      "   macro avg       0.55      0.53      0.54     22806\n",
      "weighted avg       0.93      0.95      0.94     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 240 features (percentile = 90%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21905\n",
      "           1       0.14      0.07      0.10       901\n",
      "\n",
      "    accuracy                           0.95     22806\n",
      "   macro avg       0.55      0.53      0.53     22806\n",
      "weighted avg       0.93      0.95      0.94     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 227 features (percentile = 85%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21905\n",
      "           1       0.15      0.08      0.10       901\n",
      "\n",
      "    accuracy                           0.95     22806\n",
      "   macro avg       0.56      0.53      0.54     22806\n",
      "weighted avg       0.93      0.95      0.94     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 227 features (percentile = 85%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21905\n",
      "           1       0.14      0.08      0.10       901\n",
      "\n",
      "    accuracy                           0.95     22806\n",
      "   macro avg       0.55      0.53      0.54     22806\n",
      "weighted avg       0.93      0.95      0.94     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 227 features (percentile = 85%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21905\n",
      "           1       0.13      0.07      0.09       901\n",
      "\n",
      "    accuracy                           0.95     22806\n",
      "   macro avg       0.55      0.53      0.53     22806\n",
      "weighted avg       0.93      0.95      0.94     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 213 features (percentile = 80%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21905\n",
      "           1       0.15      0.08      0.10       901\n",
      "\n",
      "    accuracy                           0.95     22806\n",
      "   macro avg       0.56      0.53      0.54     22806\n",
      "weighted avg       0.93      0.95      0.94     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 213 features (percentile = 80%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21905\n",
      "           1       0.14      0.08      0.10       901\n",
      "\n",
      "    accuracy                           0.95     22806\n",
      "   macro avg       0.55      0.53      0.54     22806\n",
      "weighted avg       0.93      0.95      0.94     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 213 features (percentile = 80%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21905\n",
      "           1       0.13      0.07      0.09       901\n",
      "\n",
      "    accuracy                           0.95     22806\n",
      "   macro avg       0.55      0.52      0.53     22806\n",
      "weighted avg       0.93      0.95      0.94     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 187 features (percentile = 70%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21905\n",
      "           1       0.15      0.07      0.10       901\n",
      "\n",
      "    accuracy                           0.95     22806\n",
      "   macro avg       0.56      0.53      0.54     22806\n",
      "weighted avg       0.93      0.95      0.94     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 187 features (percentile = 70%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21905\n",
      "           1       0.14      0.08      0.10       901\n",
      "\n",
      "    accuracy                           0.95     22806\n",
      "   macro avg       0.55      0.53      0.54     22806\n",
      "weighted avg       0.93      0.95      0.94     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 187 features (percentile = 70%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21905\n",
      "           1       0.14      0.07      0.10       901\n",
      "\n",
      "    accuracy                           0.95     22806\n",
      "   macro avg       0.55      0.53      0.53     22806\n",
      "weighted avg       0.93      0.95      0.94     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 160 features (percentile = 60%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21905\n",
      "           1       0.14      0.07      0.10       901\n",
      "\n",
      "    accuracy                           0.95     22806\n",
      "   macro avg       0.55      0.53      0.53     22806\n",
      "weighted avg       0.93      0.95      0.94     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 160 features (percentile = 60%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21905\n",
      "           1       0.14      0.07      0.10       901\n",
      "\n",
      "    accuracy                           0.95     22806\n",
      "   macro avg       0.55      0.53      0.53     22806\n",
      "weighted avg       0.93      0.95      0.94     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 160 features (percentile = 60%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21905\n",
      "           1       0.14      0.07      0.10       901\n",
      "\n",
      "    accuracy                           0.95     22806\n",
      "   macro avg       0.55      0.53      0.53     22806\n",
      "weighted avg       0.93      0.95      0.94     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 133 features (percentile = 50%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21905\n",
      "           1       0.14      0.08      0.10       901\n",
      "\n",
      "    accuracy                           0.95     22806\n",
      "   macro avg       0.55      0.53      0.54     22806\n",
      "weighted avg       0.93      0.95      0.94     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 133 features (percentile = 50%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21905\n",
      "           1       0.14      0.07      0.10       901\n",
      "\n",
      "    accuracy                           0.94     22806\n",
      "   macro avg       0.55      0.53      0.53     22806\n",
      "weighted avg       0.93      0.94      0.94     22806\n",
      "\n",
      "\n",
      "================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobustScaler, select 133 features (percentile = 50%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     21905\n",
      "           1       0.15      0.07      0.10       901\n",
      "\n",
      "    accuracy                           0.95     22806\n",
      "   macro avg       0.56      0.53      0.54     22806\n",
      "weighted avg       0.93      0.95      0.94     22806\n",
      "\n",
      "\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = 3\n",
    "weights = 'distance'\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, algorithm = 'ball_tree', n_jobs=5)\n",
    "detail = f\"n_neighbors={n_neighbors}, weights={weights}\"\n",
    "\n",
    "eval_all(knn, detail, X_train, y_train, X_test, y_test, knn_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e6560036",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T08:30:14.496495Z",
     "start_time": "2023-09-26T08:30:14.451477Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Feature selection</th>\n",
       "      <th>No. features</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>n_neighbors=3, weights=distance</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>227 (85%)</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>n_neighbors=3, weights=distance</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>213 (80%)</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>n_neighbors=3, weights=distance</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>133 (50%)</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>n_neighbors=3, weights=distance</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>240 (90%)</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>n_neighbors=3, weights=distance</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>213 (80%)</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>n_neighbors=3, weights=distance</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>187 (70%)</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>n_neighbors=3, weights=distance</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>160 (60%)</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>n_neighbors=3, weights=distance</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>160 (60%)</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>n_neighbors=3, weights=distance</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>160 (60%)</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>n_neighbors=3, weights=distance</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>187 (70%)</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>n_neighbors=3, weights=distance</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>187 (70%)</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>n_neighbors=3, weights=distance</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>133 (50%)</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>n_neighbors=3, weights=distance</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>-</td>\n",
       "      <td>267</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>n_neighbors=3, weights=distance</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>227 (85%)</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>n_neighbors=3, weights=distance</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>240 (90%)</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>n_neighbors=3, weights=distance</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>-</td>\n",
       "      <td>267</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>n_neighbors=3, weights=distance</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>240 (90%)</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>n_neighbors=3, weights=distance</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>133 (50%)</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>n_neighbors=3, weights=distance</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>-</td>\n",
       "      <td>267</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>n_neighbors=3, weights=distance</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>213 (80%)</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>n_neighbors=3, weights=distance</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>227 (85%)</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>n_neighbors=3, weights=distance</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>267</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model                          Details          Scaler  \\\n",
       "0   KNeighborsClassifier  n_neighbors=3, weights=distance  StandardScaler   \n",
       "1   KNeighborsClassifier  n_neighbors=3, weights=distance  StandardScaler   \n",
       "2   KNeighborsClassifier  n_neighbors=3, weights=distance  StandardScaler   \n",
       "3   KNeighborsClassifier  n_neighbors=3, weights=distance  StandardScaler   \n",
       "4   KNeighborsClassifier  n_neighbors=3, weights=distance    MinMaxScaler   \n",
       "5   KNeighborsClassifier  n_neighbors=3, weights=distance  StandardScaler   \n",
       "6   KNeighborsClassifier  n_neighbors=3, weights=distance    RobustScaler   \n",
       "7   KNeighborsClassifier  n_neighbors=3, weights=distance    MinMaxScaler   \n",
       "8   KNeighborsClassifier  n_neighbors=3, weights=distance  StandardScaler   \n",
       "9   KNeighborsClassifier  n_neighbors=3, weights=distance    RobustScaler   \n",
       "10  KNeighborsClassifier  n_neighbors=3, weights=distance    MinMaxScaler   \n",
       "11  KNeighborsClassifier  n_neighbors=3, weights=distance    RobustScaler   \n",
       "12  KNeighborsClassifier  n_neighbors=3, weights=distance  StandardScaler   \n",
       "13  KNeighborsClassifier  n_neighbors=3, weights=distance    MinMaxScaler   \n",
       "14  KNeighborsClassifier  n_neighbors=3, weights=distance    MinMaxScaler   \n",
       "15  KNeighborsClassifier  n_neighbors=3, weights=distance    MinMaxScaler   \n",
       "16  KNeighborsClassifier  n_neighbors=3, weights=distance    RobustScaler   \n",
       "17  KNeighborsClassifier  n_neighbors=3, weights=distance    MinMaxScaler   \n",
       "18  KNeighborsClassifier  n_neighbors=3, weights=distance    RobustScaler   \n",
       "19  KNeighborsClassifier  n_neighbors=3, weights=distance    RobustScaler   \n",
       "20  KNeighborsClassifier  n_neighbors=3, weights=distance    RobustScaler   \n",
       "21  KNeighborsClassifier  n_neighbors=3, weights=distance               -   \n",
       "\n",
       "   Feature selection No. features  Precision  Recall  F1-score    AUC  \n",
       "0     UFS(f_classif)    227 (85%)      0.153   0.077     0.102  0.530  \n",
       "1     UFS(f_classif)    213 (80%)      0.152   0.077     0.102  0.530  \n",
       "2     UFS(f_classif)    133 (50%)      0.144   0.075     0.099  0.529  \n",
       "3     UFS(f_classif)    240 (90%)      0.151   0.075     0.101  0.529  \n",
       "4     UFS(f_classif)    213 (80%)      0.141   0.075     0.098  0.528  \n",
       "5     UFS(f_classif)    187 (70%)      0.149   0.074     0.099  0.528  \n",
       "6     UFS(f_classif)    160 (60%)      0.143   0.074     0.098  0.528  \n",
       "7     UFS(f_classif)    160 (60%)      0.140   0.074     0.097  0.528  \n",
       "8     UFS(f_classif)    160 (60%)      0.143   0.073     0.097  0.528  \n",
       "9     UFS(f_classif)    187 (70%)      0.142   0.074     0.098  0.528  \n",
       "10    UFS(f_classif)    187 (70%)      0.141   0.075     0.098  0.528  \n",
       "11    UFS(f_classif)    133 (50%)      0.149   0.074     0.099  0.528  \n",
       "12                 -          267      0.149   0.074     0.099  0.528  \n",
       "13    UFS(f_classif)    227 (85%)      0.141   0.075     0.098  0.528  \n",
       "14    UFS(f_classif)    240 (90%)      0.142   0.075     0.098  0.528  \n",
       "15                 -          267      0.141   0.075     0.098  0.528  \n",
       "16    UFS(f_classif)    240 (90%)      0.139   0.072     0.095  0.527  \n",
       "17    UFS(f_classif)    133 (50%)      0.136   0.074     0.096  0.527  \n",
       "18                 -          267      0.136   0.071     0.093  0.526  \n",
       "19    UFS(f_classif)    213 (80%)      0.131   0.068     0.089  0.525  \n",
       "20    UFS(f_classif)    227 (85%)      0.134   0.069     0.091  0.525  \n",
       "21                 -          267      0.127   0.040     0.061  0.514  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_evaluation = knn_evaluation.sort_values(by='AUC', ascending=False, ignore_index=True)\n",
    "knn_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0869ea3b",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "923dd788",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T03:18:38.740901Z",
     "start_time": "2023-09-21T03:18:38.724902Z"
    }
   },
   "outputs": [],
   "source": [
    "svm_evaluation = base_evaluation_table.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6a8a2089",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T03:53:55.031586Z",
     "start_time": "2023-09-21T03:18:40.933594Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\miniconda3\\envs\\jupyter_kernel\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.75      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.78     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.75      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.78     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.43      0.60     21905\n",
      "           1       0.06      0.84      0.11       901\n",
      "\n",
      "    accuracy                           0.45     22806\n",
      "   macro avg       0.52      0.64      0.36     22806\n",
      "weighted avg       0.95      0.45      0.58     22806\n",
      "\n",
      "\n",
      "================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\miniconda3\\envs\\jupyter_kernel\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler, select 240 features (percentile = 90%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.75      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.78     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 240 features (percentile = 90%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.76      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.78     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 240 features (percentile = 90%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.46      0.62     21905\n",
      "           1       0.06      0.83      0.11       901\n",
      "\n",
      "    accuracy                           0.47     22806\n",
      "   macro avg       0.52      0.64      0.37     22806\n",
      "weighted avg       0.95      0.47      0.60     22806\n",
      "\n",
      "\n",
      "================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\miniconda3\\envs\\jupyter_kernel\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler, select 227 features (percentile = 85%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.76      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.78     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 227 features (percentile = 85%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.76      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.78     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 227 features (percentile = 85%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.45      0.61     21905\n",
      "           1       0.06      0.83      0.11       901\n",
      "\n",
      "    accuracy                           0.46     22806\n",
      "   macro avg       0.52      0.64      0.36     22806\n",
      "weighted avg       0.95      0.46      0.59     22806\n",
      "\n",
      "\n",
      "================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\miniconda3\\envs\\jupyter_kernel\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler, select 213 features (percentile = 80%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.76      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.78     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 213 features (percentile = 80%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.76      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.78     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 213 features (percentile = 80%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.45      0.62     21905\n",
      "           1       0.06      0.83      0.11       901\n",
      "\n",
      "    accuracy                           0.47     22806\n",
      "   macro avg       0.52      0.64      0.36     22806\n",
      "weighted avg       0.95      0.47      0.60     22806\n",
      "\n",
      "\n",
      "================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\miniconda3\\envs\\jupyter_kernel\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler, select 187 features (percentile = 70%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.76      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.78     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 187 features (percentile = 70%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.76      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.78     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 187 features (percentile = 70%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.43      0.60     21905\n",
      "           1       0.06      0.84      0.11       901\n",
      "\n",
      "    accuracy                           0.45     22806\n",
      "   macro avg       0.52      0.64      0.35     22806\n",
      "weighted avg       0.95      0.45      0.58     22806\n",
      "\n",
      "\n",
      "================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\miniconda3\\envs\\jupyter_kernel\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler, select 160 features (percentile = 60%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.75      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 160 features (percentile = 60%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.75      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 160 features (percentile = 60%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.42      0.59     21905\n",
      "           1       0.06      0.85      0.11       901\n",
      "\n",
      "    accuracy                           0.44     22806\n",
      "   macro avg       0.52      0.64      0.35     22806\n",
      "weighted avg       0.95      0.44      0.57     22806\n",
      "\n",
      "\n",
      "================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\miniconda3\\envs\\jupyter_kernel\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler, select 133 features (percentile = 50%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.75      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 133 features (percentile = 50%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.75      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 133 features (percentile = 50%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.64      0.78     21905\n",
      "           1       0.08      0.79      0.15       901\n",
      "\n",
      "    accuracy                           0.65     22806\n",
      "   macro avg       0.53      0.72      0.46     22806\n",
      "weighted avg       0.95      0.65      0.75     22806\n",
      "\n",
      "\n",
      "================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\miniconda3\\envs\\jupyter_kernel\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "C = 10\n",
    "penalty = 'l2' \n",
    "\n",
    "svm = LinearSVC(C=C, penalty = penalty, dual = False, class_weight='balanced')\n",
    "detail = f\"C={C}, penalty={penalty}\"\n",
    "\n",
    "eval_all(svm, detail, X_train, y_train, X_test, y_test, svm_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0a519c70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-21T03:57:23.076880Z",
     "start_time": "2023-09-21T03:57:23.026609Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Feature selection</th>\n",
       "      <th>No. features</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>C=10, penalty=l2</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>187 (70%)</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>C=10, penalty=l2</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>187 (70%)</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>C=10, penalty=l2</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>240 (90%)</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>C=10, penalty=l2</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>227 (85%)</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>C=10, penalty=l2</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>227 (85%)</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>C=10, penalty=l2</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>213 (80%)</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>C=10, penalty=l2</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>-</td>\n",
       "      <td>267</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>C=10, penalty=l2</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>160 (60%)</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>C=10, penalty=l2</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>213 (80%)</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>C=10, penalty=l2</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>-</td>\n",
       "      <td>267</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>C=10, penalty=l2</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>240 (90%)</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>C=10, penalty=l2</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>160 (60%)</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>C=10, penalty=l2</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>133 (50%)</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>C=10, penalty=l2</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>133 (50%)</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>C=10, penalty=l2</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>133 (50%)</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>C=10, penalty=l2</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>240 (90%)</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>C=10, penalty=l2</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>213 (80%)</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>C=10, penalty=l2</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>227 (85%)</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>C=10, penalty=l2</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>-</td>\n",
       "      <td>267</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>C=10, penalty=l2</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>160 (60%)</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>C=10, penalty=l2</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>187 (70%)</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>C=10, penalty=l2</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>267</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model           Details          Scaler Feature selection  \\\n",
       "0   LinearSVC  C=10, penalty=l2  StandardScaler    UFS(f_classif)   \n",
       "1   LinearSVC  C=10, penalty=l2    MinMaxScaler    UFS(f_classif)   \n",
       "2   LinearSVC  C=10, penalty=l2    MinMaxScaler    UFS(f_classif)   \n",
       "3   LinearSVC  C=10, penalty=l2  StandardScaler    UFS(f_classif)   \n",
       "4   LinearSVC  C=10, penalty=l2    MinMaxScaler    UFS(f_classif)   \n",
       "5   LinearSVC  C=10, penalty=l2  StandardScaler    UFS(f_classif)   \n",
       "6   LinearSVC  C=10, penalty=l2  StandardScaler                 -   \n",
       "7   LinearSVC  C=10, penalty=l2  StandardScaler    UFS(f_classif)   \n",
       "8   LinearSVC  C=10, penalty=l2    MinMaxScaler    UFS(f_classif)   \n",
       "9   LinearSVC  C=10, penalty=l2    MinMaxScaler                 -   \n",
       "10  LinearSVC  C=10, penalty=l2  StandardScaler    UFS(f_classif)   \n",
       "11  LinearSVC  C=10, penalty=l2    MinMaxScaler    UFS(f_classif)   \n",
       "12  LinearSVC  C=10, penalty=l2  StandardScaler    UFS(f_classif)   \n",
       "13  LinearSVC  C=10, penalty=l2    MinMaxScaler    UFS(f_classif)   \n",
       "14  LinearSVC  C=10, penalty=l2    RobustScaler    UFS(f_classif)   \n",
       "15  LinearSVC  C=10, penalty=l2    RobustScaler    UFS(f_classif)   \n",
       "16  LinearSVC  C=10, penalty=l2    RobustScaler    UFS(f_classif)   \n",
       "17  LinearSVC  C=10, penalty=l2    RobustScaler    UFS(f_classif)   \n",
       "18  LinearSVC  C=10, penalty=l2    RobustScaler                 -   \n",
       "19  LinearSVC  C=10, penalty=l2    RobustScaler    UFS(f_classif)   \n",
       "20  LinearSVC  C=10, penalty=l2    RobustScaler    UFS(f_classif)   \n",
       "21  LinearSVC  C=10, penalty=l2               -                 -   \n",
       "\n",
       "   No. features  Precision  Recall  F1-score    AUC  \n",
       "0     187 (70%)      0.091   0.757     0.162  0.723  \n",
       "1     187 (70%)      0.091   0.756     0.162  0.722  \n",
       "2     240 (90%)      0.090   0.756     0.161  0.722  \n",
       "3     227 (85%)      0.091   0.757     0.162  0.722  \n",
       "4     227 (85%)      0.090   0.756     0.162  0.722  \n",
       "5     213 (80%)      0.091   0.757     0.162  0.722  \n",
       "6           267      0.091   0.755     0.162  0.722  \n",
       "7     160 (60%)      0.091   0.754     0.162  0.722  \n",
       "8     213 (80%)      0.090   0.756     0.161  0.721  \n",
       "9           267      0.090   0.755     0.161  0.721  \n",
       "10    240 (90%)      0.091   0.755     0.162  0.721  \n",
       "11    160 (60%)      0.090   0.750     0.161  0.720  \n",
       "12    133 (50%)      0.090   0.749     0.161  0.719  \n",
       "13    133 (50%)      0.090   0.747     0.160  0.718  \n",
       "14    133 (50%)      0.083   0.791     0.150  0.716  \n",
       "15    240 (90%)      0.059   0.831     0.111  0.644  \n",
       "16    213 (80%)      0.059   0.830     0.110  0.641  \n",
       "17    227 (85%)      0.058   0.835     0.109  0.640  \n",
       "18          267      0.058   0.845     0.108  0.639  \n",
       "19    160 (60%)      0.057   0.849     0.107  0.637  \n",
       "20    187 (70%)      0.057   0.840     0.107  0.635  \n",
       "21          267      0.060   0.087     0.071  0.515  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_evaluation = svm_evaluation.sort_values(by='AUC', ascending=False, ignore_index=True)\n",
    "svm_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938ca8c3",
   "metadata": {},
   "source": [
    "# Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "1d63bd78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T09:25:41.980358Z",
     "start_time": "2023-09-26T09:25:41.969356Z"
    }
   },
   "outputs": [],
   "source": [
    "kernel_svm_evaluation = base_evaluation_table.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "96ed3a75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T06:35:23.511666Z",
     "start_time": "2023-09-27T01:47:00.801966Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.75      0.85     21905\n",
      "           1       0.10      0.70      0.18       901\n",
      "\n",
      "    accuracy                           0.75     22806\n",
      "   macro avg       0.54      0.72      0.52     22806\n",
      "weighted avg       0.95      0.75      0.83     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.69      0.81     21905\n",
      "           1       0.09      0.74      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.01      0.01     21905\n",
      "           1       0.04      1.00      0.08       901\n",
      "\n",
      "    accuracy                           0.05     22806\n",
      "   macro avg       0.51      0.50      0.04     22806\n",
      "weighted avg       0.95      0.05      0.01     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 240 features (percentile = 90%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.76      0.86     21905\n",
      "           1       0.10      0.68      0.18       901\n",
      "\n",
      "    accuracy                           0.75     22806\n",
      "   macro avg       0.54      0.72      0.52     22806\n",
      "weighted avg       0.95      0.75      0.83     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 240 features (percentile = 90%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.69      0.81     21905\n",
      "           1       0.09      0.74      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 240 features (percentile = 90%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.01      0.01     21905\n",
      "           1       0.04      1.00      0.08       901\n",
      "\n",
      "    accuracy                           0.05     22806\n",
      "   macro avg       0.51      0.50      0.04     22806\n",
      "weighted avg       0.95      0.05      0.01     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 227 features (percentile = 85%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.76      0.86     21905\n",
      "           1       0.11      0.69      0.18       901\n",
      "\n",
      "    accuracy                           0.76     22806\n",
      "   macro avg       0.54      0.72      0.52     22806\n",
      "weighted avg       0.95      0.76      0.83     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 227 features (percentile = 85%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.74      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 227 features (percentile = 85%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.01      0.01     21905\n",
      "           1       0.04      1.00      0.08       901\n",
      "\n",
      "    accuracy                           0.05     22806\n",
      "   macro avg       0.51      0.50      0.04     22806\n",
      "weighted avg       0.95      0.05      0.01     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 213 features (percentile = 80%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.76      0.86     21905\n",
      "           1       0.11      0.68      0.18       901\n",
      "\n",
      "    accuracy                           0.76     22806\n",
      "   macro avg       0.54      0.72      0.52     22806\n",
      "weighted avg       0.95      0.76      0.83     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 213 features (percentile = 80%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.69      0.81     21905\n",
      "           1       0.09      0.74      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 213 features (percentile = 80%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.01      0.01     21905\n",
      "           1       0.04      1.00      0.08       901\n",
      "\n",
      "    accuracy                           0.04     22806\n",
      "   macro avg       0.51      0.50      0.04     22806\n",
      "weighted avg       0.95      0.04      0.01     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 187 features (percentile = 70%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.76      0.86     21905\n",
      "           1       0.11      0.68      0.18       901\n",
      "\n",
      "    accuracy                           0.76     22806\n",
      "   macro avg       0.54      0.72      0.52     22806\n",
      "weighted avg       0.95      0.76      0.83     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 187 features (percentile = 70%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.69      0.81     21905\n",
      "           1       0.09      0.74      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 187 features (percentile = 70%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.01      0.01     21905\n",
      "           1       0.04      1.00      0.08       901\n",
      "\n",
      "    accuracy                           0.04     22806\n",
      "   macro avg       0.51      0.50      0.04     22806\n",
      "weighted avg       0.95      0.04      0.01     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 160 features (percentile = 60%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.77      0.86     21905\n",
      "           1       0.11      0.68      0.19       901\n",
      "\n",
      "    accuracy                           0.76     22806\n",
      "   macro avg       0.55      0.72      0.52     22806\n",
      "weighted avg       0.95      0.76      0.83     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 160 features (percentile = 60%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.69      0.81     21905\n",
      "           1       0.09      0.74      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.71      0.48     22806\n",
      "weighted avg       0.95      0.69      0.78     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 160 features (percentile = 60%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.01      0.01     21905\n",
      "           1       0.04      1.00      0.08       901\n",
      "\n",
      "    accuracy                           0.04     22806\n",
      "   macro avg       0.51      0.50      0.04     22806\n",
      "weighted avg       0.95      0.04      0.01     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 133 features (percentile = 50%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.77      0.86     21905\n",
      "           1       0.11      0.69      0.19       901\n",
      "\n",
      "    accuracy                           0.76     22806\n",
      "   macro avg       0.55      0.73      0.52     22806\n",
      "weighted avg       0.95      0.76      0.83     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 133 features (percentile = 50%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81     21905\n",
      "           1       0.09      0.75      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.48     22806\n",
      "weighted avg       0.95      0.69      0.78     22806\n",
      "\n",
      "\n",
      "================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobustScaler, select 133 features (percentile = 50%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.09      0.16     21905\n",
      "           1       0.04      0.99      0.08       901\n",
      "\n",
      "    accuracy                           0.12     22806\n",
      "   macro avg       0.52      0.54      0.12     22806\n",
      "weighted avg       0.96      0.12      0.16     22806\n",
      "\n",
      "\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "C=10\n",
    "\n",
    "rbf_svc = SVC(kernel='rbf', C=C, class_weight='balanced', random_state=12)\n",
    "\n",
    "detail = f\"kernel = rbf, C={C}\"\n",
    "\n",
    "eval_all(rbf_svc, detail, X_train, y_train, X_test, y_test, kernel_svm_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "fe9472ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T10:31:00.051581Z",
     "start_time": "2023-09-27T06:35:24.208662Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.75      0.85     21905\n",
      "           1       0.09      0.62      0.16       901\n",
      "\n",
      "    accuracy                           0.74     22806\n",
      "   macro avg       0.54      0.68      0.50     22806\n",
      "weighted avg       0.94      0.74      0.82     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.69      0.81     21905\n",
      "           1       0.09      0.74      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.01      0.01     21905\n",
      "           1       0.04      1.00      0.08       901\n",
      "\n",
      "    accuracy                           0.05     22806\n",
      "   macro avg       0.51      0.50      0.04     22806\n",
      "weighted avg       0.95      0.05      0.01     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 240 features (percentile = 90%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.75      0.85     21905\n",
      "           1       0.09      0.62      0.16       901\n",
      "\n",
      "    accuracy                           0.74     22806\n",
      "   macro avg       0.54      0.69      0.51     22806\n",
      "weighted avg       0.94      0.74      0.82     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 240 features (percentile = 90%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.69      0.81     21905\n",
      "           1       0.09      0.74      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 240 features (percentile = 90%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.01      0.01     21905\n",
      "           1       0.04      1.00      0.08       901\n",
      "\n",
      "    accuracy                           0.05     22806\n",
      "   macro avg       0.51      0.50      0.04     22806\n",
      "weighted avg       0.95      0.05      0.01     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 227 features (percentile = 85%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.75      0.85     21905\n",
      "           1       0.09      0.63      0.16       901\n",
      "\n",
      "    accuracy                           0.75     22806\n",
      "   macro avg       0.54      0.69      0.51     22806\n",
      "weighted avg       0.94      0.75      0.82     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 227 features (percentile = 85%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.69      0.81     21905\n",
      "           1       0.09      0.74      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 227 features (percentile = 85%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.01      0.01     21905\n",
      "           1       0.04      1.00      0.08       901\n",
      "\n",
      "    accuracy                           0.05     22806\n",
      "   macro avg       0.51      0.50      0.04     22806\n",
      "weighted avg       0.95      0.05      0.01     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 213 features (percentile = 80%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.76      0.85     21905\n",
      "           1       0.10      0.62      0.17       901\n",
      "\n",
      "    accuracy                           0.75     22806\n",
      "   macro avg       0.54      0.69      0.51     22806\n",
      "weighted avg       0.94      0.75      0.83     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 213 features (percentile = 80%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.69      0.81     21905\n",
      "           1       0.09      0.74      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 213 features (percentile = 80%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.01      0.01     21905\n",
      "           1       0.04      1.00      0.08       901\n",
      "\n",
      "    accuracy                           0.04     22806\n",
      "   macro avg       0.51      0.50      0.04     22806\n",
      "weighted avg       0.95      0.04      0.01     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 187 features (percentile = 70%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.76      0.85     21905\n",
      "           1       0.10      0.63      0.17       901\n",
      "\n",
      "    accuracy                           0.75     22806\n",
      "   macro avg       0.54      0.69      0.51     22806\n",
      "weighted avg       0.95      0.75      0.83     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 187 features (percentile = 70%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.69      0.81     21905\n",
      "           1       0.09      0.74      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.49     22806\n",
      "weighted avg       0.95      0.69      0.79     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 187 features (percentile = 70%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.01      0.01     21905\n",
      "           1       0.04      1.00      0.08       901\n",
      "\n",
      "    accuracy                           0.04     22806\n",
      "   macro avg       0.51      0.50      0.04     22806\n",
      "weighted avg       0.95      0.04      0.01     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 160 features (percentile = 60%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.76      0.86     21905\n",
      "           1       0.10      0.64      0.17       901\n",
      "\n",
      "    accuracy                           0.75     22806\n",
      "   macro avg       0.54      0.70      0.51     22806\n",
      "weighted avg       0.95      0.75      0.83     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 160 features (percentile = 60%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.69      0.81     21905\n",
      "           1       0.09      0.74      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.71      0.48     22806\n",
      "weighted avg       0.95      0.69      0.78     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 160 features (percentile = 60%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.01      0.01     21905\n",
      "           1       0.04      1.00      0.08       901\n",
      "\n",
      "    accuracy                           0.04     22806\n",
      "   macro avg       0.51      0.50      0.04     22806\n",
      "weighted avg       0.95      0.04      0.01     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 133 features (percentile = 50%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.76      0.86     21905\n",
      "           1       0.10      0.64      0.17       901\n",
      "\n",
      "    accuracy                           0.76     22806\n",
      "   macro avg       0.54      0.70      0.52     22806\n",
      "weighted avg       0.95      0.76      0.83     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 133 features (percentile = 50%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.68      0.81     21905\n",
      "           1       0.09      0.76      0.16       901\n",
      "\n",
      "    accuracy                           0.69     22806\n",
      "   macro avg       0.54      0.72      0.48     22806\n",
      "weighted avg       0.95      0.69      0.78     22806\n",
      "\n",
      "\n",
      "================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobustScaler, select 133 features (percentile = 50%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.06      0.11     21905\n",
      "           1       0.04      0.99      0.08       901\n",
      "\n",
      "    accuracy                           0.09     22806\n",
      "   macro avg       0.52      0.52      0.09     22806\n",
      "weighted avg       0.96      0.09      0.11     22806\n",
      "\n",
      "\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "C=10\n",
    "\n",
    "poly_svc = SVC(kernel='poly', C=C, class_weight='balanced', random_state=12)\n",
    "\n",
    "detail = f\"kernel = poly, C={C}\"\n",
    "\n",
    "eval_all(poly_svc, detail, X_train, y_train, X_test, y_test, kernel_svm_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "06deee6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T14:30:26.514274Z",
     "start_time": "2023-09-27T10:31:00.671585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.65      0.78     21905\n",
      "           1       0.07      0.67      0.13       901\n",
      "\n",
      "    accuracy                           0.65     22806\n",
      "   macro avg       0.53      0.66      0.46     22806\n",
      "weighted avg       0.94      0.65      0.76     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.57      0.72     21905\n",
      "           1       0.06      0.72      0.12       901\n",
      "\n",
      "    accuracy                           0.57     22806\n",
      "   macro avg       0.52      0.64      0.42     22806\n",
      "weighted avg       0.94      0.57      0.69     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.01      0.01     21905\n",
      "           1       0.04      1.00      0.08       901\n",
      "\n",
      "    accuracy                           0.05     22806\n",
      "   macro avg       0.51      0.50      0.05     22806\n",
      "weighted avg       0.94      0.05      0.02     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 240 features (percentile = 90%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.68      0.80     21905\n",
      "           1       0.08      0.65      0.14       901\n",
      "\n",
      "    accuracy                           0.68     22806\n",
      "   macro avg       0.53      0.67      0.47     22806\n",
      "weighted avg       0.94      0.68      0.78     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 240 features (percentile = 90%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.56      0.72     21905\n",
      "           1       0.06      0.72      0.12       901\n",
      "\n",
      "    accuracy                           0.57     22806\n",
      "   macro avg       0.52      0.64      0.42     22806\n",
      "weighted avg       0.94      0.57      0.69     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 240 features (percentile = 90%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.01      0.01     21905\n",
      "           1       0.04      1.00      0.08       901\n",
      "\n",
      "    accuracy                           0.05     22806\n",
      "   macro avg       0.51      0.50      0.04     22806\n",
      "weighted avg       0.94      0.05      0.02     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 227 features (percentile = 85%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.64      0.77     21905\n",
      "           1       0.07      0.65      0.12       901\n",
      "\n",
      "    accuracy                           0.64     22806\n",
      "   macro avg       0.52      0.64      0.45     22806\n",
      "weighted avg       0.94      0.64      0.75     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 227 features (percentile = 85%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.56      0.72     21905\n",
      "           1       0.06      0.72      0.12       901\n",
      "\n",
      "    accuracy                           0.57     22806\n",
      "   macro avg       0.52      0.64      0.42     22806\n",
      "weighted avg       0.94      0.57      0.69     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 227 features (percentile = 85%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.01      0.01     21905\n",
      "           1       0.04      1.00      0.08       901\n",
      "\n",
      "    accuracy                           0.05     22806\n",
      "   macro avg       0.51      0.50      0.04     22806\n",
      "weighted avg       0.94      0.05      0.02     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 213 features (percentile = 80%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.64      0.77     21905\n",
      "           1       0.07      0.64      0.12       901\n",
      "\n",
      "    accuracy                           0.64     22806\n",
      "   macro avg       0.52      0.64      0.45     22806\n",
      "weighted avg       0.94      0.64      0.75     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 213 features (percentile = 80%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.56      0.72     21905\n",
      "           1       0.06      0.72      0.12       901\n",
      "\n",
      "    accuracy                           0.57     22806\n",
      "   macro avg       0.52      0.64      0.42     22806\n",
      "weighted avg       0.94      0.57      0.69     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 213 features (percentile = 80%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.01      0.01     21905\n",
      "           1       0.04      1.00      0.08       901\n",
      "\n",
      "    accuracy                           0.05     22806\n",
      "   macro avg       0.51      0.50      0.04     22806\n",
      "weighted avg       0.94      0.05      0.02     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 187 features (percentile = 70%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.65      0.78     21905\n",
      "           1       0.07      0.66      0.13       901\n",
      "\n",
      "    accuracy                           0.65     22806\n",
      "   macro avg       0.53      0.66      0.46     22806\n",
      "weighted avg       0.94      0.65      0.76     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 187 features (percentile = 70%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.56      0.71     21905\n",
      "           1       0.06      0.74      0.12       901\n",
      "\n",
      "    accuracy                           0.57     22806\n",
      "   macro avg       0.52      0.65      0.42     22806\n",
      "weighted avg       0.95      0.57      0.69     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 187 features (percentile = 70%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.01      0.01     21905\n",
      "           1       0.04      1.00      0.08       901\n",
      "\n",
      "    accuracy                           0.04     22806\n",
      "   macro avg       0.51      0.50      0.04     22806\n",
      "weighted avg       0.95      0.04      0.01     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 160 features (percentile = 60%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.65      0.78     21905\n",
      "           1       0.07      0.64      0.13       901\n",
      "\n",
      "    accuracy                           0.65     22806\n",
      "   macro avg       0.52      0.65      0.45     22806\n",
      "weighted avg       0.94      0.65      0.76     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 160 features (percentile = 60%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.56      0.71     21905\n",
      "           1       0.06      0.73      0.12       901\n",
      "\n",
      "    accuracy                           0.56     22806\n",
      "   macro avg       0.52      0.64      0.41     22806\n",
      "weighted avg       0.94      0.56      0.69     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 160 features (percentile = 60%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.01      0.01     21905\n",
      "           1       0.04      1.00      0.08       901\n",
      "\n",
      "    accuracy                           0.04     22806\n",
      "   macro avg       0.51      0.50      0.04     22806\n",
      "weighted avg       0.95      0.04      0.01     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 133 features (percentile = 50%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.64      0.78     21905\n",
      "           1       0.07      0.63      0.12       901\n",
      "\n",
      "    accuracy                           0.64     22806\n",
      "   macro avg       0.52      0.64      0.45     22806\n",
      "weighted avg       0.94      0.64      0.75     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 133 features (percentile = 50%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.56      0.71     21905\n",
      "           1       0.06      0.73      0.12       901\n",
      "\n",
      "    accuracy                           0.56     22806\n",
      "   macro avg       0.52      0.64      0.41     22806\n",
      "weighted avg       0.94      0.56      0.69     22806\n",
      "\n",
      "\n",
      "================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobustScaler, select 133 features (percentile = 50%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.08      0.15     21905\n",
      "           1       0.04      0.97      0.08       901\n",
      "\n",
      "    accuracy                           0.12     22806\n",
      "   macro avg       0.51      0.53      0.12     22806\n",
      "weighted avg       0.95      0.12      0.15     22806\n",
      "\n",
      "\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "C=10\n",
    "\n",
    "sigmoid_svc = SVC(kernel='sigmoid', C=C, class_weight='balanced',random_state=12)\n",
    "\n",
    "detail = f\"kernel = sigmoid, C={C}\"\n",
    "\n",
    "eval_all(sigmoid_svc, detail, X_train, y_train, X_test, y_test, kernel_svm_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c7002b31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T01:51:40.166043Z",
     "start_time": "2023-09-28T01:51:40.115043Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Feature selection</th>\n",
       "      <th>No. features</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>kernel = rbf, C=10</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>133 (50%)</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>kernel = rbf, C=10</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>187 (70%)</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>kernel = rbf, C=10</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>-</td>\n",
       "      <td>267</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>kernel = rbf, C=10</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>160 (60%)</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>kernel = rbf, C=10</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>227 (85%)</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>SVC</td>\n",
       "      <td>kernel = poly, C=10</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>213 (80%)</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>SVC</td>\n",
       "      <td>kernel = poly, C=10</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>187 (70%)</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>SVC</td>\n",
       "      <td>kernel = sigmoid, C=10</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>-</td>\n",
       "      <td>267</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>SVC</td>\n",
       "      <td>kernel = poly, C=10</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>160 (60%)</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>SVC</td>\n",
       "      <td>kernel = rbf, C=10</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>267</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model                 Details          Scaler Feature selection  \\\n",
       "0    SVC      kernel = rbf, C=10  StandardScaler    UFS(f_classif)   \n",
       "1    SVC      kernel = rbf, C=10  StandardScaler    UFS(f_classif)   \n",
       "2    SVC      kernel = rbf, C=10  StandardScaler                 -   \n",
       "3    SVC      kernel = rbf, C=10  StandardScaler    UFS(f_classif)   \n",
       "4    SVC      kernel = rbf, C=10  StandardScaler    UFS(f_classif)   \n",
       "..   ...                     ...             ...               ...   \n",
       "61   SVC     kernel = poly, C=10    RobustScaler    UFS(f_classif)   \n",
       "62   SVC     kernel = poly, C=10    RobustScaler    UFS(f_classif)   \n",
       "63   SVC  kernel = sigmoid, C=10    RobustScaler                 -   \n",
       "64   SVC     kernel = poly, C=10    RobustScaler    UFS(f_classif)   \n",
       "65   SVC      kernel = rbf, C=10               -                 -   \n",
       "\n",
       "   No. features  Precision  Recall  F1-score    AUC  \n",
       "0     133 (50%)      0.108   0.688     0.187  0.727  \n",
       "1     187 (70%)      0.106   0.685     0.184  0.724  \n",
       "2           267      0.103   0.697     0.180  0.724  \n",
       "3     160 (60%)      0.107   0.683     0.185  0.724  \n",
       "4     227 (85%)      0.105   0.686     0.183  0.723  \n",
       "..          ...        ...     ...       ...    ...  \n",
       "61    213 (80%)      0.040   0.998     0.076  0.502  \n",
       "62    187 (70%)      0.040   0.998     0.076  0.502  \n",
       "63          267      0.040   0.997     0.076  0.502  \n",
       "64    160 (60%)      0.040   0.998     0.076  0.502  \n",
       "65          267      0.040   0.998     0.076  0.502  \n",
       "\n",
       "[66 rows x 9 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_svm_evaluation = kernel_svm_evaluation.sort_values(by='AUC', ascending=False, ignore_index=True)\n",
    "kernel_svm_evaluation.to_csv('kernel_svm_evaluation.csv', index=False)\n",
    "kernel_svm_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d219a54",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "6f555df7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:54:08.978176Z",
     "start_time": "2023-09-28T02:54:08.962178Z"
    }
   },
   "outputs": [],
   "source": [
    "nb_evaluation = base_evaluation_table.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "52877b2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T03:43:30.580809Z",
     "start_time": "2023-09-28T03:43:30.133809Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>imp_op_var40_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var29_ult3</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.437292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.874930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.213045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.213045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.500340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53209</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.092479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53210</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.876672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53211</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.3125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.152033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53212</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.875058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53213</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.033126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53214 rows × 267 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var3   var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0       0.0  2.1875                 0.0                      0.0   \n",
       "1       0.0  0.3750                 0.0                      0.0   \n",
       "2       0.0  3.6875                 0.0                      0.0   \n",
       "3       0.0 -0.1875                 0.0                      0.0   \n",
       "4       0.0  0.1875                 0.0                      0.0   \n",
       "...     ...     ...                 ...                      ...   \n",
       "53209   0.0  0.5625                 0.0                      0.0   \n",
       "53210   0.0 -0.2500                 0.0                      0.0   \n",
       "53211   0.0 -0.3125                 0.0                      0.0   \n",
       "53212   0.0  0.0625                 0.0                      0.0   \n",
       "53213   0.0 -0.1875                 0.0                      0.0   \n",
       "\n",
       "       imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  \\\n",
       "0                         0.00                      0.0   \n",
       "1                        96.75                      0.0   \n",
       "2                         0.00                      0.0   \n",
       "3                         0.00                      0.0   \n",
       "4                         0.00                      0.0   \n",
       "...                        ...                      ...   \n",
       "53209                     0.00                      0.0   \n",
       "53210                     0.00                      0.0   \n",
       "53211                     0.00                      0.0   \n",
       "53212                     0.00                      0.0   \n",
       "53213                     0.00                      0.0   \n",
       "\n",
       "       imp_op_var40_comer_ult3  imp_op_var40_efect_ult1  \\\n",
       "0                          0.0                      0.0   \n",
       "1                          0.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          0.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "53209                      0.0                      0.0   \n",
       "53210                      0.0                      0.0   \n",
       "53211                      0.0                      0.0   \n",
       "53212                      0.0                      0.0   \n",
       "53213                      0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_efect_ult3  imp_op_var40_ult1  ...  \\\n",
       "0                          0.0                0.0  ...   \n",
       "1                          0.0                0.0  ...   \n",
       "2                          0.0                0.0  ...   \n",
       "3                          0.0                0.0  ...   \n",
       "4                          0.0                0.0  ...   \n",
       "...                        ...                ...  ...   \n",
       "53209                      0.0                0.0  ...   \n",
       "53210                      0.0                0.0  ...   \n",
       "53211                      0.0                0.0  ...   \n",
       "53212                      0.0                0.0  ...   \n",
       "53213                      0.0                0.0  ...   \n",
       "\n",
       "       saldo_medio_var29_ult3  saldo_medio_var33_hace2  \\\n",
       "0                         0.0                      0.0   \n",
       "1                         0.0                      0.0   \n",
       "2                         0.0                      0.0   \n",
       "3                         0.0                      0.0   \n",
       "4                         0.0                      0.0   \n",
       "...                       ...                      ...   \n",
       "53209                     0.0                      0.0   \n",
       "53210                     0.0                      0.0   \n",
       "53211                     0.0                      0.0   \n",
       "53212                     0.0                      0.0   \n",
       "53213                     0.0                      0.0   \n",
       "\n",
       "       saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                          0.0                     0.0   \n",
       "1                          0.0                     0.0   \n",
       "2                          0.0                     0.0   \n",
       "3                          0.0                     0.0   \n",
       "4                          0.0                     0.0   \n",
       "...                        ...                     ...   \n",
       "53209                      0.0                     0.0   \n",
       "53210                      0.0                     0.0   \n",
       "53211                      0.0                     0.0   \n",
       "53212                      0.0                     0.0   \n",
       "53213                      0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var33_ult3  saldo_medio_var44_hace2  \\\n",
       "0                         0.0                      0.0   \n",
       "1                         0.0                      0.0   \n",
       "2                         0.0                      0.0   \n",
       "3                         0.0                      0.0   \n",
       "4                         0.0                      0.0   \n",
       "...                       ...                      ...   \n",
       "53209                     0.0                      0.0   \n",
       "53210                     0.0                      0.0   \n",
       "53211                     0.0                      0.0   \n",
       "53212                     0.0                      0.0   \n",
       "53213                     0.0                      0.0   \n",
       "\n",
       "       saldo_medio_var44_hace3  saldo_medio_var44_ult1  \\\n",
       "0                          0.0                     0.0   \n",
       "1                          0.0                     0.0   \n",
       "2                          0.0                     0.0   \n",
       "3                          0.0                     0.0   \n",
       "4                          0.0                     0.0   \n",
       "...                        ...                     ...   \n",
       "53209                      0.0                     0.0   \n",
       "53210                      0.0                     0.0   \n",
       "53211                      0.0                     0.0   \n",
       "53212                      0.0                     0.0   \n",
       "53213                      0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var44_ult3     var38  \n",
       "0                         0.0 -1.437292  \n",
       "1                         0.0  0.874930  \n",
       "2                         0.0  0.213045  \n",
       "3                         0.0  0.213045  \n",
       "4                         0.0  7.500340  \n",
       "...                       ...       ...  \n",
       "53209                     0.0 -0.092479  \n",
       "53210                     0.0 -0.876672  \n",
       "53211                     0.0  3.152033  \n",
       "53212                     0.0 -0.875058  \n",
       "53213                     0.0  3.033126  \n",
       "\n",
       "[53214 rows x 267 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nor = RobustScaler()\n",
    "_X_train = pd.DataFrame(nor.fit_transform(X_train), columns= X_train.columns)\n",
    "_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "9d84c7b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:55:25.380060Z",
     "start_time": "2023-09-28T02:55:25.222060Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to ComplementNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [242]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m cnb \u001b[38;5;241m=\u001b[39m ComplementNB(alpha\u001b[38;5;241m=\u001b[39malpha)\n\u001b[0;32m      5\u001b[0m detail \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malpha=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malpha\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m \u001b[43meval_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_evaluation\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [193]\u001b[0m, in \u001b[0;36meval_all\u001b[1;34m(model, detail, X_train, y_train, X_test, y_test, table)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_all\u001b[39m(model, detail, X_train, y_train, X_test, y_test, table):\n\u001b[0;32m     66\u001b[0m     \n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# No scale + No use UFS\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     precision, recall, F1_score, auc, rp\u001b[38;5;241m=\u001b[39m \u001b[43mmodel_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m     num_features \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     70\u001b[0m     save_model(model, \u001b[38;5;241m0\u001b[39m, num_features)\n",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36mmodel_score\u001b[1;34m(model, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_score\u001b[39m(model, X_train, y_train, X_test, y_test):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      6\u001b[0m     precision \u001b[38;5;241m=\u001b[39m precision_score(y_test,pred)\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32mC:\\Users\\PC\\miniconda3\\envs\\jupyter_kernel\\lib\\site-packages\\sklearn\\naive_bayes.py:726\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    724\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_counters(n_classes, n_features)\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    727\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_alpha()\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_feature_log_prob(alpha)\n",
      "File \u001b[1;32mC:\\Users\\PC\\miniconda3\\envs\\jupyter_kernel\\lib\\site-packages\\sklearn\\naive_bayes.py:978\u001b[0m, in \u001b[0;36mComplementNB._count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_count\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y):\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;124;03m\"\"\"Count feature occurrences.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 978\u001b[0m     \u001b[43mcheck_non_negative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mComplementNB (input X)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    979\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m safe_sparse_dot(Y\u001b[38;5;241m.\u001b[39mT, X)\n\u001b[0;32m    980\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mC:\\Users\\PC\\miniconda3\\envs\\jupyter_kernel\\lib\\site-packages\\sklearn\\utils\\validation.py:1372\u001b[0m, in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1369\u001b[0m     X_min \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mmin()\n\u001b[0;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative values in data passed to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m whom)\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to ComplementNB (input X)"
     ]
    }
   ],
   "source": [
    "alpha = 0.1\n",
    "\n",
    "cnb = ComplementNB(alpha=alpha)\n",
    "\n",
    "detail = f\"alpha={alpha}\"\n",
    "\n",
    "eval_all(cnb, detail, X_train, y_train, X_test, y_test, nb_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf74b6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_evaluation = nb_evaluation.sort_values(by='AUC', ascending=False, ignore_index=True)\n",
    "nb_evaluation.to_csv('nb_evaluation.csv', index=False)\n",
    "nb_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e508da76",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f23fe45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea11a791",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c6c6ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "822e8526",
   "metadata": {},
   "source": [
    "# Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c15f850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a433bfbd",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dafa9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b60919a",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c008033d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T07:51:02.606044Z",
     "start_time": "2023-09-26T07:51:02.594042Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_evaluation = base_evaluation_table.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "7a83a761",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T07:52:15.332152Z",
     "start_time": "2023-09-26T07:51:04.497201Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.88     21905\n",
      "           1       0.13      0.75      0.22       901\n",
      "\n",
      "    accuracy                           0.79     22806\n",
      "   macro avg       0.56      0.77      0.55     22806\n",
      "weighted avg       0.95      0.79      0.86     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.88     21905\n",
      "           1       0.13      0.75      0.22       901\n",
      "\n",
      "    accuracy                           0.79     22806\n",
      "   macro avg       0.56      0.77      0.55     22806\n",
      "weighted avg       0.95      0.79      0.86     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.88     21905\n",
      "           1       0.13      0.75      0.22       901\n",
      "\n",
      "    accuracy                           0.79     22806\n",
      "   macro avg       0.56      0.77      0.55     22806\n",
      "weighted avg       0.95      0.79      0.86     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 240 features (percentile = 90%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.88     21905\n",
      "           1       0.13      0.74      0.22       901\n",
      "\n",
      "    accuracy                           0.79     22806\n",
      "   macro avg       0.56      0.77      0.55     22806\n",
      "weighted avg       0.95      0.79      0.86     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 240 features (percentile = 90%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.88     21905\n",
      "           1       0.13      0.74      0.22       901\n",
      "\n",
      "    accuracy                           0.79     22806\n",
      "   macro avg       0.56      0.77      0.55     22806\n",
      "weighted avg       0.95      0.79      0.86     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 240 features (percentile = 90%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.88     21905\n",
      "           1       0.13      0.74      0.22       901\n",
      "\n",
      "    accuracy                           0.79     22806\n",
      "   macro avg       0.56      0.77      0.55     22806\n",
      "weighted avg       0.95      0.79      0.86     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 227 features (percentile = 85%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.88     21905\n",
      "           1       0.13      0.75      0.22       901\n",
      "\n",
      "    accuracy                           0.79     22806\n",
      "   macro avg       0.56      0.77      0.55     22806\n",
      "weighted avg       0.95      0.79      0.85     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 227 features (percentile = 85%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.88     21905\n",
      "           1       0.13      0.75      0.22       901\n",
      "\n",
      "    accuracy                           0.79     22806\n",
      "   macro avg       0.56      0.77      0.55     22806\n",
      "weighted avg       0.95      0.79      0.85     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 227 features (percentile = 85%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.88     21905\n",
      "           1       0.13      0.75      0.22       901\n",
      "\n",
      "    accuracy                           0.79     22806\n",
      "   macro avg       0.56      0.77      0.55     22806\n",
      "weighted avg       0.95      0.79      0.85     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 213 features (percentile = 80%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.88     21905\n",
      "           1       0.13      0.75      0.22       901\n",
      "\n",
      "    accuracy                           0.79     22806\n",
      "   macro avg       0.56      0.77      0.55     22806\n",
      "weighted avg       0.95      0.79      0.86     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 213 features (percentile = 80%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.88     21905\n",
      "           1       0.13      0.75      0.22       901\n",
      "\n",
      "    accuracy                           0.79     22806\n",
      "   macro avg       0.56      0.77      0.55     22806\n",
      "weighted avg       0.95      0.79      0.86     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 213 features (percentile = 80%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.88     21905\n",
      "           1       0.13      0.75      0.22       901\n",
      "\n",
      "    accuracy                           0.79     22806\n",
      "   macro avg       0.56      0.77      0.55     22806\n",
      "weighted avg       0.95      0.79      0.86     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 187 features (percentile = 70%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.88     21905\n",
      "           1       0.13      0.75      0.23       901\n",
      "\n",
      "    accuracy                           0.80     22806\n",
      "   macro avg       0.56      0.77      0.55     22806\n",
      "weighted avg       0.95      0.80      0.86     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 187 features (percentile = 70%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.88     21905\n",
      "           1       0.13      0.74      0.22       901\n",
      "\n",
      "    accuracy                           0.80     22806\n",
      "   macro avg       0.56      0.77      0.55     22806\n",
      "weighted avg       0.95      0.80      0.86     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 187 features (percentile = 70%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.88     21905\n",
      "           1       0.13      0.74      0.22       901\n",
      "\n",
      "    accuracy                           0.80     22806\n",
      "   macro avg       0.56      0.77      0.55     22806\n",
      "weighted avg       0.95      0.80      0.86     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 160 features (percentile = 60%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.88     21905\n",
      "           1       0.13      0.75      0.22       901\n",
      "\n",
      "    accuracy                           0.79     22806\n",
      "   macro avg       0.56      0.77      0.55     22806\n",
      "weighted avg       0.95      0.79      0.85     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 160 features (percentile = 60%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.88     21905\n",
      "           1       0.13      0.74      0.22       901\n",
      "\n",
      "    accuracy                           0.79     22806\n",
      "   macro avg       0.56      0.77      0.55     22806\n",
      "weighted avg       0.95      0.79      0.85     22806\n",
      "\n",
      "\n",
      "================================\n",
      "RobustScaler, select 160 features (percentile = 60%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.88     21905\n",
      "           1       0.13      0.74      0.22       901\n",
      "\n",
      "    accuracy                           0.79     22806\n",
      "   macro avg       0.56      0.77      0.55     22806\n",
      "weighted avg       0.95      0.79      0.85     22806\n",
      "\n",
      "\n",
      "================================\n",
      "StandardScaler, select 133 features (percentile = 50%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.79      0.88     21905\n",
      "           1       0.13      0.75      0.22       901\n",
      "\n",
      "    accuracy                           0.79     22806\n",
      "   macro avg       0.56      0.77      0.55     22806\n",
      "weighted avg       0.95      0.79      0.85     22806\n",
      "\n",
      "\n",
      "================================\n",
      "MinMaxScaler, select 133 features (percentile = 50%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.79      0.88     21905\n",
      "           1       0.13      0.75      0.22       901\n",
      "\n",
      "    accuracy                           0.79     22806\n",
      "   macro avg       0.56      0.77      0.55     22806\n",
      "weighted avg       0.95      0.79      0.85     22806\n",
      "\n",
      "\n",
      "================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobustScaler, select 133 features (percentile = 50%):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.79      0.88     21905\n",
      "           1       0.13      0.75      0.22       901\n",
      "\n",
      "    accuracy                           0.79     22806\n",
      "   macro avg       0.56      0.77      0.55     22806\n",
      "weighted avg       0.95      0.79      0.85     22806\n",
      "\n",
      "\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 100\n",
    "max_depth = 5\n",
    "learning_rate=0.05\n",
    "subsample=1.0\n",
    "colsample_bytree=0.5\n",
    "min_child_weight = 4\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=n_estimators,\n",
    "                    max_depth = max_depth,\n",
    "                    learning_rate=learning_rate, \n",
    "                    subsample=subsample,\n",
    "                    colsample_bytree=colsample_bytree,\n",
    "                    min_child_weight = min_child_weight,\n",
    "                    scale_pos_weight = 24)\n",
    "\n",
    "detail = detail = f\"n_estimators: {n_estimators}, max_depth: {max_depth}, learning_rate: {learning_rate}, subsample: {subsample}, colsample_bytree: {colsample_bytree}, min_child_weight: {min_child_weight}\"\n",
    "\n",
    "\n",
    "eval_all(xgb, detail, X_train, y_train, X_test, y_test, xgb_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "44c9166a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T07:55:17.843468Z",
     "start_time": "2023-09-26T07:55:17.801476Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Feature selection</th>\n",
       "      <th>No. features</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>n_estimators: 100, max_depth: 5, learning_rate...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>267</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>n_estimators: 100, max_depth: 5, learning_rate...</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>-</td>\n",
       "      <td>267</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>n_estimators: 100, max_depth: 5, learning_rate...</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>-</td>\n",
       "      <td>267</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>n_estimators: 100, max_depth: 5, learning_rate...</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>160 (60%)</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>n_estimators: 100, max_depth: 5, learning_rate...</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>187 (70%)</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>n_estimators: 100, max_depth: 5, learning_rate...</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>227 (85%)</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>n_estimators: 100, max_depth: 5, learning_rate...</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>227 (85%)</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>n_estimators: 100, max_depth: 5, learning_rate...</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>227 (85%)</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>n_estimators: 100, max_depth: 5, learning_rate...</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>213 (80%)</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>n_estimators: 100, max_depth: 5, learning_rate...</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>213 (80%)</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>n_estimators: 100, max_depth: 5, learning_rate...</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>213 (80%)</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>n_estimators: 100, max_depth: 5, learning_rate...</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>-</td>\n",
       "      <td>267</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>n_estimators: 100, max_depth: 5, learning_rate...</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>187 (70%)</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>n_estimators: 100, max_depth: 5, learning_rate...</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>187 (70%)</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>n_estimators: 100, max_depth: 5, learning_rate...</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>133 (50%)</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>n_estimators: 100, max_depth: 5, learning_rate...</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>133 (50%)</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>n_estimators: 100, max_depth: 5, learning_rate...</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>133 (50%)</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>n_estimators: 100, max_depth: 5, learning_rate...</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>240 (90%)</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>n_estimators: 100, max_depth: 5, learning_rate...</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>240 (90%)</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>n_estimators: 100, max_depth: 5, learning_rate...</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>240 (90%)</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>n_estimators: 100, max_depth: 5, learning_rate...</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>160 (60%)</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>n_estimators: 100, max_depth: 5, learning_rate...</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>UFS(f_classif)</td>\n",
       "      <td>160 (60%)</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model                                            Details  \\\n",
       "0   XGBClassifier  n_estimators: 100, max_depth: 5, learning_rate...   \n",
       "1   XGBClassifier  n_estimators: 100, max_depth: 5, learning_rate...   \n",
       "2   XGBClassifier  n_estimators: 100, max_depth: 5, learning_rate...   \n",
       "3   XGBClassifier  n_estimators: 100, max_depth: 5, learning_rate...   \n",
       "4   XGBClassifier  n_estimators: 100, max_depth: 5, learning_rate...   \n",
       "5   XGBClassifier  n_estimators: 100, max_depth: 5, learning_rate...   \n",
       "6   XGBClassifier  n_estimators: 100, max_depth: 5, learning_rate...   \n",
       "7   XGBClassifier  n_estimators: 100, max_depth: 5, learning_rate...   \n",
       "8   XGBClassifier  n_estimators: 100, max_depth: 5, learning_rate...   \n",
       "9   XGBClassifier  n_estimators: 100, max_depth: 5, learning_rate...   \n",
       "10  XGBClassifier  n_estimators: 100, max_depth: 5, learning_rate...   \n",
       "11  XGBClassifier  n_estimators: 100, max_depth: 5, learning_rate...   \n",
       "12  XGBClassifier  n_estimators: 100, max_depth: 5, learning_rate...   \n",
       "13  XGBClassifier  n_estimators: 100, max_depth: 5, learning_rate...   \n",
       "14  XGBClassifier  n_estimators: 100, max_depth: 5, learning_rate...   \n",
       "15  XGBClassifier  n_estimators: 100, max_depth: 5, learning_rate...   \n",
       "16  XGBClassifier  n_estimators: 100, max_depth: 5, learning_rate...   \n",
       "17  XGBClassifier  n_estimators: 100, max_depth: 5, learning_rate...   \n",
       "18  XGBClassifier  n_estimators: 100, max_depth: 5, learning_rate...   \n",
       "19  XGBClassifier  n_estimators: 100, max_depth: 5, learning_rate...   \n",
       "20  XGBClassifier  n_estimators: 100, max_depth: 5, learning_rate...   \n",
       "21  XGBClassifier  n_estimators: 100, max_depth: 5, learning_rate...   \n",
       "\n",
       "            Scaler Feature selection No. features  Precision  Recall  \\\n",
       "0                -                 -          267      0.132   0.751   \n",
       "1     MinMaxScaler                 -          267      0.132   0.751   \n",
       "2     RobustScaler                 -          267      0.132   0.751   \n",
       "3   StandardScaler    UFS(f_classif)    160 (60%)      0.131   0.750   \n",
       "4   StandardScaler    UFS(f_classif)    187 (70%)      0.133   0.747   \n",
       "5   StandardScaler    UFS(f_classif)    227 (85%)      0.131   0.751   \n",
       "6     MinMaxScaler    UFS(f_classif)    227 (85%)      0.131   0.751   \n",
       "7     RobustScaler    UFS(f_classif)    227 (85%)      0.131   0.751   \n",
       "8   StandardScaler    UFS(f_classif)    213 (80%)      0.131   0.748   \n",
       "9     RobustScaler    UFS(f_classif)    213 (80%)      0.131   0.748   \n",
       "10    MinMaxScaler    UFS(f_classif)    213 (80%)      0.131   0.748   \n",
       "11  StandardScaler                 -          267      0.131   0.747   \n",
       "12    MinMaxScaler    UFS(f_classif)    187 (70%)      0.132   0.744   \n",
       "13    RobustScaler    UFS(f_classif)    187 (70%)      0.132   0.744   \n",
       "14  StandardScaler    UFS(f_classif)    133 (50%)      0.129   0.750   \n",
       "15    MinMaxScaler    UFS(f_classif)    133 (50%)      0.129   0.750   \n",
       "16    RobustScaler    UFS(f_classif)    133 (50%)      0.129   0.750   \n",
       "17    RobustScaler    UFS(f_classif)    240 (90%)      0.130   0.744   \n",
       "18    MinMaxScaler    UFS(f_classif)    240 (90%)      0.130   0.744   \n",
       "19  StandardScaler    UFS(f_classif)    240 (90%)      0.130   0.744   \n",
       "20    MinMaxScaler    UFS(f_classif)    160 (60%)      0.129   0.739   \n",
       "21    RobustScaler    UFS(f_classif)    160 (60%)      0.129   0.739   \n",
       "\n",
       "    F1-score    AUC  \n",
       "0      0.224  0.774  \n",
       "1      0.224  0.774  \n",
       "2      0.224  0.774  \n",
       "3      0.223  0.773  \n",
       "4      0.225  0.773  \n",
       "5      0.223  0.773  \n",
       "6      0.223  0.773  \n",
       "7      0.223  0.773  \n",
       "8      0.223  0.772  \n",
       "9      0.224  0.772  \n",
       "10     0.224  0.772  \n",
       "11     0.223  0.771  \n",
       "12     0.224  0.771  \n",
       "13     0.224  0.771  \n",
       "14     0.221  0.771  \n",
       "15     0.221  0.771  \n",
       "16     0.221  0.771  \n",
       "17     0.222  0.770  \n",
       "18     0.222  0.770  \n",
       "19     0.222  0.770  \n",
       "20     0.220  0.767  \n",
       "21     0.220  0.767  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_evaluation = xgb_evaluation.sort_values(by='AUC', ascending=False, ignore_index=True)\n",
    "xgb_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3027ea9f",
   "metadata": {},
   "source": [
    "**Tuning parameters with GridSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9d2bc9a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T04:21:51.563159Z",
     "start_time": "2023-09-26T04:21:50.854158Z"
    }
   },
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "_X_train = std.fit_transform(X_train)\n",
    "_X_test = std.transform(X_test)\n",
    "                  \n",
    "fc = SelectPercentile(f_classif, percentile=80)\n",
    "fc.fit(_X_train, y_train)\n",
    "\n",
    "_X_train = fc.transform(_X_train)\n",
    "_X_test = fc.transform(_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "312902e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T07:43:11.673477Z",
     "start_time": "2023-09-26T07:30:41.453523Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=80;, score=0.833 total time=   1.6s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=80;, score=0.828 total time=   1.6s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=80;, score=0.827 total time=   1.6s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=80;, score=0.837 total time=   1.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=80;, score=0.844 total time=   1.5s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100;, score=0.833 total time=   1.9s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100;, score=0.829 total time=   1.8s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100;, score=0.828 total time=   1.9s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100;, score=0.838 total time=   1.8s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=100;, score=0.844 total time=   1.8s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=200;, score=0.833 total time=   3.4s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=200;, score=0.831 total time=   3.4s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=200;, score=0.828 total time=   3.4s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=200;, score=0.837 total time=   3.4s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=200;, score=0.843 total time=   3.4s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=80;, score=0.833 total time=   1.6s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=80;, score=0.828 total time=   1.6s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=80;, score=0.827 total time=   1.5s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=80;, score=0.837 total time=   1.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=80;, score=0.844 total time=   1.5s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100;, score=0.834 total time=   1.8s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100;, score=0.829 total time=   1.9s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100;, score=0.828 total time=   1.9s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100;, score=0.838 total time=   1.9s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=100;, score=0.844 total time=   1.9s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=200;, score=0.833 total time=   3.4s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=200;, score=0.831 total time=   3.4s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=200;, score=0.829 total time=   3.4s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=200;, score=0.838 total time=   3.4s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=200;, score=0.843 total time=   3.4s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=80;, score=0.833 total time=   1.5s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=80;, score=0.828 total time=   1.5s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=80;, score=0.827 total time=   1.5s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=80;, score=0.837 total time=   1.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=80;, score=0.843 total time=   1.6s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=100;, score=0.834 total time=   1.8s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=100;, score=0.829 total time=   1.9s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=100;, score=0.828 total time=   1.9s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=100;, score=0.838 total time=   1.9s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=100;, score=0.845 total time=   1.8s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=200;, score=0.833 total time=   3.4s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=200;, score=0.831 total time=   3.4s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=200;, score=0.829 total time=   3.4s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=200;, score=0.838 total time=   3.4s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, min_child_weight=4, n_estimators=200;, score=0.843 total time=   3.4s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=80;, score=0.831 total time=   2.1s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=80;, score=0.827 total time=   2.1s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=80;, score=0.828 total time=   2.1s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=80;, score=0.839 total time=   2.1s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=80;, score=0.841 total time=   2.1s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=100;, score=0.831 total time=   2.5s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=100;, score=0.827 total time=   2.5s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=100;, score=0.828 total time=   2.4s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=100;, score=0.838 total time=   2.5s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=100;, score=0.841 total time=   2.5s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=200;, score=0.828 total time=   4.6s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=200;, score=0.827 total time=   4.6s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=200;, score=0.824 total time=   4.6s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=200;, score=0.836 total time=   4.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=5, min_child_weight=2, n_estimators=200;, score=0.835 total time=   4.6s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=80;, score=0.832 total time=   2.1s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=80;, score=0.826 total time=   2.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=80;, score=0.829 total time=   2.1s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=80;, score=0.839 total time=   2.1s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=80;, score=0.841 total time=   2.1s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=100;, score=0.831 total time=   2.5s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=100;, score=0.828 total time=   2.5s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=100;, score=0.828 total time=   2.5s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=100;, score=0.838 total time=   2.5s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=100;, score=0.842 total time=   2.5s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=200;, score=0.829 total time=   4.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=200;, score=0.827 total time=   4.6s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=200;, score=0.824 total time=   4.6s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=200;, score=0.834 total time=   4.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=200;, score=0.838 total time=   4.6s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=80;, score=0.830 total time=   2.1s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=80;, score=0.826 total time=   2.1s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=80;, score=0.829 total time=   2.1s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=80;, score=0.840 total time=   2.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=80;, score=0.841 total time=   2.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=100;, score=0.831 total time=   2.5s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=100;, score=0.826 total time=   2.5s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=100;, score=0.828 total time=   2.5s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=100;, score=0.839 total time=   2.5s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=100;, score=0.842 total time=   2.5s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=200;, score=0.829 total time=   4.6s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=200;, score=0.824 total time=   4.6s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=200;, score=0.825 total time=   4.6s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=200;, score=0.836 total time=   4.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=200;, score=0.837 total time=   4.6s\n",
      "[CV 1/5] END learning_rate=0.08, max_depth=3, min_child_weight=2, n_estimators=80;, score=0.834 total time=   1.6s\n",
      "[CV 2/5] END learning_rate=0.08, max_depth=3, min_child_weight=2, n_estimators=80;, score=0.830 total time=   1.5s\n",
      "[CV 3/5] END learning_rate=0.08, max_depth=3, min_child_weight=2, n_estimators=80;, score=0.829 total time=   1.5s\n",
      "[CV 4/5] END learning_rate=0.08, max_depth=3, min_child_weight=2, n_estimators=80;, score=0.838 total time=   1.5s\n",
      "[CV 5/5] END learning_rate=0.08, max_depth=3, min_child_weight=2, n_estimators=80;, score=0.845 total time=   1.5s\n",
      "[CV 1/5] END learning_rate=0.08, max_depth=3, min_child_weight=2, n_estimators=100;, score=0.833 total time=   1.9s\n",
      "[CV 2/5] END learning_rate=0.08, max_depth=3, min_child_weight=2, n_estimators=100;, score=0.830 total time=   1.8s\n",
      "[CV 3/5] END learning_rate=0.08, max_depth=3, min_child_weight=2, n_estimators=100;, score=0.829 total time=   1.9s\n",
      "[CV 4/5] END learning_rate=0.08, max_depth=3, min_child_weight=2, n_estimators=100;, score=0.837 total time=   1.9s\n",
      "[CV 5/5] END learning_rate=0.08, max_depth=3, min_child_weight=2, n_estimators=100;, score=0.844 total time=   1.8s\n",
      "[CV 1/5] END learning_rate=0.08, max_depth=3, min_child_weight=2, n_estimators=200;, score=0.832 total time=   3.4s\n",
      "[CV 2/5] END learning_rate=0.08, max_depth=3, min_child_weight=2, n_estimators=200;, score=0.830 total time=   3.4s\n",
      "[CV 3/5] END learning_rate=0.08, max_depth=3, min_child_weight=2, n_estimators=200;, score=0.826 total time=   3.4s\n",
      "[CV 4/5] END learning_rate=0.08, max_depth=3, min_child_weight=2, n_estimators=200;, score=0.835 total time=   3.4s\n",
      "[CV 5/5] END learning_rate=0.08, max_depth=3, min_child_weight=2, n_estimators=200;, score=0.839 total time=   3.4s\n",
      "[CV 1/5] END learning_rate=0.08, max_depth=3, min_child_weight=3, n_estimators=80;, score=0.834 total time=   1.6s\n",
      "[CV 2/5] END learning_rate=0.08, max_depth=3, min_child_weight=3, n_estimators=80;, score=0.829 total time=   1.6s\n",
      "[CV 3/5] END learning_rate=0.08, max_depth=3, min_child_weight=3, n_estimators=80;, score=0.829 total time=   1.5s\n",
      "[CV 4/5] END learning_rate=0.08, max_depth=3, min_child_weight=3, n_estimators=80;, score=0.838 total time=   1.6s\n",
      "[CV 5/5] END learning_rate=0.08, max_depth=3, min_child_weight=3, n_estimators=80;, score=0.845 total time=   1.5s\n",
      "[CV 1/5] END learning_rate=0.08, max_depth=3, min_child_weight=3, n_estimators=100;, score=0.834 total time=   1.9s\n",
      "[CV 2/5] END learning_rate=0.08, max_depth=3, min_child_weight=3, n_estimators=100;, score=0.831 total time=   1.9s\n",
      "[CV 3/5] END learning_rate=0.08, max_depth=3, min_child_weight=3, n_estimators=100;, score=0.829 total time=   1.9s\n",
      "[CV 4/5] END learning_rate=0.08, max_depth=3, min_child_weight=3, n_estimators=100;, score=0.837 total time=   1.9s\n",
      "[CV 5/5] END learning_rate=0.08, max_depth=3, min_child_weight=3, n_estimators=100;, score=0.844 total time=   1.9s\n",
      "[CV 1/5] END learning_rate=0.08, max_depth=3, min_child_weight=3, n_estimators=200;, score=0.833 total time=   3.4s\n",
      "[CV 2/5] END learning_rate=0.08, max_depth=3, min_child_weight=3, n_estimators=200;, score=0.830 total time=   3.4s\n",
      "[CV 3/5] END learning_rate=0.08, max_depth=3, min_child_weight=3, n_estimators=200;, score=0.828 total time=   3.4s\n",
      "[CV 4/5] END learning_rate=0.08, max_depth=3, min_child_weight=3, n_estimators=200;, score=0.835 total time=   3.4s\n",
      "[CV 5/5] END learning_rate=0.08, max_depth=3, min_child_weight=3, n_estimators=200;, score=0.839 total time=   3.4s\n",
      "[CV 1/5] END learning_rate=0.08, max_depth=3, min_child_weight=4, n_estimators=80;, score=0.835 total time=   1.5s\n",
      "[CV 2/5] END learning_rate=0.08, max_depth=3, min_child_weight=4, n_estimators=80;, score=0.829 total time=   1.5s\n",
      "[CV 3/5] END learning_rate=0.08, max_depth=3, min_child_weight=4, n_estimators=80;, score=0.829 total time=   1.6s\n",
      "[CV 4/5] END learning_rate=0.08, max_depth=3, min_child_weight=4, n_estimators=80;, score=0.838 total time=   1.6s\n",
      "[CV 5/5] END learning_rate=0.08, max_depth=3, min_child_weight=4, n_estimators=80;, score=0.844 total time=   1.5s\n",
      "[CV 1/5] END learning_rate=0.08, max_depth=3, min_child_weight=4, n_estimators=100;, score=0.834 total time=   1.9s\n",
      "[CV 2/5] END learning_rate=0.08, max_depth=3, min_child_weight=4, n_estimators=100;, score=0.831 total time=   1.9s\n",
      "[CV 3/5] END learning_rate=0.08, max_depth=3, min_child_weight=4, n_estimators=100;, score=0.829 total time=   1.9s\n",
      "[CV 4/5] END learning_rate=0.08, max_depth=3, min_child_weight=4, n_estimators=100;, score=0.837 total time=   1.9s\n",
      "[CV 5/5] END learning_rate=0.08, max_depth=3, min_child_weight=4, n_estimators=100;, score=0.843 total time=   1.9s\n",
      "[CV 1/5] END learning_rate=0.08, max_depth=3, min_child_weight=4, n_estimators=200;, score=0.832 total time=   3.4s\n",
      "[CV 2/5] END learning_rate=0.08, max_depth=3, min_child_weight=4, n_estimators=200;, score=0.831 total time=   3.4s\n",
      "[CV 3/5] END learning_rate=0.08, max_depth=3, min_child_weight=4, n_estimators=200;, score=0.828 total time=   3.4s\n",
      "[CV 4/5] END learning_rate=0.08, max_depth=3, min_child_weight=4, n_estimators=200;, score=0.837 total time=   3.4s\n",
      "[CV 5/5] END learning_rate=0.08, max_depth=3, min_child_weight=4, n_estimators=200;, score=0.837 total time=   3.4s\n",
      "[CV 1/5] END learning_rate=0.08, max_depth=5, min_child_weight=2, n_estimators=80;, score=0.829 total time=   2.1s\n",
      "[CV 2/5] END learning_rate=0.08, max_depth=5, min_child_weight=2, n_estimators=80;, score=0.828 total time=   2.1s\n",
      "[CV 3/5] END learning_rate=0.08, max_depth=5, min_child_weight=2, n_estimators=80;, score=0.827 total time=   2.1s\n",
      "[CV 4/5] END learning_rate=0.08, max_depth=5, min_child_weight=2, n_estimators=80;, score=0.835 total time=   2.0s\n",
      "[CV 5/5] END learning_rate=0.08, max_depth=5, min_child_weight=2, n_estimators=80;, score=0.839 total time=   2.0s\n",
      "[CV 1/5] END learning_rate=0.08, max_depth=5, min_child_weight=2, n_estimators=100;, score=0.829 total time=   2.5s\n",
      "[CV 2/5] END learning_rate=0.08, max_depth=5, min_child_weight=2, n_estimators=100;, score=0.826 total time=   2.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END learning_rate=0.08, max_depth=5, min_child_weight=2, n_estimators=100;, score=0.826 total time=   2.5s\n",
      "[CV 4/5] END learning_rate=0.08, max_depth=5, min_child_weight=2, n_estimators=100;, score=0.834 total time=   2.5s\n",
      "[CV 5/5] END learning_rate=0.08, max_depth=5, min_child_weight=2, n_estimators=100;, score=0.837 total time=   2.5s\n",
      "[CV 1/5] END learning_rate=0.08, max_depth=5, min_child_weight=2, n_estimators=200;, score=0.824 total time=   4.6s\n",
      "[CV 2/5] END learning_rate=0.08, max_depth=5, min_child_weight=2, n_estimators=200;, score=0.822 total time=   4.6s\n",
      "[CV 3/5] END learning_rate=0.08, max_depth=5, min_child_weight=2, n_estimators=200;, score=0.818 total time=   4.6s\n",
      "[CV 4/5] END learning_rate=0.08, max_depth=5, min_child_weight=2, n_estimators=200;, score=0.830 total time=   4.6s\n",
      "[CV 5/5] END learning_rate=0.08, max_depth=5, min_child_weight=2, n_estimators=200;, score=0.829 total time=   4.6s\n",
      "[CV 1/5] END learning_rate=0.08, max_depth=5, min_child_weight=3, n_estimators=80;, score=0.830 total time=   2.0s\n",
      "[CV 2/5] END learning_rate=0.08, max_depth=5, min_child_weight=3, n_estimators=80;, score=0.828 total time=   2.1s\n",
      "[CV 3/5] END learning_rate=0.08, max_depth=5, min_child_weight=3, n_estimators=80;, score=0.826 total time=   2.1s\n",
      "[CV 4/5] END learning_rate=0.08, max_depth=5, min_child_weight=3, n_estimators=80;, score=0.836 total time=   2.1s\n",
      "[CV 5/5] END learning_rate=0.08, max_depth=5, min_child_weight=3, n_estimators=80;, score=0.838 total time=   2.0s\n",
      "[CV 1/5] END learning_rate=0.08, max_depth=5, min_child_weight=3, n_estimators=100;, score=0.831 total time=   2.5s\n",
      "[CV 2/5] END learning_rate=0.08, max_depth=5, min_child_weight=3, n_estimators=100;, score=0.827 total time=   2.5s\n",
      "[CV 3/5] END learning_rate=0.08, max_depth=5, min_child_weight=3, n_estimators=100;, score=0.825 total time=   2.5s\n",
      "[CV 4/5] END learning_rate=0.08, max_depth=5, min_child_weight=3, n_estimators=100;, score=0.836 total time=   2.5s\n",
      "[CV 5/5] END learning_rate=0.08, max_depth=5, min_child_weight=3, n_estimators=100;, score=0.836 total time=   2.5s\n",
      "[CV 1/5] END learning_rate=0.08, max_depth=5, min_child_weight=3, n_estimators=200;, score=0.826 total time=   4.6s\n",
      "[CV 2/5] END learning_rate=0.08, max_depth=5, min_child_weight=3, n_estimators=200;, score=0.824 total time=   4.6s\n",
      "[CV 3/5] END learning_rate=0.08, max_depth=5, min_child_weight=3, n_estimators=200;, score=0.817 total time=   4.5s\n",
      "[CV 4/5] END learning_rate=0.08, max_depth=5, min_child_weight=3, n_estimators=200;, score=0.830 total time=   4.6s\n",
      "[CV 5/5] END learning_rate=0.08, max_depth=5, min_child_weight=3, n_estimators=200;, score=0.826 total time=   4.6s\n",
      "[CV 1/5] END learning_rate=0.08, max_depth=5, min_child_weight=4, n_estimators=80;, score=0.830 total time=   2.0s\n",
      "[CV 2/5] END learning_rate=0.08, max_depth=5, min_child_weight=4, n_estimators=80;, score=0.828 total time=   2.0s\n",
      "[CV 3/5] END learning_rate=0.08, max_depth=5, min_child_weight=4, n_estimators=80;, score=0.828 total time=   2.0s\n",
      "[CV 4/5] END learning_rate=0.08, max_depth=5, min_child_weight=4, n_estimators=80;, score=0.836 total time=   2.0s\n",
      "[CV 5/5] END learning_rate=0.08, max_depth=5, min_child_weight=4, n_estimators=80;, score=0.841 total time=   2.0s\n",
      "[CV 1/5] END learning_rate=0.08, max_depth=5, min_child_weight=4, n_estimators=100;, score=0.830 total time=   2.5s\n",
      "[CV 2/5] END learning_rate=0.08, max_depth=5, min_child_weight=4, n_estimators=100;, score=0.827 total time=   2.5s\n",
      "[CV 3/5] END learning_rate=0.08, max_depth=5, min_child_weight=4, n_estimators=100;, score=0.827 total time=   2.5s\n",
      "[CV 4/5] END learning_rate=0.08, max_depth=5, min_child_weight=4, n_estimators=100;, score=0.835 total time=   2.4s\n",
      "[CV 5/5] END learning_rate=0.08, max_depth=5, min_child_weight=4, n_estimators=100;, score=0.839 total time=   2.5s\n",
      "[CV 1/5] END learning_rate=0.08, max_depth=5, min_child_weight=4, n_estimators=200;, score=0.826 total time=   4.6s\n",
      "[CV 2/5] END learning_rate=0.08, max_depth=5, min_child_weight=4, n_estimators=200;, score=0.823 total time=   4.6s\n",
      "[CV 3/5] END learning_rate=0.08, max_depth=5, min_child_weight=4, n_estimators=200;, score=0.820 total time=   4.6s\n",
      "[CV 4/5] END learning_rate=0.08, max_depth=5, min_child_weight=4, n_estimators=200;, score=0.830 total time=   4.6s\n",
      "[CV 5/5] END learning_rate=0.08, max_depth=5, min_child_weight=4, n_estimators=200;, score=0.829 total time=   4.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_child_weight=2, n_estimators=80;, score=0.833 total time=   1.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_child_weight=2, n_estimators=80;, score=0.830 total time=   1.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_child_weight=2, n_estimators=80;, score=0.831 total time=   1.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_child_weight=2, n_estimators=80;, score=0.838 total time=   1.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_child_weight=2, n_estimators=80;, score=0.842 total time=   1.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_child_weight=2, n_estimators=100;, score=0.833 total time=   1.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_child_weight=2, n_estimators=100;, score=0.831 total time=   1.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_child_weight=2, n_estimators=100;, score=0.831 total time=   1.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_child_weight=2, n_estimators=100;, score=0.838 total time=   1.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_child_weight=2, n_estimators=100;, score=0.841 total time=   1.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_child_weight=2, n_estimators=200;, score=0.832 total time=   3.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_child_weight=2, n_estimators=200;, score=0.829 total time=   3.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_child_weight=2, n_estimators=200;, score=0.827 total time=   3.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_child_weight=2, n_estimators=200;, score=0.836 total time=   3.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_child_weight=2, n_estimators=200;, score=0.835 total time=   3.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=80;, score=0.834 total time=   1.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=80;, score=0.831 total time=   1.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=80;, score=0.831 total time=   1.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=80;, score=0.838 total time=   1.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=80;, score=0.843 total time=   1.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100;, score=0.834 total time=   1.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100;, score=0.831 total time=   1.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100;, score=0.831 total time=   1.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100;, score=0.838 total time=   1.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100;, score=0.842 total time=   1.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=200;, score=0.833 total time=   3.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=200;, score=0.830 total time=   3.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=200;, score=0.828 total time=   3.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=200;, score=0.836 total time=   3.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=200;, score=0.836 total time=   3.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=80;, score=0.834 total time=   1.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=80;, score=0.830 total time=   1.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=80;, score=0.830 total time=   1.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=80;, score=0.839 total time=   1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=80;, score=0.843 total time=   1.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=100;, score=0.833 total time=   1.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=100;, score=0.830 total time=   1.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=100;, score=0.829 total time=   1.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=100;, score=0.838 total time=   1.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=100;, score=0.842 total time=   1.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=200;, score=0.831 total time=   3.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=200;, score=0.830 total time=   3.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=200;, score=0.827 total time=   3.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=200;, score=0.838 total time=   3.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, min_child_weight=4, n_estimators=200;, score=0.836 total time=   3.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_child_weight=2, n_estimators=80;, score=0.830 total time=   2.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_child_weight=2, n_estimators=80;, score=0.827 total time=   2.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_child_weight=2, n_estimators=80;, score=0.826 total time=   2.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_child_weight=2, n_estimators=80;, score=0.834 total time=   2.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_child_weight=2, n_estimators=80;, score=0.838 total time=   2.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_child_weight=2, n_estimators=100;, score=0.830 total time=   2.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_child_weight=2, n_estimators=100;, score=0.826 total time=   2.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_child_weight=2, n_estimators=100;, score=0.824 total time=   2.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_child_weight=2, n_estimators=100;, score=0.832 total time=   2.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_child_weight=2, n_estimators=100;, score=0.836 total time=   2.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_child_weight=2, n_estimators=200;, score=0.823 total time=   4.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_child_weight=2, n_estimators=200;, score=0.819 total time=   4.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_child_weight=2, n_estimators=200;, score=0.810 total time=   4.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_child_weight=2, n_estimators=200;, score=0.827 total time=   4.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_child_weight=2, n_estimators=200;, score=0.824 total time=   4.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=80;, score=0.832 total time=   2.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=80;, score=0.827 total time=   2.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=80;, score=0.826 total time=   2.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=80;, score=0.835 total time=   2.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=80;, score=0.837 total time=   2.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=100;, score=0.830 total time=   2.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=100;, score=0.825 total time=   2.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=100;, score=0.824 total time=   2.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=100;, score=0.834 total time=   2.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=100;, score=0.835 total time=   2.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=200;, score=0.821 total time=   4.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=200;, score=0.822 total time=   4.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=200;, score=0.814 total time=   4.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=200;, score=0.828 total time=   4.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_child_weight=3, n_estimators=200;, score=0.825 total time=   4.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_child_weight=4, n_estimators=80;, score=0.829 total time=   2.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_child_weight=4, n_estimators=80;, score=0.829 total time=   2.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_child_weight=4, n_estimators=80;, score=0.825 total time=   2.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_child_weight=4, n_estimators=80;, score=0.834 total time=   2.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_child_weight=4, n_estimators=80;, score=0.839 total time=   2.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_child_weight=4, n_estimators=100;, score=0.829 total time=   2.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_child_weight=4, n_estimators=100;, score=0.827 total time=   2.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_child_weight=4, n_estimators=100;, score=0.824 total time=   2.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_child_weight=4, n_estimators=100;, score=0.833 total time=   2.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_child_weight=4, n_estimators=100;, score=0.838 total time=   2.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, min_child_weight=4, n_estimators=200;, score=0.821 total time=   4.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, min_child_weight=4, n_estimators=200;, score=0.819 total time=   4.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, min_child_weight=4, n_estimators=200;, score=0.813 total time=   4.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, min_child_weight=4, n_estimators=200;, score=0.825 total time=   4.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, min_child_weight=4, n_estimators=200;, score=0.826 total time=   4.6s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=0.5,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=0.05, m...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=5,\n",
       "                                     max_leaves=None, min_child_weight=4,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.05, 0.08, 0.1],\n",
       "                         &#x27;max_depth&#x27;: [3, 5], &#x27;min_child_weight&#x27;: [2, 3, 4],\n",
       "                         &#x27;n_estimators&#x27;: [80, 100, 200]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=0.5,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=0.05, m...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=5,\n",
       "                                     max_leaves=None, min_child_weight=4,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.05, 0.08, 0.1],\n",
       "                         &#x27;max_depth&#x27;: [3, 5], &#x27;min_child_weight&#x27;: [2, 3, 4],\n",
       "                         &#x27;n_estimators&#x27;: [80, 100, 200]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.5, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=4, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.5, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=4, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=0.5,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=0.05, m...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=5,\n",
       "                                     max_leaves=None, min_child_weight=4,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={'learning_rate': [0.05, 0.08, 0.1],\n",
       "                         'max_depth': [3, 5], 'min_child_weight': [2, 3, 4],\n",
       "                         'n_estimators': [80, 100, 200]},\n",
       "             scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'n_estimators': [80, 100, 200],\n",
    "              'learning_rate' : [0.05,0.08,0.1],\n",
    "              'max_depth': [3,5],\n",
    "              'min_child_weight': [2,3,4]}\n",
    "\n",
    "tuning_xgb = GridSearchCV(xgb, param_grid=parameters, scoring='roc_auc',cv=5,verbose=3)\n",
    "tuning_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1cb8c8ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T07:45:33.414898Z",
     "start_time": "2023-09-26T07:45:33.392813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 3,\n",
       " 'n_estimators': 80}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f509d39e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T07:45:41.448741Z",
     "start_time": "2023-09-26T07:45:41.335794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.77      0.87     21905\n",
      "           1       0.12      0.77      0.21       901\n",
      "\n",
      "    accuracy                           0.77     22806\n",
      "   macro avg       0.56      0.77      0.54     22806\n",
      "weighted avg       0.95      0.77      0.84     22806\n",
      "\n",
      "0.774\n"
     ]
    }
   ],
   "source": [
    "pred = tuning_xgb.predict(X_test)\n",
    "print(classification_report(y_test, pred))\n",
    "auc = roc_auc_score(y_test, pred).round(3)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defba419",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T03:31:17.368439Z",
     "start_time": "2023-09-26T03:31:17.358450Z"
    }
   },
   "source": [
    "# Hist Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf5ea78",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5165f5f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T03:33:45.925053Z",
     "start_time": "2023-09-19T03:33:44.799053Z"
    }
   },
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6cd912",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a0a4de",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d277a838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e5bf2c6",
   "metadata": {},
   "source": [
    "# Submission Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0703a001",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T06:55:51.648924Z",
     "start_time": "2023-09-26T06:55:51.511928Z"
    }
   },
   "outputs": [],
   "source": [
    "id_test = test_data['ID']\n",
    "X_test_sub = pd.DataFrame(test_data.drop(['ID'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8db2593b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T06:55:52.656925Z",
     "start_time": "2023-09-26T06:55:52.596925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>imp_op_var40_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var29_ult3</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40532.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45486.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46993.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187898.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73649.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75813</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40243.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75814</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146961.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75815</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167299.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75816</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75817</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75818 rows × 369 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0         2     32                 0.0                      0.0   \n",
       "1         2     35                 0.0                      0.0   \n",
       "2         2     23                 0.0                      0.0   \n",
       "3         2     24                 0.0                      0.0   \n",
       "4         2     23                 0.0                      0.0   \n",
       "...     ...    ...                 ...                      ...   \n",
       "75813     2     23                 0.0                      0.0   \n",
       "75814     2     26                 0.0                      0.0   \n",
       "75815     2     24                 0.0                      0.0   \n",
       "75816     2     40                 0.0                      0.0   \n",
       "75817     2     23                 0.0                      0.0   \n",
       "\n",
       "       imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  \\\n",
       "0                          0.0                      0.0   \n",
       "1                          0.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          0.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "75813                      0.0                      0.0   \n",
       "75814                      0.0                      0.0   \n",
       "75815                      0.0                      0.0   \n",
       "75816                      0.0                      0.0   \n",
       "75817                      0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_comer_ult3  imp_op_var40_efect_ult1  \\\n",
       "0                          0.0                      0.0   \n",
       "1                          0.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          0.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "75813                      0.0                      0.0   \n",
       "75814                      0.0                      0.0   \n",
       "75815                      0.0                      0.0   \n",
       "75816                      0.0                      0.0   \n",
       "75817                      0.0                      0.0   \n",
       "\n",
       "       imp_op_var40_efect_ult3  imp_op_var40_ult1  ...  \\\n",
       "0                          0.0                0.0  ...   \n",
       "1                          0.0                0.0  ...   \n",
       "2                          0.0                0.0  ...   \n",
       "3                          0.0                0.0  ...   \n",
       "4                          0.0                0.0  ...   \n",
       "...                        ...                ...  ...   \n",
       "75813                      0.0                0.0  ...   \n",
       "75814                      0.0                0.0  ...   \n",
       "75815                      0.0                0.0  ...   \n",
       "75816                      0.0                0.0  ...   \n",
       "75817                      0.0                0.0  ...   \n",
       "\n",
       "       saldo_medio_var29_ult3  saldo_medio_var33_hace2  \\\n",
       "0                         0.0                      0.0   \n",
       "1                         0.0                      0.0   \n",
       "2                         0.0                      0.0   \n",
       "3                         0.0                      0.0   \n",
       "4                         0.0                      0.0   \n",
       "...                       ...                      ...   \n",
       "75813                     0.0                      0.0   \n",
       "75814                     0.0                      0.0   \n",
       "75815                     0.0                      0.0   \n",
       "75816                     0.0                      0.0   \n",
       "75817                     0.0                      0.0   \n",
       "\n",
       "       saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                          0.0                     0.0   \n",
       "1                          0.0                     0.0   \n",
       "2                          0.0                     0.0   \n",
       "3                          0.0                     0.0   \n",
       "4                          0.0                     0.0   \n",
       "...                        ...                     ...   \n",
       "75813                      0.0                     0.0   \n",
       "75814                      0.0                     0.0   \n",
       "75815                      0.0                     0.0   \n",
       "75816                      0.0                     0.0   \n",
       "75817                      0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var33_ult3  saldo_medio_var44_hace2  \\\n",
       "0                         0.0                      0.0   \n",
       "1                         0.0                      0.0   \n",
       "2                         0.0                      0.0   \n",
       "3                         0.0                      0.0   \n",
       "4                         0.0                      0.0   \n",
       "...                       ...                      ...   \n",
       "75813                     0.0                      0.0   \n",
       "75814                     0.0                      0.0   \n",
       "75815                     0.0                      0.0   \n",
       "75816                     0.0                      0.0   \n",
       "75817                     0.0                      0.0   \n",
       "\n",
       "       saldo_medio_var44_hace3  saldo_medio_var44_ult1  \\\n",
       "0                          0.0                     0.0   \n",
       "1                          0.0                     0.0   \n",
       "2                          0.0                     0.0   \n",
       "3                          0.0                     0.0   \n",
       "4                          0.0                     0.0   \n",
       "...                        ...                     ...   \n",
       "75813                      0.0                     0.0   \n",
       "75814                      0.0                     0.0   \n",
       "75815                      0.0                     0.0   \n",
       "75816                      0.0                     0.0   \n",
       "75817                      0.0                     0.0   \n",
       "\n",
       "       saldo_medio_var44_ult3          var38  \n",
       "0                         0.0   40532.100000  \n",
       "1                         0.0   45486.720000  \n",
       "2                         0.0   46993.950000  \n",
       "3                         0.0  187898.610000  \n",
       "4                         0.0   73649.730000  \n",
       "...                       ...            ...  \n",
       "75813                     0.0   40243.200000  \n",
       "75814                     0.0  146961.300000  \n",
       "75815                     0.0  167299.770000  \n",
       "75816                     0.0  117310.979016  \n",
       "75817                     0.0  117310.979016  \n",
       "\n",
       "[75818 rows x 369 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5e18ebfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T06:41:54.995057Z",
     "start_time": "2023-09-26T06:41:54.431061Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SelectPercentile(percentile=80)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectPercentile</label><div class=\"sk-toggleable__content\"><pre>SelectPercentile(percentile=80)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SelectPercentile(percentile=80)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "_X_train = sc.fit_transform(X_train)\n",
    "               \n",
    "fc = SelectPercentile(f_classif, percentile=80)\n",
    "fc.fit(_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "161bf54b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T06:55:58.684138Z",
     "start_time": "2023-09-26T06:55:58.320144Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_sub = X_test_sub.drop(columns=dup_col, axis=1)\n",
    "X_test_sub = X_test_sub.drop(columns=drop_col, axis=1)\n",
    "\n",
    "X_test_sub = sel.transform(X_test_sub)\n",
    "# X_test_sub = sc.transform(X_test_sub)\n",
    "# X_test_sub = fc.transform(X_test_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "93fd558b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T06:55:59.918228Z",
     "start_time": "2023-09-26T06:55:59.903219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75818, 267)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "289d4986",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T07:28:08.714974Z",
     "start_time": "2023-09-26T07:28:08.665141Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('model/XGBClassifier/XGBClassifier_noScale_267.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "1162e016",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T07:28:47.853480Z",
     "start_time": "2023-09-26T07:28:47.786533Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred= clf.predict_proba(X_test_sub)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "eb6b104e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T07:28:49.281969Z",
     "start_time": "2023-09-26T07:28:49.072968Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"ID\":id_test, \"TARGET\":y_pred})\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_kernel",
   "language": "python",
   "name": "jupyter_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
