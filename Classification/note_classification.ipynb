{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c07d469",
   "metadata": {},
   "source": [
    "# Xử lý Imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54efee96",
   "metadata": {},
   "source": [
    "## Metric\n",
    "\n",
    "Khi hiện tượng mất cân bằng dữ liệu nghiêm trọng xảy ra thì việc sử dụng độ chính xác làm thước đo đánh giá mô hình thường không hiệu quả bởi hầu hết chúng đều đạt độ chính xác rất cao. Một mô hình ngẫu nhiên dự báo toàn bộ là nhãn thuộc nhóm đa số cũng sẽ mang lại kết quả gần bằng `100%`. Khi đó ta có thể cân nhắc tới một số metrics thay thế như `precision, recall, f1-score, gini,...`. Các chỉ số này sẽ không quá lớn để dẫn tới ngộ nhận độ chính xác, đồng thời chúng tập trung hơn vào việc đánh giá độ chính xác trên nhóm thiểu số, nhóm mà chúng ta muốn dự báo chính xác hơn so với nhóm đa số.\n",
    "\n",
    "<img src=\"https://github.com/thangnch/photos/blob/master/Screen%20Shot%202020-06-16%20at%2014.00.30.png?raw=true&a=1\" width=\"600px\" style=\"display:block; margin-left:auto; margin-right:auto\"/>\n",
    "\n",
    "<img src=\"https://images.viblo.asia/b327fba1-8ae2-4729-805e-a417ce5cb905.png\" width=\"350px\" style=\"display:block; margin-left:auto; margin-right:auto\"/>\n",
    "\n",
    "Từ các hình trên ta dễ dàng hình dung được ý nghĩa của các chỉ số đó là:\n",
    "\n",
    "* **Precision**: Mức độ dự báo chính xác trong những trường hợp được dự báo là Positive.\n",
    "\n",
    "$$precision = \\frac{TP}{TP+FP}$$\n",
    "\n",
    "* **Recall**: Mức độ dự báo chuẩn xác những trường hợp là Positive trong những trường hợp thực tế là Positive.\n",
    "\n",
    "$$Recall = \\frac{TP}{TP+FN}$$\n",
    "\n",
    "* **F1-Score**: Trung bình điều hòa giữa Precision và Recall. Đây là chỉ số thay thế lý tưởng cho accuracy khi mô hình có tỷ lệ mất cân bằng mẫu cao.\n",
    "\n",
    "$$F1 = \\frac{2}{\\frac{1}{precision} + \\frac{1}{recall}}$$\n",
    "\n",
    "\n",
    "* **ROC**: **ROC (Receiver Operating Characteristic)**, là một biểu đồ thường được sử dụng trong việc đánh giá hiệu suất của các mô hình phân loại. **ROC curve** thường biểu thị **True Positive Rate(TPR)** (chính là Recall) trên trục Y và **False Positive Rate(FPR)** trên trục X. \n",
    "\n",
    "$$TPR = \\frac{TP}{TP+FN}$$\n",
    "\n",
    "$$FPR = \\frac{FP}{FP+TN}$$\n",
    "\n",
    "  **TPR** là tỷ lệ các mẫu dương thực sự được phân loại đúng bởi mô hình (tức là các trường hợp thực sự thuộc vào lớp dương và được dự đoán đúng). **FPR** là tỷ lệ các mẫu âm thực sự bị phân loại sai lầm thành lớp dương (tức là các trường hợp thực sự thuộc vào lớp âm nhưng bị dự đoán là lớp dương).\n",
    "  \n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Sensitivity_and_specificity_1.01.svg/341px-Sensitivity_and_specificity_1.01.svg.png\" width=\"350px\" style=\"display:block; margin-left:auto; margin-right:auto\"/>\n",
    "\n",
    "  **Biểu đồ ROC** thường bắt đầu từ gốc tọa độ (0,0) và điểm ở góc trên bên trái của biểu đồ là điểm \"lý tưởng\" - có **FPR** bằng 0 và **TPR** bằng 1. Điều này thể hiện một mô hình hoàn hảo không phạm phân loại sai lầm. Tuy nhiên, trong thực tế, điểm này thường không đạt được. Do đó, mục tiêu là cố gắng **tối đa hóa TPR** và đồng thời **giảm thiểu FPR**.\n",
    "\n",
    "* **AUC**: Việc vẽ đồ thị **ROC** sẽ dẫn tới một khái niệm tính toán vùng nằm dưới đường ROC **(Area Under the Curve – AUC )**. Đại lượng này có **giá trị từ 0-1**, giá trị càng cao thì model càng tốt và có nghĩa là đường ROC càng cong sát phía trên. Biểu diễn mối quan hệ giữa độ nhạy (sensitivity) và độ đặc hiệu (specificity). Đánh giá khả năng phân loại good và bad được dự báo từ mô hình. \n",
    "\n",
    "   AUC bằng 1 sẽ thể hiện một mô hình dự đoán hoàn hảo, trong khi AUC bằng 0.5 thể hiện hiệu suất tương đương với việc phân loại ngẫu nhiên. Điều quan trọng là tối ưu hóa TPR và đồng thời giảm thiểu FPR để tạo ra một đường cong ROC có giá trị AUC lớn nhất.\n",
    "\n",
    "Một mô hình có các chỉ số trên đều cao thì mô hình có chất lượng dự báo càng tốt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebdd207",
   "metadata": {},
   "source": [
    "## Under sampling\n",
    "\n",
    "**Under sampling** là việc ta giảm số lượng các quan sát của nhóm đa số để nó trở nên cân bằng với số quan sát của nhóm thiểu số. Ưu điểm của under sampling là làm cân bằng mẫu một cách nhanh chóng, dễ dàng tiến hành thực hiện mà không cần đến thuật toán giả lập mẫu.\n",
    "\n",
    "Tuy nhiên nhược điểm của nó là kích thước mẫu sẽ bị giảm đáng kể. Gỉa sử nhóm thiểu số có kích thước là 500, như vậy để tạo ra sự cân bằng mẫu giữa nhóm đa số và thiểu số sẽ cần giảm kích thước mẫu của nhóm đa số từ 10000 về 500. Tổng kích thước tập huấn luyện sau under sampling là 1000 và chiếm gần 1/10 kích thước tập huấn luyện ban đầu. Tập huấn luyện mới khá nhỏ, không đại diện cho phân phối của toàn bộ tập dữ liệu và thường dễ dẫn tới hiện tượng overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d396b82",
   "metadata": {},
   "source": [
    "## Over sampling\n",
    "\n",
    "**Over sampling** là các phương pháp giúp giải quyết hiện tượng mất cân bằng mẫu bằng cách gia tăng kích thước mẫu thuộc nhóm thiểu số bằng các kĩ thuật khác nhau. Có 2 phương pháp chính để thực hiện over sampling đó là:\n",
    "\n",
    "* Lựa chọn mẫu có tái lập.\n",
    "* Mô phỏng mẫu mới dựa trên thông tin tổng hợp của các mẫu cũ.\n",
    "\n",
    "### Naive random over-sampling\n",
    "\n",
    "**Naive random Over sampling** là phương pháp tái chọn mẫu dựa trên giả thuyết ngây ngô là dữ liệu mẫu giả lập mới sẽ giống dữ liệu sẵn có. Do đó ta sẽ cân bằng mẫu bằng cách lựa chọn ngẫu nhiên có lặp lại các quan sát thuộc nhóm thiểu số.\n",
    "\n",
    "### SMOTE\n",
    "\n",
    "**SMOTE** (Synthetic Minority Over-sampling) và **ADASYN** (Adaptive synthetic sampling) là các phương pháp sinh mẫu nhằm gia tăng kích thước mẫu của nhóm thiểu số trong trường hợp xảy ra mất cân bằng mẫu. Để gia tăng kích thước mẫu, với mỗi một mẫu thuộc nhóm thiểu số ta sẽ lựa chọn ra $k$ mẫu láng giềng gần nhất với nó và sau đó thực hiện tổ hợp tuyến tính để tạo ra mẫu giả lập. Phương pháp để lựa chọn ra các láng giềng của một quan sát có thể dựa trên thuật toán `kNN` hoặc `SVM`.\n",
    "\n",
    "**SMOTE** được điều chỉnh thông qua hai tham số chính: `k_neighbors` (số lượng hàng xóm gần nhất mà thuật toán sẽ xem xét) và số lượng điểm mới mà bạn muốn tạo ra. Các bước của thuật toán **SMOTE** như sau:\n",
    "\n",
    "1. Ngẫu nhiên chọn một điểm thuộc lớp thiểu số (minority point).\n",
    "\n",
    "2. Ngẫu nhiên chọn bất kỳ điểm nào trong `k_neighbors` điểm gần nhất của điểm đã chọn ở bước 1, và điểm này cũng thuộc cùng một lớp với điểm đã chọn.\n",
    "\n",
    "3. Ngẫu nhiên xác định một giá trị lambda nằm trong khoảng `[0, 1]`.\n",
    "\n",
    "4. Tạo ra và đặt một điểm mới trên đoạn thẳng nối giữa hai điểm đã chọn ở bước 1 và bước 2. Điểm mới này được đặt ở vị trí nằm giữa hai điểm gốc và cách điểm gốc một phần trăm lambda của khoảng cách giữa hai điểm gốc.\n",
    "\n",
    "Mục đích của SMOTE là tạo ra các điểm dữ liệu tổng hợp cho lớp thiểu số để làm tăng cường dữ liệu và cân bằng tỷ lệ giữa các lớp. Bằng cách làm như vậy, nó giúp cải thiện khả năng của mô hình học máy trong việc phân loại các trường hợp thuộc lớp thiểu số.\n",
    "\n",
    "<img src=\"image/smote.png\" width=\"450px\" style=\"display:block; margin-left:auto; margin-right:auto\"/>\n",
    "\n",
    "### ADASYN\n",
    "\n",
    "**ADASYN** là một phiên bản cải tiến của **SMOTE**. Chức năng chính của **ADASYN** tương tự với **SMOTE**, nhưng có một cải tiến nhỏ. Sau khi tạo ra các mẫu tổng hợp, ADASYN thêm vào các điểm một giá trị ngẫu nhiên nhỏ, từ đó làm cho chúng trở nên thực tế hơn. Nói cách khác, thay vì tất cả các mẫu đều có sự tương quan tuyến tính hoàn toàn với điểm gốc, chúng có một chút phân tán hoặc biến động.\n",
    "\n",
    "Khi ADASYN thêm giá trị ngẫu nhiên nhỏ vào các điểm tổng hợp, nó tạo ra một sự biến động nhỏ trong dữ liệu tổng hợp. Điều này làm cho các mẫu tổng hợp không nằm hoàn toàn trên đường thẳng nối các điểm gốc, mà thay vào đó chúng có sự phân tán nhỏ trong không gian dữ liệu. Sự phân tán này giúp làm cho các mẫu tổng hợp trở nên \"tự nhiên\" hơn và có tính thực tế cao hơn, giúp mô hình học máy có khả năng tổng quát hóa tốt hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba6d2cd",
   "metadata": {},
   "source": [
    "## Class weights\n",
    "\n",
    "Việc dự báo sai một quan sát thuộc mẫu đa số sẽ ít nghiêm trọng hơn so với dự báo sai một quan sát thuộc mẫu thiểu số. Xuất phát từ ý tưởng đó chúng ta sẽ phạt nặng hơn đối với sai số dự báo thuộc nhóm thiểu bằng cách gán cho nó một trọng số lớn hơn trong công thức của hàm loss function. Chẳng hạn như bên dưới trong argument `class_weight` chúng ta sẽ gán cho các trọng số của class thiểu số nhãn `1` là giá trị 0.9 và class đa số nhãn `0` là 0.1. Khi đó kết quả mô hình thu được trên tập test sẽ là:\n",
    "\n",
    "\n",
    "```\n",
    "model_pen = RandomForestClassifier(n_estimators=500, \n",
    "                                max_depth=10, \n",
    "                                min_samples_split=400, \n",
    "                                random_state=12, \n",
    "                                class_weight={0: 0.1,\n",
    "                                              1: 0.9},\n",
    "                                max_features=\"auto\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6ca16e",
   "metadata": {},
   "source": [
    "## Threshold moving\n",
    "\n",
    "Với bài toán classifier, nhiều lần các bộ phân loại sẽ dự đoán xác suất của việc một mẫu thuộc vào một lớp cụ thể nào. Chúng ta gán xác suất dự đoán này cho một lớp cụ thể dựa trên một ngưỡng cố định, thường là 0.5. Nghĩa là, nếu xác suất dự đoán < 0.5, thì mẫu thuộc vào một lớp cụ thể, và nếu không thì mẫu thuộc vào lớp còn lại.\n",
    "\n",
    "Tuy nhiên, đối với các vấn đề về sự mất cân bằng giữa các lớp, ngưỡng mặc định này có thể không hoạt động đúng cách. Chúng ta cần thay đổi ngưỡng thành giá trị tối ưu để có thể phân tách hai lớp hiệu quả. Chúng ta có thể sử dụng ROC Curves và Đường cong Precision-Recall (Precision-Recall Curves) để tìm ngưỡng tối ưu cho bộ phân loại. Chúng ta cũng có thể sử dụng phương pháp tìm kiếm trên lưới (grid search) hoặc tìm kiếm trong một tập hợp các giá trị để xác định giá trị tối ưu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c3e255",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Đầu ra dự đoán của logistic regression thường được viết chung dưới dạng:\n",
    "\\\\[\n",
    "f(\\mathbf{x}) = \\theta(\\mathbf{w}^T\\mathbf{x})\n",
    "\\\\]\n",
    "\n",
    "Trong đó \\\\(\\theta\\\\) được gọi là logistic function. Một số activation cho mô hình tuyến tính được cho trong hình dưới đây:\n",
    "\n",
    "<div class=\"imgcap\">\n",
    "<img src =\"https://machinelearningcoban.com/assets/LogisticRegression/activation.png\" align = \"center\" width = \"800\">\n",
    "</div> \n",
    "\n",
    "## Sigmoid function\n",
    "\n",
    "Trong số các hàm số có 3 tính chất nói trên thì hàm _sigmoid_:\n",
    "\n",
    "$$f(s) = \\frac{1}{1 + e^{-s}} \\triangleq \\sigma(s)$$\n",
    "\n",
    "được sử dụng nhiều nhất, vì nó bị chặn trong khoảng \\\\((0, 1)\\\\). Thêm nữa:\n",
    "\n",
    "$$\n",
    "\\lim_{s \\rightarrow -\\infty}\\sigma(s) = 0; ~~ \\lim_{s \\rightarrow +\\infty}\\sigma(s) = 1 \n",
    "$$\n",
    "\n",
    "Đặc biệt hơn nữa:\n",
    "\n",
    "\\\\[\n",
    "\\begin{eqnarray}\n",
    "\\sigma'(s) &=& \\frac{e^{-s}}{(1 + e^{-s})^2} \\newline\n",
    "&=& \\frac{1}{1 + e^{-s}} \\frac{e^{-s}}{1 + e^{-s}} \\newline\n",
    "&=& \\sigma(s)(1 - \\sigma(s))\n",
    "\\end{eqnarray}\n",
    "\\\\]\n",
    "\n",
    "Công thức đạo hàm đơn giản thế này giúp hàm số này được sử dụng rộng rãi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a192e2ad",
   "metadata": {},
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a6c3d1",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d44240a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T04:25:30.941935Z",
     "start_time": "2023-08-23T04:25:30.925945Z"
    }
   },
   "source": [
    "## Kernel Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6e3779",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_kernel",
   "language": "python",
   "name": "jupyter_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
